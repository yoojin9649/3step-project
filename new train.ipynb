{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ac14c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import matplotlib; matplotlib.use('Agg')\n",
    "import os\n",
    "import os.path as osp\n",
    "import argparse\n",
    "\n",
    "from train import train \n",
    "from test import test\n",
    "from test_beam import test_beam "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270cd592",
   "metadata": {},
   "source": [
    "## 하이퍼 파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24cdd0c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreFalseAction(option_strings=['--no-attention'], dest='attention', nargs=0, const=False, default=True, type=None, choices=None, help='Use this for convcap without attention', metavar=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch Convolutional Image Captioning Model')\n",
    "\n",
    "parser.add_argument('model_dir', help='output directory to save models & results')\n",
    "\n",
    "parser.add_argument('-g', '--gpu', type=int, default=0,\\\n",
    "                    help='gpu device id')\n",
    "\n",
    "parser.add_argument('--coco_root', type=str, default= './data/coco/',\\\n",
    "                    help='directory containing coco dataset train2014, val2014, & annotations')\n",
    "\n",
    "parser.add_argument('-t', '--is_train', type=int, default=1,\\\n",
    "                    help='use 1 to train model')\n",
    "\n",
    "parser.add_argument('-e', '--epochs', type=int, default=30,\\\n",
    "                    help='number of training epochs')\n",
    "\n",
    "parser.add_argument('-b', '--batchsize', type=int, default=20,\\\n",
    "                    help='number of images per training batch')\n",
    "\n",
    "parser.add_argument('-c', '--ncap_per_img', type=int, default=5,\\\n",
    "                    help='ground-truth captions per image in training batch')\n",
    "\n",
    "parser.add_argument('-n', '--num_layers', type=int, default=3,\\\n",
    "                    help='depth of convcap network')\n",
    "\n",
    "parser.add_argument('-m', '--nthreads', type=int, default=4,\\\n",
    "                    help='pytorch data loader threads')\n",
    "\n",
    "# parser.add_argument('-ft', '--finetune_after', type=int, default=8,\\\n",
    "#                     help='epochs after which vgg16 is fine-tuned')\n",
    "\n",
    "parser.add_argument('-lr', '--learning_rate', type=float, default=5e-5,\\\n",
    "                    help='learning rate for convcap')\n",
    "\n",
    "parser.add_argument('-st', '--lr_step_size', type=int, default=15,\\\n",
    "                    help='epochs to decay learning rate after')\n",
    "\n",
    "parser.add_argument('-sc', '--score_select', type=str, default='CIDEr',\\\n",
    "                    help='metric to pick best model')\n",
    "\n",
    "parser.add_argument('--beam_size', type=int, default=1, \\\n",
    "                    help='beam size to use for test') \n",
    "\n",
    "parser.add_argument('--attention', dest='attention', action='store_true', \\\n",
    "                    help='Use this for convcap with attention (by default set)')\n",
    "\n",
    "parser.add_argument('--no-attention', dest='attention', action='store_false', \\\n",
    "                    help='Use this for convcap without attention')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "faf0548c",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.set_defaults(attention=True)\n",
    "\n",
    "args, _ = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0aeed33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.finetune_after = 8\n",
    "args.model_dir = 'output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499b1870",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8973368b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f87f230",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import argparse\n",
    "import numpy as np \n",
    "import json\n",
    "import time\n",
    " \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models                                                                     \n",
    "\n",
    "from coco_loader import coco_loader\n",
    "from convcap import convcap\n",
    "from vggfeats import Vgg16Feats\n",
    "from tqdm import tqdm \n",
    "from test import test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92131ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15d80637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n"
     ]
    }
   ],
   "source": [
    "if (args.is_train == 1):\n",
    "    print('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d858dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading annotation file...\n",
      "Found 113287 images in split: train\n",
      "[DEBUG] #words in wordlist: 9221\n",
      "[DEBUG] Loading train data ... 3.102025 secs\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "train_data = coco_loader(args.coco_root, split='train', ncap_per_img=args.ncap_per_img)\n",
    "print('[DEBUG] Loading train data ... %f secs' % (time.time() - t_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb3bb293",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = DataLoader(dataset=train_data, num_workers=0, batch_size=args.batchsize, \\\n",
    "                               shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309eb135",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1e5f0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import json\n",
    "import argparse\n",
    "from random import shuffle, seed\n",
    "import string\n",
    "# non-standard dependencies:\n",
    "import h5py\n",
    "from six.moves import cPickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import skimage.io\n",
    "\n",
    "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "\n",
    "preprocess = Compose([\n",
    "    Resize((224, 224), interpolation=Image.BICUBIC),\n",
    "    CenterCrop((224, 224)),\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "from clip.clip import load\n",
    "from timm.models.vision_transformer import resize_pos_embed\n",
    "import timm\n",
    "\n",
    "from captioning.utils.resnet_utils import myResnet\n",
    "import captioning.utils.resnet as resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1122f8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, transform = load('RN50', jit=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be477e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIP(\n",
       "  (visual): ModifiedResNet(\n",
       "    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (-1): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (attnpool): AttentionPool2d(\n",
       "      (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (c_proj): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (resblocks): Sequential(\n",
       "      (0): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (6): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (7): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (8): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (9): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (10): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (11): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (token_embedding): Embedding(49408, 512)\n",
       "  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.cuda()\n",
    "model.train(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1045204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "convcap(\n",
       "  (emb_0): Embedding(9221, 2048, padding_idx=0)\n",
       "  (emb_1): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "  (imgproj): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "  (resproj): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv1d(4096, 4096, kernel_size=(5,), stride=(1,), padding=(4,))\n",
       "    (1): Conv1d(2048, 4096, kernel_size=(5,), stride=(1,), padding=(4,))\n",
       "    (2): Conv1d(2048, 4096, kernel_size=(5,), stride=(1,), padding=(4,))\n",
       "  )\n",
       "  (attention): ModuleList(\n",
       "    (0): AttentionLayer(\n",
       "      (in_projection): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (out_projection): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    )\n",
       "    (1): AttentionLayer(\n",
       "      (in_projection): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (out_projection): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    )\n",
       "    (2): AttentionLayer(\n",
       "      (in_projection): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (out_projection): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier_0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "  (classifier_1): Linear(in_features=1024, out_features=9221, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convcap model\n",
    "model_convcap = convcap(train_data.numwords, args.num_layers, is_attention=args.attention, nfeats=2048, nimgfeats=1024)\n",
    "model_convcap.cuda()\n",
    "model_convcap.train(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97ce59a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.RMSprop(model_convcap.parameters(), lr=args.learning_rate)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=args.lr_step_size, gamma=.1)\n",
    "img_optimizer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3353b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = args.batchsize\n",
    "ncap_per_img = args.ncap_per_img\n",
    "batchsize_cap = batchsize*ncap_per_img\n",
    "max_tokens = train_data.max_tokens\n",
    "nbatches = np.int_(np.floor((len(train_data.ids)*1.)/batchsize)) \n",
    "bestscore = .0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df1e0a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_img_per_cap(imgsfeats, imgsfc7, ncap_per_img):\n",
    "    batchsize, featdim, feat_h, feat_w = imgsfeats.size()\n",
    "    batchsize_cap = batchsize*ncap_per_img\n",
    "    imgsfeats = imgsfeats.unsqueeze(1).expand(batchsize, ncap_per_img, featdim, feat_h, feat_w)\n",
    "    imgsfeats = imgsfeats.contiguous().view(batchsize_cap, featdim, feat_h, feat_w)\n",
    "    \n",
    "    batchsize, featdim = imgsfc7.size()\n",
    "    batchsize_cap = batchsize*ncap_per_img\n",
    "    imgsfc7 = imgsfc7.unsqueeze(1).expand(batchsize, ncap_per_img, featdim)\n",
    "    imgsfc7 = imgsfc7.contiguous().view(batchsize_cap, featdim)\n",
    "    \n",
    "    return imgsfeats, imgsfc7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68b32322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1191667",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   for epoch in range(args.epochs):\n",
    "# 코드가 잘 돌아가는지 확인하기 위해 2번만 돌려봤습니다. 전 30(args.epochs)번 돌렸습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "928d1dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dbwls\\anaconda3\\envs\\clipcap\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "  0%|                                                                                        | 0/5664 [00:00<?, ?it/s]D:\\ComputerVisionImageCaptioning\\convcap-master\\convcap.py:49: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(x.view(sz[0] * sz[1], sz[2]))\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 5664/5664 [1:09:18<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Training epoch 0 has loss 4.989432\n",
      "Loading annotation file...\n",
      "Found 5000 images in split: val\n",
      "[DEBUG] #words in wordlist: 9221\n",
      "[DEBUG] Loading val data ... 4.182087 secs\n",
      "[DEBUG] Running inference on val with 250 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/250 [00:00<?, ?it/s]D:\\ComputerVisionImageCaptioning\\convcap-master\\test.py:91: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  wordprobs = F.softmax(wordact_t).cpu().data.numpy()\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 250/250 [01:22<00:00,  3.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.67s)\n",
      "creating index...\n",
      "index created!\n",
      "Using 5000/5000 predictions\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 46222, 'reflen': 46534, 'guess': [46222, 41222, 36222, 31222], 'correct': [30415, 13423, 4919, 1742]}\n",
      "ratio: 0.9932952249967553\n",
      "Bleu_1: 0.654\n",
      "Bleu_2: 0.460\n",
      "Bleu_3: 0.306\n",
      "Bleu_4: 0.199\n",
      "computing METEOR score...\n",
      "METEOR: 0.198\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.466\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.604\n",
      "computing SPICE score...\n",
      "SPICE: 0.127\n",
      "[DEBUG] Saving model at epoch 0 with CIDEr score of 0.603762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 5664/5664 [36:59<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Training epoch 1 has loss 3.724845\n",
      "Loading annotation file...\n",
      "Found 5000 images in split: val\n",
      "[DEBUG] #words in wordlist: 9221\n",
      "[DEBUG] Loading val data ... 3.537999 secs\n",
      "[DEBUG] Running inference on val with 250 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 250/250 [01:21<00:00,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.25s)\n",
      "creating index...\n",
      "index created!\n",
      "Using 5000/5000 predictions\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 47486, 'reflen': 47432, 'guess': [47486, 42486, 37486, 32486], 'correct': [32221, 15023, 6005, 2320]}\n",
      "ratio: 1.0011384719176717\n",
      "Bleu_1: 0.679\n",
      "Bleu_2: 0.490\n",
      "Bleu_3: 0.337\n",
      "Bleu_4: 0.229\n",
      "computing METEOR score...\n",
      "METEOR: 0.218\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.488\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.725\n",
      "computing SPICE score...\n",
      "SPICE: 0.149\n",
      "[DEBUG] Saving model at epoch 1 with CIDEr score of 0.725487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 5664/5664 [36:59<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Training epoch 2 has loss 3.459597\n",
      "Loading annotation file...\n",
      "Found 5000 images in split: val\n",
      "[DEBUG] #words in wordlist: 9221\n",
      "[DEBUG] Loading val data ... 4.454183 secs\n",
      "[DEBUG] Running inference on val with 250 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 250/250 [01:20<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.24s)\n",
      "creating index...\n",
      "index created!\n",
      "Using 5000/5000 predictions\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 47538, 'reflen': 47419, 'guess': [47538, 42538, 37538, 32538], 'correct': [32941, 15787, 6344, 2527]}\n",
      "ratio: 1.0025095425883928\n",
      "Bleu_1: 0.693\n",
      "Bleu_2: 0.507\n",
      "Bleu_3: 0.352\n",
      "Bleu_4: 0.241\n",
      "computing METEOR score...\n",
      "METEOR: 0.221\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.497\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.762\n",
      "computing SPICE score...\n",
      "SPICE: 0.155\n",
      "[DEBUG] Saving model at epoch 2 with CIDEr score of 0.761757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 5664/5664 [36:59<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Training epoch 3 has loss 3.321762\n",
      "Loading annotation file...\n",
      "Found 5000 images in split: val\n",
      "[DEBUG] #words in wordlist: 9221\n",
      "[DEBUG] Loading val data ... 3.544999 secs\n",
      "[DEBUG] Running inference on val with 250 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 250/250 [01:20<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.25s)\n",
      "creating index...\n",
      "index created!\n",
      "Using 5000/5000 predictions\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 48149, 'reflen': 47760, 'guess': [48149, 43149, 38149, 33149], 'correct': [33573, 16562, 7046, 2952]}\n",
      "ratio: 1.008144891122257\n",
      "Bleu_1: 0.697\n",
      "Bleu_2: 0.517\n",
      "Bleu_3: 0.367\n",
      "Bleu_4: 0.258\n",
      "computing METEOR score...\n",
      "METEOR: 0.233\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.506\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.819\n",
      "computing SPICE score...\n",
      "SPICE: 0.163\n",
      "[DEBUG] Saving model at epoch 3 with CIDEr score of 0.818592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 5664/5664 [37:00<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Training epoch 4 has loss 3.228324\n",
      "Loading annotation file...\n",
      "Found 5000 images in split: val\n",
      "[DEBUG] #words in wordlist: 9221\n",
      "[DEBUG] Loading val data ... 4.482045 secs\n",
      "[DEBUG] Running inference on val with 250 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 250/250 [01:20<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.24s)\n",
      "creating index...\n",
      "index created!\n",
      "Using 5000/5000 predictions\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 47018, 'reflen': 47036, 'guess': [47018, 42018, 37018, 32018], 'correct': [33027, 16301, 6879, 2866]}\n",
      "ratio: 0.9996173143974616\n",
      "Bleu_1: 0.702\n",
      "Bleu_2: 0.522\n",
      "Bleu_3: 0.370\n",
      "Bleu_4: 0.259\n",
      "computing METEOR score...\n",
      "METEOR: 0.230\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.506\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.822\n",
      "computing SPICE score...\n",
      "SPICE: 0.161\n",
      "[DEBUG] Saving model at epoch 4 with CIDEr score of 0.821711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 5664/5664 [36:53<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Training epoch 5 has loss 3.157045\n",
      "Loading annotation file...\n",
      "Found 5000 images in split: val\n",
      "[DEBUG] #words in wordlist: 9221\n",
      "[DEBUG] Loading val data ... 3.542176 secs\n",
      "[DEBUG] Running inference on val with 250 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 250/250 [01:20<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.25s)\n",
      "creating index...\n",
      "index created!\n",
      "Using 5000/5000 predictions\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 46962, 'reflen': 46945, 'guess': [46962, 41962, 36962, 31962], 'correct': [33265, 16498, 7132, 3078]}\n",
      "ratio: 1.0003621258919801\n",
      "Bleu_1: 0.708\n",
      "Bleu_2: 0.528\n",
      "Bleu_3: 0.377\n",
      "Bleu_4: 0.268\n",
      "computing METEOR score...\n",
      "METEOR: 0.233\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.508\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.842\n",
      "computing SPICE score...\n",
      "SPICE: 0.164\n",
      "[DEBUG] Saving model at epoch 5 with CIDEr score of 0.842000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 5664/5664 [37:09<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Training epoch 6 has loss 3.100183\n",
      "Loading annotation file...\n",
      "Found 5000 images in split: val\n",
      "[DEBUG] #words in wordlist: 9221\n",
      "[DEBUG] Loading val data ... 4.523999 secs\n",
      "[DEBUG] Running inference on val with 250 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 250/250 [01:20<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.24s)\n",
      "creating index...\n",
      "index created!\n",
      "Using 5000/5000 predictions\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 47077, 'reflen': 47053, 'guess': [47077, 42077, 37077, 32077], 'correct': [33688, 16835, 7278, 3072]}\n",
      "ratio: 1.00051006312029\n",
      "Bleu_1: 0.716\n",
      "Bleu_2: 0.535\n",
      "Bleu_3: 0.383\n",
      "Bleu_4: 0.271\n",
      "computing METEOR score...\n",
      "METEOR: 0.236\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.513\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.860\n",
      "computing SPICE score...\n",
      "SPICE: 0.169\n",
      "[DEBUG] Saving model at epoch 6 with CIDEr score of 0.860355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 5664/5664 [37:09<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Training epoch 7 has loss 3.051425\n",
      "Loading annotation file...\n",
      "Found 5000 images in split: val\n",
      "[DEBUG] #words in wordlist: 9221\n",
      "[DEBUG] Loading val data ... 3.603192 secs\n",
      "[DEBUG] Running inference on val with 250 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 250/250 [01:20<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.24s)\n",
      "creating index...\n",
      "index created!\n",
      "Using 5000/5000 predictions\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 47715, 'reflen': 47546, 'guess': [47715, 42715, 37715, 32715], 'correct': [33578, 16779, 7214, 3080]}\n",
      "ratio: 1.0035544525301603\n",
      "Bleu_1: 0.704\n",
      "Bleu_2: 0.526\n",
      "Bleu_3: 0.375\n",
      "Bleu_4: 0.266\n",
      "computing METEOR score...\n",
      "METEOR: 0.236\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.509\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.854\n",
      "computing SPICE score...\n",
      "SPICE: 0.166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 5664/5664 [37:03<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Training epoch 8 has loss 3.009316\n",
      "Loading annotation file...\n",
      "Found 5000 images in split: val\n",
      "[DEBUG] #words in wordlist: 9221\n",
      "[DEBUG] Loading val data ... 4.599041 secs\n",
      "[DEBUG] Running inference on val with 250 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 250/250 [01:20<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.25s)\n",
      "creating index...\n",
      "index created!\n",
      "Using 5000/5000 predictions\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 47894, 'reflen': 47625, 'guess': [47894, 42894, 37894, 32894], 'correct': [34035, 17171, 7512, 3248]}\n",
      "ratio: 1.0056482939632336\n",
      "Bleu_1: 0.711\n",
      "Bleu_2: 0.533\n",
      "Bleu_3: 0.383\n",
      "Bleu_4: 0.273\n",
      "computing METEOR score...\n",
      "METEOR: 0.240\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.516\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.869\n",
      "computing SPICE score...\n",
      "SPICE: 0.170\n",
      "[DEBUG] Saving model at epoch 8 with CIDEr score of 0.869287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 5664/5664 [37:13<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Training epoch 9 has loss 2.969102\n",
      "Loading annotation file...\n",
      "Found 5000 images in split: val\n",
      "[DEBUG] #words in wordlist: 9221\n",
      "[DEBUG] Loading val data ... 3.657043 secs\n",
      "[DEBUG] Running inference on val with 250 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 250/250 [01:20<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.24s)\n",
      "creating index...\n",
      "index created!\n",
      "Using 5000/5000 predictions\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 47521, 'reflen': 47315, 'guess': [47521, 42521, 37521, 32521], 'correct': [33799, 16934, 7545, 3348]}\n",
      "ratio: 1.0043537990066362\n",
      "Bleu_1: 0.711\n",
      "Bleu_2: 0.532\n",
      "Bleu_3: 0.385\n",
      "Bleu_4: 0.277\n",
      "computing METEOR score...\n",
      "METEOR: 0.240\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.515\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.884\n",
      "computing SPICE score...\n",
      "SPICE: 0.170\n",
      "[DEBUG] Saving model at epoch 9 with CIDEr score of 0.884008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 5664/5664 [37:05<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Training epoch 10 has loss 2.933248\n",
      "Loading annotation file...\n",
      "Found 5000 images in split: val\n",
      "[DEBUG] #words in wordlist: 9221\n",
      "[DEBUG] Loading val data ... 4.398000 secs\n",
      "[DEBUG] Running inference on val with 250 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 250/250 [01:20<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.25s)\n",
      "creating index...\n",
      "index created!\n",
      "Using 5000/5000 predictions\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 48496, 'reflen': 48028, 'guess': [48496, 43496, 38496, 33496], 'correct': [34260, 17140, 7606, 3360]}\n",
      "ratio: 1.009744315815753\n",
      "Bleu_1: 0.706\n",
      "Bleu_2: 0.528\n",
      "Bleu_3: 0.380\n",
      "Bleu_4: 0.273\n",
      "computing METEOR score...\n",
      "METEOR: 0.243\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.517\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.883\n",
      "computing SPICE score...\n",
      "SPICE: 0.172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 5664/5664 [37:16<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Training epoch 11 has loss 2.898622\n",
      "Loading annotation file...\n",
      "Found 5000 images in split: val\n",
      "[DEBUG] #words in wordlist: 9221\n",
      "[DEBUG] Loading val data ... 4.452576 secs\n",
      "[DEBUG] Running inference on val with 250 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 250/250 [01:20<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.24s)\n",
      "creating index...\n",
      "index created!\n",
      "Using 5000/5000 predictions\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 48313, 'reflen': 47919, 'guess': [48313, 43313, 38313, 33313], 'correct': [34140, 17316, 7822, 3534]}\n",
      "ratio: 1.0082222083098353\n",
      "Bleu_1: 0.707\n",
      "Bleu_2: 0.532\n",
      "Bleu_3: 0.386\n",
      "Bleu_4: 0.280\n",
      "computing METEOR score...\n",
      "METEOR: 0.242\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.518\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.887\n",
      "computing SPICE score...\n",
      "SPICE: 0.173\n",
      "[DEBUG] Saving model at epoch 11 with CIDEr score of 0.886847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 5664/5664 [37:04<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Training epoch 12 has loss 2.865029\n",
      "Loading annotation file...\n",
      "Found 5000 images in split: val\n",
      "[DEBUG] #words in wordlist: 9221\n",
      "[DEBUG] Loading val data ... 4.506992 secs\n",
      "[DEBUG] Running inference on val with 250 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 250/250 [01:20<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.24s)\n",
      "creating index...\n",
      "index created!\n",
      "Using 5000/5000 predictions\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 48492, 'reflen': 48046, 'guess': [48492, 43492, 38492, 33492], 'correct': [34530, 17392, 7652, 3295]}\n",
      "ratio: 1.0092827706780791\n",
      "Bleu_1: 0.712\n",
      "Bleu_2: 0.534\n",
      "Bleu_3: 0.384\n",
      "Bleu_4: 0.273\n",
      "computing METEOR score...\n",
      "METEOR: 0.242\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.520\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.888\n",
      "computing SPICE score...\n",
      "SPICE: 0.171\n",
      "[DEBUG] Saving model at epoch 12 with CIDEr score of 0.888330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 5664/5664 [37:14<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Training epoch 13 has loss 2.831491\n",
      "Loading annotation file...\n",
      "Found 5000 images in split: val\n",
      "[DEBUG] #words in wordlist: 9221\n",
      "[DEBUG] Loading val data ... 4.580999 secs\n",
      "[DEBUG] Running inference on val with 250 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 250/250 [01:20<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.25s)\n",
      "creating index...\n",
      "index created!\n",
      "Using 5000/5000 predictions\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 48273, 'reflen': 47908, 'guess': [48273, 43273, 38273, 33273], 'correct': [34289, 17457, 7701, 3384]}\n",
      "ratio: 1.0076187693078191\n",
      "Bleu_1: 0.710\n",
      "Bleu_2: 0.535\n",
      "Bleu_3: 0.386\n",
      "Bleu_4: 0.277\n",
      "computing METEOR score...\n",
      "METEOR: 0.242\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.518\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.888\n",
      "computing SPICE score...\n",
      "SPICE: 0.173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 5664/5664 [37:09<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Training epoch 14 has loss 2.711402\n",
      "Loading annotation file...\n",
      "Found 5000 images in split: val\n",
      "[DEBUG] #words in wordlist: 9221\n",
      "[DEBUG] Loading val data ... 3.643136 secs\n",
      "[DEBUG] Running inference on val with 250 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 250/250 [01:20<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.25s)\n",
      "creating index...\n",
      "index created!\n",
      "Using 5000/5000 predictions\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 48181, 'reflen': 47831, 'guess': [48181, 43181, 38181, 33181], 'correct': [34602, 17802, 8103, 3692]}\n",
      "ratio: 1.0073174301185215\n",
      "Bleu_1: 0.718\n",
      "Bleu_2: 0.544\n",
      "Bleu_3: 0.398\n",
      "Bleu_4: 0.289\n",
      "computing METEOR score...\n",
      "METEOR: 0.248\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.526\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.932\n",
      "computing SPICE score...\n",
      "SPICE: 0.178\n",
      "[DEBUG] Saving model at epoch 14 with CIDEr score of 0.931870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 5664/5664 [37:07<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Training epoch 15 has loss 2.687235\n",
      "Loading annotation file...\n",
      "Found 5000 images in split: val\n",
      "[DEBUG] #words in wordlist: 9221\n",
      "[DEBUG] Loading val data ... 4.386000 secs\n",
      "[DEBUG] Running inference on val with 250 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 250/250 [01:20<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.24s)\n",
      "creating index...\n",
      "index created!\n",
      "Using 5000/5000 predictions\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 48433, 'reflen': 48038, 'guess': [48433, 43433, 38433, 33433], 'correct': [34620, 17866, 8129, 3748]}\n",
      "ratio: 1.0082226570631374\n",
      "Bleu_1: 0.715\n",
      "Bleu_2: 0.542\n",
      "Bleu_3: 0.396\n",
      "Bleu_4: 0.289\n",
      "computing METEOR score...\n",
      "METEOR: 0.248\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.525\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.931\n",
      "computing SPICE score...\n",
      "SPICE: 0.178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 5664/5664 [37:15<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Training epoch 16 has loss 2.674812\n",
      "Loading annotation file...\n",
      "Found 5000 images in split: val\n",
      "[DEBUG] #words in wordlist: 9221\n",
      "[DEBUG] Loading val data ... 4.415999 secs\n",
      "[DEBUG] Running inference on val with 250 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 250/250 [01:20<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.24s)\n",
      "creating index...\n",
      "index created!\n",
      "Using 5000/5000 predictions\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 48396, 'reflen': 48055, 'guess': [48396, 43396, 38396, 33396], 'correct': [34640, 17905, 8187, 3749]}\n",
      "ratio: 1.0070960357923004\n",
      "Bleu_1: 0.716\n",
      "Bleu_2: 0.543\n",
      "Bleu_3: 0.398\n",
      "Bleu_4: 0.290\n",
      "computing METEOR score...\n",
      "METEOR: 0.249\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.527\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.934\n",
      "computing SPICE score...\n",
      "SPICE: 0.178\n",
      "[DEBUG] Saving model at epoch 16 with CIDEr score of 0.933553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 5664/5664 [37:11<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Training epoch 17 has loss 2.664922\n",
      "Loading annotation file...\n",
      "Found 5000 images in split: val\n",
      "[DEBUG] #words in wordlist: 9221\n",
      "[DEBUG] Loading val data ... 4.413039 secs\n",
      "[DEBUG] Running inference on val with 250 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 250/250 [01:20<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.24s)\n",
      "creating index...\n",
      "index created!\n",
      "Using 5000/5000 predictions\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 48190, 'reflen': 47864, 'guess': [48190, 43190, 38190, 33190], 'correct': [34567, 17773, 8078, 3648]}\n",
      "ratio: 1.0068109643991099\n",
      "Bleu_1: 0.717\n",
      "Bleu_2: 0.543\n",
      "Bleu_3: 0.397\n",
      "Bleu_4: 0.288\n",
      "computing METEOR score...\n",
      "METEOR: 0.247\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.526\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.925\n",
      "computing SPICE score...\n",
      "SPICE: 0.177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 5664/5664 [37:12<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Training epoch 18 has loss 2.655495\n",
      "Loading annotation file...\n",
      "Found 5000 images in split: val\n",
      "[DEBUG] #words in wordlist: 9221\n",
      "[DEBUG] Loading val data ... 4.495003 secs\n",
      "[DEBUG] Running inference on val with 250 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 250/250 [01:20<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.24s)\n",
      "creating index...\n",
      "index created!\n",
      "Using 5000/5000 predictions\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 48418, 'reflen': 48040, 'guess': [48418, 43418, 38418, 33418], 'correct': [34670, 17955, 8258, 3838]}\n",
      "ratio: 1.0078684429641755\n",
      "Bleu_1: 0.716\n",
      "Bleu_2: 0.544\n",
      "Bleu_3: 0.399\n",
      "Bleu_4: 0.292\n",
      "computing METEOR score...\n",
      "METEOR: 0.250\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.529\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.938\n",
      "computing SPICE score...\n",
      "SPICE: 0.178\n",
      "[DEBUG] Saving model at epoch 18 with CIDEr score of 0.937585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 5664/5664 [37:17<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Training epoch 19 has loss 2.645840\n",
      "Loading annotation file...\n",
      "Found 5000 images in split: val\n",
      "[DEBUG] #words in wordlist: 9221\n",
      "[DEBUG] Loading val data ... 3.607000 secs\n",
      "[DEBUG] Running inference on val with 250 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 250/250 [01:20<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.25s)\n",
      "creating index...\n",
      "index created!\n",
      "Using 5000/5000 predictions\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 48176, 'reflen': 47877, 'guess': [48176, 43176, 38176, 33176], 'correct': [34580, 17862, 8185, 3762]}\n",
      "ratio: 1.0062451699145518\n",
      "Bleu_1: 0.718\n",
      "Bleu_2: 0.545\n",
      "Bleu_3: 0.399\n",
      "Bleu_4: 0.291\n",
      "computing METEOR score...\n",
      "METEOR: 0.249\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.527\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.932\n",
      "computing SPICE score...\n",
      "SPICE: 0.178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 5664/5664 [37:09<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Training epoch 20 has loss 2.638928\n",
      "Loading annotation file...\n",
      "Found 5000 images in split: val\n",
      "[DEBUG] #words in wordlist: 9221\n",
      "[DEBUG] Loading val data ... 4.280002 secs\n",
      "[DEBUG] Running inference on val with 250 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 250/250 [01:20<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.25s)\n",
      "creating index...\n",
      "index created!\n",
      "Using 5000/5000 predictions\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 48567, 'reflen': 48134, 'guess': [48567, 43567, 38567, 33567], 'correct': [34721, 17812, 8107, 3720]}\n",
      "ratio: 1.0089957202808617\n",
      "Bleu_1: 0.715\n",
      "Bleu_2: 0.541\n",
      "Bleu_3: 0.395\n",
      "Bleu_4: 0.287\n",
      "computing METEOR score...\n",
      "METEOR: 0.249\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.525\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.927\n",
      "computing SPICE score...\n",
      "SPICE: 0.178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 5664/5664 [37:18<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Training epoch 21 has loss 2.631627\n",
      "Loading annotation file...\n",
      "Found 5000 images in split: val\n",
      "[DEBUG] #words in wordlist: 9221\n",
      "[DEBUG] Loading val data ... 3.519216 secs\n",
      "[DEBUG] Running inference on val with 250 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 250/250 [01:20<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.24s)\n",
      "creating index...\n",
      "index created!\n",
      "Using 5000/5000 predictions\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 48340, 'reflen': 47989, 'guess': [48340, 43340, 38340, 33340], 'correct': [34554, 17842, 8149, 3733]}\n",
      "ratio: 1.0073141761653504\n",
      "Bleu_1: 0.715\n",
      "Bleu_2: 0.542\n",
      "Bleu_3: 0.397\n",
      "Bleu_4: 0.289\n",
      "computing METEOR score...\n",
      "METEOR: 0.249\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.526\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.927\n",
      "computing SPICE score...\n",
      "SPICE: 0.177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 5664/5664 [37:16<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Training epoch 22 has loss 2.624597\n",
      "Loading annotation file...\n",
      "Found 5000 images in split: val\n",
      "[DEBUG] #words in wordlist: 9221\n",
      "[DEBUG] Loading val data ... 4.507088 secs\n",
      "[DEBUG] Running inference on val with 250 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 250/250 [01:20<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.25s)\n",
      "creating index...\n",
      "index created!\n",
      "Using 5000/5000 predictions\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 48465, 'reflen': 48107, 'guess': [48465, 43465, 38465, 33465], 'correct': [34575, 17817, 8175, 3733]}\n",
      "ratio: 1.0074417444446546\n",
      "Bleu_1: 0.713\n",
      "Bleu_2: 0.541\n",
      "Bleu_3: 0.396\n",
      "Bleu_4: 0.289\n",
      "computing METEOR score...\n",
      "METEOR: 0.249\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.525\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.927\n",
      "computing SPICE score...\n",
      "SPICE: 0.177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 5664/5664 [37:06<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Training epoch 23 has loss 2.617305\n",
      "Loading annotation file...\n",
      "Found 5000 images in split: val\n",
      "[DEBUG] #words in wordlist: 9221\n",
      "[DEBUG] Loading val data ... 3.508161 secs\n",
      "[DEBUG] Running inference on val with 250 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 250/250 [01:20<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.24s)\n",
      "creating index...\n",
      "index created!\n",
      "Using 5000/5000 predictions\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 48487, 'reflen': 48094, 'guess': [48487, 43487, 38487, 33487], 'correct': [34567, 17798, 8149, 3732]}\n",
      "ratio: 1.0081714974840728\n",
      "Bleu_1: 0.713\n",
      "Bleu_2: 0.540\n",
      "Bleu_3: 0.395\n",
      "Bleu_4: 0.288\n",
      "computing METEOR score...\n",
      "METEOR: 0.248\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.526\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.926\n",
      "computing SPICE score...\n",
      "SPICE: 0.177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 5664/5664 [37:12<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Training epoch 24 has loss 2.610523\n",
      "Loading annotation file...\n",
      "Found 5000 images in split: val\n",
      "[DEBUG] #words in wordlist: 9221\n",
      "[DEBUG] Loading val data ... 4.502084 secs\n",
      "[DEBUG] Running inference on val with 250 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 250/250 [01:20<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.24s)\n",
      "creating index...\n",
      "index created!\n",
      "Using 5000/5000 predictions\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 48230, 'reflen': 47856, 'guess': [48230, 43230, 38230, 33230], 'correct': [34344, 17554, 7991, 3664]}\n",
      "ratio: 1.0078151120026537\n",
      "Bleu_1: 0.712\n",
      "Bleu_2: 0.538\n",
      "Bleu_3: 0.392\n",
      "Bleu_4: 0.286\n",
      "computing METEOR score...\n",
      "METEOR: 0.247\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.523\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.921\n",
      "computing SPICE score...\n",
      "SPICE: 0.177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 5664/5664 [36:58<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Training epoch 25 has loss 2.603060\n",
      "Loading annotation file...\n",
      "Found 5000 images in split: val\n",
      "[DEBUG] #words in wordlist: 9221\n",
      "[DEBUG] Loading val data ... 3.602592 secs\n",
      "[DEBUG] Running inference on val with 250 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 250/250 [01:20<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.25s)\n",
      "creating index...\n",
      "index created!\n",
      "Using 5000/5000 predictions\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 48490, 'reflen': 48140, 'guess': [48490, 43490, 38490, 33490], 'correct': [34468, 17592, 7973, 3630]}\n",
      "ratio: 1.007270461154944\n",
      "Bleu_1: 0.711\n",
      "Bleu_2: 0.536\n",
      "Bleu_3: 0.391\n",
      "Bleu_4: 0.283\n",
      "computing METEOR score...\n",
      "METEOR: 0.248\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.523\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.919\n",
      "computing SPICE score...\n",
      "SPICE: 0.176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 5664/5664 [36:50<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Training epoch 26 has loss 2.596197\n",
      "Loading annotation file...\n",
      "Found 5000 images in split: val\n",
      "[DEBUG] #words in wordlist: 9221\n",
      "[DEBUG] Loading val data ... 4.559343 secs\n",
      "[DEBUG] Running inference on val with 250 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 250/250 [01:20<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.25s)\n",
      "creating index...\n",
      "index created!\n",
      "Using 5000/5000 predictions\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 48538, 'reflen': 48149, 'guess': [48538, 43538, 38538, 33538], 'correct': [34693, 17925, 8218, 3773]}\n",
      "ratio: 1.008079087831502\n",
      "Bleu_1: 0.715\n",
      "Bleu_2: 0.542\n",
      "Bleu_3: 0.397\n",
      "Bleu_4: 0.290\n",
      "computing METEOR score...\n",
      "METEOR: 0.250\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.526\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.930\n",
      "computing SPICE score...\n",
      "SPICE: 0.178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 5664/5664 [36:50<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Training epoch 27 has loss 2.589466\n",
      "Loading annotation file...\n",
      "Found 5000 images in split: val\n",
      "[DEBUG] #words in wordlist: 9221\n",
      "[DEBUG] Loading val data ... 3.594564 secs\n",
      "[DEBUG] Running inference on val with 250 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 250/250 [01:20<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.24s)\n",
      "creating index...\n",
      "index created!\n",
      "Using 5000/5000 predictions\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 48748, 'reflen': 48283, 'guess': [48748, 43748, 38748, 33748], 'correct': [34596, 17805, 8149, 3752]}\n",
      "ratio: 1.0096307188865439\n",
      "Bleu_1: 0.710\n",
      "Bleu_2: 0.537\n",
      "Bleu_3: 0.393\n",
      "Bleu_4: 0.287\n",
      "computing METEOR score...\n",
      "METEOR: 0.249\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.524\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.926\n",
      "computing SPICE score...\n",
      "SPICE: 0.178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 5664/5664 [36:57<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Training epoch 28 has loss 2.582845\n",
      "Loading annotation file...\n",
      "Found 5000 images in split: val\n",
      "[DEBUG] #words in wordlist: 9221\n",
      "[DEBUG] Loading val data ... 4.526001 secs\n",
      "[DEBUG] Running inference on val with 250 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 250/250 [01:20<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.25s)\n",
      "creating index...\n",
      "index created!\n",
      "Using 5000/5000 predictions\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 48702, 'reflen': 48265, 'guess': [48702, 43702, 38702, 33702], 'correct': [34702, 17900, 8197, 3758]}\n",
      "ratio: 1.0090541800476327\n",
      "Bleu_1: 0.713\n",
      "Bleu_2: 0.540\n",
      "Bleu_3: 0.395\n",
      "Bleu_4: 0.288\n",
      "computing METEOR score...\n",
      "METEOR: 0.249\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.526\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.924\n",
      "computing SPICE score...\n",
      "SPICE: 0.177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 5664/5664 [36:48<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Training epoch 29 has loss 2.564430\n",
      "Loading annotation file...\n",
      "Found 5000 images in split: val\n",
      "[DEBUG] #words in wordlist: 9221\n",
      "[DEBUG] Loading val data ... 3.603759 secs\n",
      "[DEBUG] Running inference on val with 250 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 250/250 [01:20<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.25s)\n",
      "creating index...\n",
      "index created!\n",
      "Using 5000/5000 predictions\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 48493, 'reflen': 48097, 'guess': [48493, 43493, 38493, 33493], 'correct': [34647, 17882, 8141, 3718]}\n",
      "ratio: 1.0082333617481132\n",
      "Bleu_1: 0.714\n",
      "Bleu_2: 0.542\n",
      "Bleu_3: 0.396\n",
      "Bleu_4: 0.288\n",
      "computing METEOR score...\n",
      "METEOR: 0.249\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.526\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.927\n",
      "computing SPICE score...\n",
      "SPICE: 0.178\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(args.epochs): \n",
    "    loss_train = 0.\n",
    "    \n",
    "#     if(epoch == args.finetune_after):\n",
    "#         img_optimizer = optim.RMSprop(model_imgcnn.parameters(), lr=1e-5)\n",
    "#         img_scheduler = lr_scheduler.StepLR(img_optimizer, step_size=args.lr_step_size, gamma=.1)\n",
    "\n",
    "    scheduler.step()    \n",
    "#     if(img_optimizer):\n",
    "#         img_scheduler.step()\n",
    "\n",
    "    #One epoch of train\n",
    "    for batch_idx, (imgs, captions, wordclass, mask, _) in \\\n",
    "      tqdm(enumerate(train_data_loader), total=nbatches):\n",
    "        \n",
    "        imgs = imgs.view(batchsize, 3, 224, 224)\n",
    "        wordclass = wordclass.view(batchsize_cap, max_tokens)\n",
    "        mask = mask.view(batchsize_cap, max_tokens)\n",
    "\n",
    "        imgs_v = Variable(imgs).cuda()\n",
    "        wordclass_v = Variable(wordclass).cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "#         if(img_optimizer):\n",
    "#             img_optimizer.zero_grad() \n",
    "\n",
    "        imgsfeats, imgsfc7 = model.encode_image(imgs_v)\n",
    "        imgsfeats, imgsfc7 = repeat_img_per_cap(imgsfeats, imgsfc7, ncap_per_img)\n",
    "        _, _, feat_h, feat_w = imgsfeats.size()\n",
    "\n",
    "        if(args.attention == True):\n",
    "            wordact, attn = model_convcap(imgsfeats.float(), imgsfc7.float(), wordclass_v)\n",
    "            attn = attn.view(batchsize_cap, max_tokens, feat_h, feat_w)\n",
    "        else:\n",
    "            wordact, _ = model_convcap(imgsfeats, imgsfc7, wordclass_v)\n",
    "\n",
    "        wordact = wordact[:,:,:-1]\n",
    "        wordclass_v = wordclass_v[:,1:]\n",
    "        mask = mask[:,1:].contiguous()\n",
    "\n",
    "        wordact_t = wordact.permute(0, 2, 1).contiguous().view(batchsize_cap*(max_tokens-1), -1)\n",
    "        wordclass_t = wordclass_v.contiguous().view(batchsize_cap*(max_tokens-1), 1)\n",
    "      \n",
    "        maskids = torch.nonzero(mask.view(-1)).numpy().reshape(-1)\n",
    "\n",
    "        if(args.attention == True):\n",
    "            #Cross-entropy loss and attention loss of Show, Attend and Tell\n",
    "            loss = F.cross_entropy(wordact_t[maskids, ...], \\\n",
    "                                   wordclass_t[maskids, ...].contiguous().view(maskids.shape[0])) \\\n",
    "            + (torch.sum(torch.pow(1. - torch.sum(attn, 1), 2)))\\\n",
    "            /(batchsize_cap*feat_h*feat_w)\n",
    "        else:\n",
    "            loss = F.cross_entropy(wordact_t[maskids, ...], \\\n",
    "                                   wordclass_t[maskids, ...].contiguous().view(maskids.shape[0]))\n",
    "\n",
    "        loss_train = loss_train + loss.data\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "#         if(img_optimizer):\n",
    "#             img_optimizer.step()\n",
    "\n",
    "    loss_train = (loss_train*1.)/(batch_idx)\n",
    "    print('[DEBUG] Training epoch %d has loss %f' % (epoch, loss_train))\n",
    "\n",
    "    modelfn = osp.join(args.model_dir, 'model.pth')\n",
    "\n",
    "#     if(img_optimizer):\n",
    "#         img_optimizer_dict = img_optimizer.state_dict()\n",
    "#     else:\n",
    "#         img_optimizer_dict = None\n",
    "\n",
    "    torch.save({\n",
    "          'epoch': epoch,\n",
    "          'state_dict': model_convcap.state_dict(),\n",
    "#           'img_state_dict': model.encode_image.state_dict(),\n",
    "          'optimizer' : optimizer.state_dict(),\n",
    "#           'img_optimizer' : img_optimizer_dict,\n",
    "    }, modelfn)\n",
    "\n",
    "    #Run on validation and obtain score\n",
    "    scores = test(args, 'val', model_convcap=model_convcap, model_imgcnn=model)\n",
    "    score = scores[0][args.score_select]\n",
    "\n",
    "    if(score > bestscore):\n",
    "        bestscore = score\n",
    "        print('[DEBUG] Saving model at epoch %d with %s score of %f'\\\n",
    "          % (epoch, args.score_select, score))\n",
    "        bestmodelfn = osp.join(args.model_dir, 'bestmodel.pth')\n",
    "        os.system('cp %s %s' % (modelfn, bestmodelfn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc1537b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fe42a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d18bf18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6c4c8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58892dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb8d93e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2651c7c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80b454a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd619526",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1305cf5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397b9342",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2539bab4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a351ad43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d1eb3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13bd78c8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dbwls\\anaconda3\\envs\\tlqkf\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "  0%|                                                                                        | 0/5664 [00:00<?, ?it/s]D:\\CVclass\\convcap-master\\convcap-master\\convcap.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(x.view(sz[0] * sz[1], sz[2]))\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 5664/5664 [1:58:56<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Training epoch 0 has loss 7.425636\n",
      "Loading annotation file...\n",
      "Found 5000 images in split: val\n",
      "[DEBUG] #words in wordlist: 9221\n",
      "[DEBUG] Loading val data ... 5.809345 secs\n",
      "[DEBUG] Running inference on val with 250 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/250 [00:00<?, ?it/s]D:\\CVclass\\convcap-master\\convcap-master\\test.py:87: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  wordprobs = F.softmax(wordact_t).cpu().data.numpy()\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 250/250 [01:17<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.54s)\n",
      "creating index...\n",
      "index created!\n",
      "Using 5000/5000 predictions\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "Downloading stanford-corenlp-3.6.0 for SPICE ...\n",
      "Progress: 384.5M / 384.5M (100.0%)\n",
      "Extracting stanford-corenlp-3.6.0 ...\n",
      "Done.\n",
      "computing Bleu score...\n",
      "{'testlen': 43639, 'reflen': 44922, 'guess': [43639, 38639, 33639, 28639], 'correct': [24884, 8879, 2228, 471]}\n",
      "ratio: 0.9714393838208235\n",
      "Bleu_1: 0.554\n",
      "Bleu_2: 0.351\n",
      "Bleu_3: 0.200\n",
      "Bleu_4: 0.106\n",
      "computing METEOR score...\n",
      "METEOR: 0.148\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.410\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.303\n",
      "computing SPICE score...\n",
      "SPICE: 0.086\n",
      "[DEBUG] Saving model at epoch 0 with CIDEr score of 0.303493\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1): \n",
    "    loss_train = 0.\n",
    "    \n",
    "#     if(epoch == args.finetune_after):\n",
    "#         img_optimizer = optim.RMSprop(model_imgcnn.parameters(), lr=1e-5)\n",
    "#         img_scheduler = lr_scheduler.StepLR(img_optimizer, step_size=args.lr_step_size, gamma=.1)\n",
    "\n",
    "    scheduler.step()    \n",
    "#     if(img_optimizer):\n",
    "#         img_scheduler.step()\n",
    "\n",
    "    #One epoch of train\n",
    "    for batch_idx, (imgs, captions, wordclass, mask, _) in \\\n",
    "      tqdm(enumerate(train_data_loader), total=nbatches):\n",
    "        \n",
    "        imgs = imgs.view(batchsize, 3, 224, 224)\n",
    "        wordclass = wordclass.view(batchsize_cap, max_tokens)\n",
    "        mask = mask.view(batchsize_cap, max_tokens)\n",
    "\n",
    "        imgs_v = Variable(imgs).cuda()\n",
    "        wordclass_v = Variable(wordclass).cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "#         if(img_optimizer):\n",
    "#             img_optimizer.zero_grad() \n",
    "\n",
    "        imgsfeats, imgsfc7 = model.encode_image(imgs_v)\n",
    "        imgsfeats, imgsfc7 = repeat_img_per_cap(imgsfeats, imgsfc7, ncap_per_img)\n",
    "        _, _, feat_h, feat_w = imgsfeats.size()\n",
    "\n",
    "        if(args.attention == True):\n",
    "            wordact, attn = model_convcap(imgsfeats.float(), imgsfc7.float(), wordclass_v)\n",
    "            attn = attn.view(batchsize_cap, max_tokens, feat_h, feat_w)\n",
    "        else:\n",
    "            wordact, _ = model_convcap(imgsfeats, imgsfc7, wordclass_v)\n",
    "\n",
    "        wordact = wordact[:,:,:-1]\n",
    "        wordclass_v = wordclass_v[:,1:]\n",
    "        mask = mask[:,1:].contiguous()\n",
    "\n",
    "        wordact_t = wordact.permute(0, 2, 1).contiguous().view(batchsize_cap*(max_tokens-1), -1)\n",
    "        wordclass_t = wordclass_v.contiguous().view(batchsize_cap*(max_tokens-1), 1)\n",
    "      \n",
    "        maskids = torch.nonzero(mask.view(-1)).numpy().reshape(-1)\n",
    "\n",
    "        if(args.attention == True):\n",
    "            #Cross-entropy loss and attention loss of Show, Attend and Tell\n",
    "            loss = F.cross_entropy(wordact_t[maskids, ...], \\\n",
    "                                   wordclass_t[maskids, ...].contiguous().view(maskids.shape[0])) \\\n",
    "            + (torch.sum(torch.pow(1. - torch.sum(attn, 1), 2)))\\\n",
    "            /(batchsize_cap*feat_h*feat_w)\n",
    "        else:\n",
    "            loss = F.cross_entropy(wordact_t[maskids, ...], \\\n",
    "                                   wordclass_t[maskids, ...].contiguous().view(maskids.shape[0]))\n",
    "\n",
    "        loss_train = loss_train + loss.data\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "#         if(img_optimizer):\n",
    "#             img_optimizer.step()\n",
    "\n",
    "    loss_train = (loss_train*1.)/(batch_idx)\n",
    "    print('[DEBUG] Training epoch %d has loss %f' % (epoch, loss_train))\n",
    "\n",
    "    modelfn = osp.join(args.model_dir, 'model.pth')\n",
    "\n",
    "#     if(img_optimizer):\n",
    "#         img_optimizer_dict = img_optimizer.state_dict()\n",
    "#     else:\n",
    "#         img_optimizer_dict = None\n",
    "\n",
    "    torch.save({\n",
    "          'epoch': epoch,\n",
    "          'state_dict': model_convcap.state_dict(),\n",
    "          'img_state_dict': model_imgcnn.state_dict(),\n",
    "          'optimizer' : optimizer.state_dict(),\n",
    "#           'img_optimizer' : img_optimizer_dict,\n",
    "    }, modelfn)\n",
    "\n",
    "    #Run on validation and obtain score\n",
    "    scores = test(args, 'val', model_convcap=model_convcap, model_imgcnn=model_imgcnn)\n",
    "    score = scores[0][args.score_select]\n",
    "\n",
    "    if(score > bestscore):\n",
    "        bestscore = score\n",
    "        print('[DEBUG] Saving model at epoch %d with %s score of %f'\\\n",
    "          % (epoch, args.score_select, score))\n",
    "        bestmodelfn = osp.join(args.model_dir, 'bestmodel.pth')\n",
    "        os.system('cp %s %s' % (modelfn, bestmodelfn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7331abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestmodelfn = osp.join(args.model_dir, 'bestmodel.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2d82958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'output'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "da2d7e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "split='test'\n",
    "modelfn=bestmodelfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "67b89e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'third_party/coco-caption')\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path as osp\n",
    "from pycocotools.coco import COCO\n",
    "from pycocoevalcap.eval import COCOEvalCap\n",
    "import json\n",
    "from json import encoder\n",
    "encoder.FLOAT_REPR = lambda o: format(o, '.3f')\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6134197a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def language_eval(input_data, savedir, split):\n",
    "  if type(input_data) == str: # Filename given.\n",
    "    checkpoint = json.load(open(input_data, 'r'))\n",
    "    preds = checkpoint\n",
    "  elif type(input_data) == list: # Direct predictions give.\n",
    "    preds = input_data\n",
    "\n",
    "  annFile = 'third_party/coco-caption/annotations/captions_val2014.json'\n",
    "  coco = COCO(annFile)\n",
    "  valids = coco.getImgIds()\n",
    "\n",
    "  # Filter results to only those in MSCOCO validation set (will be about a third)\n",
    "  preds_filt = [p for p in preds if p['image_id'] in valids]\n",
    "  len_p = len(preds_filt)\n",
    "  for i in range(len_p):\n",
    "    preds_filt[i]['image_id'] = int(preds_filt[i]['image_id'])\n",
    "  print('Using %d/%d predictions' % (len(preds_filt), len(preds)))\n",
    "  resFile = osp.join(savedir, 'result_%s.json' % (split))\n",
    "  json.dump(preds_filt, open(resFile, 'w')) # Serialize to temporary json file. Sigh, COCO API...\n",
    "\n",
    "  cocoRes = coco.loadRes(resFile)\n",
    "  cocoEval = COCOEvalCap(coco, cocoRes)\n",
    "  cocoEval.params['image_id'] = cocoRes.getImgIds()\n",
    "  cocoEval.evaluate()\n",
    "\n",
    "  # Create output dictionary.\n",
    "  out = {}\n",
    "  for metric, score in cocoEval.eval.items():\n",
    "    out[metric] = score\n",
    "\n",
    "  # Return aggregate and per image score.\n",
    "  return out, cocoEval.evalImgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "19f5b658",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data, savedir, split = pred_captions, args.model_dir, split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "80f4833a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.25s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 5000/5000 [11:58<00:00,  6.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 5000/5000 predictions\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 48522, 'reflen': 48024, 'guess': [48522, 43522, 38522, 33522], 'correct': [34648, 17877, 8138, 3641]}\n",
      "ratio: 1.0103698150924327\n",
      "Bleu_1: 0.714\n",
      "Bleu_2: 0.542\n",
      "Bleu_3: 0.396\n",
      "Bleu_4: 0.286\n",
      "computing METEOR score...\n",
      "METEOR: 0.249\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.525\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.944\n",
      "computing SPICE score...\n",
      "SPICE: 0.179\n"
     ]
    }
   ],
   "source": [
    "  if type(input_data) == str: # Filename given.\n",
    "    checkpoint = json.load(open(input_data, 'r'))\n",
    "    preds = checkpoint\n",
    "  elif type(input_data) == list: # Direct predictions give.\n",
    "    preds = input_data\n",
    "\n",
    "  annFile = 'third_party/coco-caption/annotations/captions_val2014.json'\n",
    "  coco = COCO(annFile)\n",
    "  valids = coco.getImgIds()\n",
    "\n",
    "  # Filter results to only those in MSCOCO validation set (will be about a third)\n",
    "  preds_filt = [p for p in tqdm(preds) if p['image_id'] in valids]\n",
    "  len_p = len(preds_filt)\n",
    "  for i in range(len_p):\n",
    "    preds_filt[i]['image_id'] = int(preds_filt[i]['image_id'])\n",
    "  print('Using %d/%d predictions' % (len(preds_filt), len(preds)))\n",
    "  resFile = osp.join(savedir, 'result_%s.json' % (split))\n",
    "  json.dump(preds_filt, open(resFile, 'w')) # Serialize to temporary json file. Sigh, COCO API...\n",
    "\n",
    "  cocoRes = coco.loadRes(resFile)\n",
    "  cocoEval = COCOEvalCap(coco, cocoRes)\n",
    "  cocoEval.params['image_id'] = cocoRes.getImgIds()\n",
    "  cocoEval.evaluate()\n",
    "\n",
    "  # Create output dictionary.\n",
    "  out = {}\n",
    "  for metric, score in cocoEval.eval.items():\n",
    "    out[metric] = score\n",
    "\n",
    "  # Return aggregate and per image score.\n",
    "#   return out, cocoEval.evalImgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "58e75569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.27s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7572/2135005884.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlanguage_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_captions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7572/3783541933.py\u001b[0m in \u001b[0;36mlanguage_eval\u001b[1;34m(input_data, savedir, split)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m   \u001b[1;31m# Filter results to only those in MSCOCO validation set (will be about a third)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m   \u001b[0mpreds_filt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpreds\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'image_id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalids\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m   \u001b[0mlen_p\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds_filt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen_p\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7572/3783541933.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m   \u001b[1;31m# Filter results to only those in MSCOCO validation set (will be about a third)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m   \u001b[0mpreds_filt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpreds\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'image_id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalids\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m   \u001b[0mlen_p\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds_filt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen_p\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\clipcap\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scores = language_eval(pred_captions, args.model_dir, split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28d7a42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9c7eba32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading annotation file...\n",
      "Found 5000 images in split: test\n",
      "[DEBUG] #words in wordlist: 9221\n",
      "[DEBUG] Loading test data ... 4.613305 secs\n",
      "[DEBUG] Running inference on test with 250 batches\n",
      "===========\n",
      "[DEBUG] Loading checkpoint output\\bestmodel.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/250 [00:00<?, ?it/s]C:\\Users\\dbwls\\AppData\\Local\\Temp/ipykernel_7572/1600790827.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  wordprobs = F.softmax(wordact_t).cpu().data.numpy()\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 250/250 [01:21<00:00,  3.08it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'COCO' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7572/1600790827.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[0mpred_captions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'image_id'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mimg_ids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'caption'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0moutcap\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlanguage_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_captions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[0mmodel_imgcnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7572/3783541933.py\u001b[0m in \u001b[0;36mlanguage_eval\u001b[1;34m(input_data, savedir, split)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m   \u001b[0mannFile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'third_party/coco-caption/annotations/captions_val2014.json'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m   \u001b[0mcoco\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCOCO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mannFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m   \u001b[0mvalids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcoco\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetImgIds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'COCO' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "  \"\"\"Runs test on split=val/test with checkpoint file modelfn or loaded model_*\"\"\"\n",
    "\n",
    "  t_start = time.time()\n",
    "  data = coco_loader(args.coco_root, split=split, ncap_per_img=1)\n",
    "  print('[DEBUG] Loading %s data ... %f secs' % (split, time.time() - t_start))\n",
    "\n",
    "  data_loader = DataLoader(dataset=data, num_workers=args.nthreads,\\\n",
    "    batch_size=args.batchsize, shuffle=False, drop_last=True)\n",
    "\n",
    "  batchsize = args.batchsize\n",
    "  max_tokens = data.max_tokens\n",
    "  num_batches = np.int_(np.floor((len(data.ids)*1.)/batchsize))\n",
    "  print('[DEBUG] Running inference on %s with %d batches' % (split, num_batches))\n",
    "\n",
    "  model, transform = load('RN50', jit=False)\n",
    "\n",
    "  if(modelfn is not None):\n",
    "    print('===========')\n",
    "    # model_imgcnn = Vgg16Feats()\n",
    "    # model_imgcnn.cuda()\n",
    "    model_imgcnn = model.cuda()\n",
    "\n",
    "    # model_convcap = convcap(data.numwords, args.num_layers, is_attention=args.attention)\n",
    "    model_convcap = convcap(data.numwords, args.num_layers, is_attention=args.attention, nfeats=2048, nimgfeats=1024)\n",
    "    model_convcap.cuda()\n",
    "\n",
    "    print('[DEBUG] Loading checkpoint %s' % modelfn)\n",
    "    checkpoint = torch.load(modelfn)\n",
    "    model_convcap.load_state_dict(checkpoint['state_dict'])\n",
    "    # model_imgcnn.load_state_dict(checkpoint['img_state_dict'])\n",
    "  else:\n",
    "    model_imgcnn = model.cuda()\n",
    "    model_convcap = model_convcap\n",
    "\n",
    "  model_imgcnn.train(False) \n",
    "  model_convcap.train(False)\n",
    "\n",
    "  pred_captions = []\n",
    "  #Test epoch\n",
    "  for batch_idx, (imgs, _, _, _, img_ids) in \\\n",
    "    tqdm(enumerate(data_loader), total=num_batches):\n",
    "    \n",
    "    imgs = imgs.view(batchsize, 3, 224, 224)\n",
    "\n",
    "    imgs_v = Variable(imgs.cuda())\n",
    "    imgsfeats, imgsfc7 = model_imgcnn.encode_image(imgs_v)\n",
    "    _, featdim, feat_h, feat_w = imgsfeats.size()\n",
    "  \n",
    "    wordclass_feed = np.zeros((batchsize, max_tokens), dtype='int64')\n",
    "    wordclass_feed[:,0] = data.wordlist.index('<S>') \n",
    "\n",
    "    outcaps = np.empty((batchsize, 0)).tolist()\n",
    "\n",
    "    for j in range(max_tokens-1):\n",
    "      wordclass = Variable(torch.from_numpy(wordclass_feed)).cuda()\n",
    "\n",
    "      wordact, _ = model_convcap(imgsfeats.float(), imgsfc7.float(), wordclass)\n",
    "\n",
    "      wordact = wordact[:,:,:-1]\n",
    "      wordact_t = wordact.permute(0, 2, 1).contiguous().view(batchsize*(max_tokens-1), -1)\n",
    "\n",
    "      wordprobs = F.softmax(wordact_t).cpu().data.numpy()\n",
    "      wordids = np.argmax(wordprobs, axis=1)\n",
    "\n",
    "      for k in range(batchsize):\n",
    "        word = data.wordlist[wordids[j+k*(max_tokens-1)]]\n",
    "        outcaps[k].append(word)\n",
    "        if(j < max_tokens-1):\n",
    "          wordclass_feed[k, j+1] = wordids[j+k*(max_tokens-1)]\n",
    "\n",
    "    for j in range(batchsize):\n",
    "      num_words = len(outcaps[j]) \n",
    "      if 'EOS' in outcaps[j]:\n",
    "        num_words = outcaps[j].index('EOS')\n",
    "      outcap = ' '.join(outcaps[j][:num_words])\n",
    "      pred_captions.append({'image_id': img_ids[j], 'caption': outcap})\n",
    "\n",
    "  scores = language_eval(pred_captions, args.model_dir, split)\n",
    "\n",
    "  model_imgcnn.train(True) \n",
    "  model_convcap.train(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f0f7eda9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'image_id': tensor(391895),\n",
       "  'caption': 'a man riding a bike down a dirt road'},\n",
       " {'image_id': tensor(60623), 'caption': 'a woman eating a donut with a fork'},\n",
       " {'image_id': tensor(483108),\n",
       "  'caption': 'a man on a bicycle is looking at a train'},\n",
       " {'image_id': tensor(384213),\n",
       "  'caption': 'a kitchen with a window and a window'},\n",
       " {'image_id': tensor(386164),\n",
       "  'caption': 'a row of wooden tables with white sheets'},\n",
       " {'image_id': tensor(223648),\n",
       "  'caption': 'a long wooden table with a bunch of green bananas on it'},\n",
       " {'image_id': tensor(403385),\n",
       "  'caption': 'a bathroom with a toilet and a sink'},\n",
       " {'image_id': tensor(294832),\n",
       "  'caption': 'a bathroom with a white toilet and a white sink'},\n",
       " {'image_id': tensor(462565),\n",
       "  'caption': 'a group of people riding bikes down a street'},\n",
       " {'image_id': tensor(436141),\n",
       "  'caption': 'a bathroom with a sink and a toilet'},\n",
       " {'image_id': tensor(192440),\n",
       "  'caption': 'a white sink and a toilet in a room'},\n",
       " {'image_id': tensor(1146),\n",
       "  'caption': 'a man wearing a suit and tie with his hands in his pockets'},\n",
       " {'image_id': tensor(559665),\n",
       "  'caption': 'a man with a backpack and a motorcycle'},\n",
       " {'image_id': tensor(394240),\n",
       "  'caption': 'a motorcycle parked in front of a building'},\n",
       " {'image_id': tensor(491497),\n",
       "  'caption': 'a white bed sitting in a bedroom next to a window'},\n",
       " {'image_id': tensor(184791),\n",
       "  'caption': 'a painting of a vase of flowers on a table'},\n",
       " {'image_id': tensor(579664),\n",
       "  'caption': 'a bunch of bananas are sitting on a tree'},\n",
       " {'image_id': tensor(550529),\n",
       "  'caption': 'a motorcycle parked on a sidewalk with a sky background'},\n",
       " {'image_id': tensor(348881),\n",
       "  'caption': 'a person walking on a platform next to a parking meter'},\n",
       " {'image_id': tensor(560623),\n",
       "  'caption': 'a view of a bunch of luggage sitting on the ground'},\n",
       " {'image_id': tensor(561100),\n",
       "  'caption': 'a small blue and white airplane on a grass field'},\n",
       " {'image_id': tensor(354533),\n",
       "  'caption': 'a motorcycle parked in a desert field with a man standing nearby'},\n",
       " {'image_id': tensor(334321),\n",
       "  'caption': 'a dog is walking down the sidewalk with a man on a bike'},\n",
       " {'image_id': tensor(368117),\n",
       "  'caption': 'a traffic light with a red light in the background'},\n",
       " {'image_id': tensor(165547),\n",
       "  'caption': 'a kitchen with a window that has a table with chairs around it'},\n",
       " {'image_id': tensor(455859),\n",
       "  'caption': 'a group of people walking down a street'},\n",
       " {'image_id': tensor(290570),\n",
       "  'caption': 'a herd of sheep grazing on a lush green field'},\n",
       " {'image_id': tensor(281455),\n",
       "  'caption': 'a bird flying over a beach with a few people in the background'},\n",
       " {'image_id': tensor(17756), 'caption': 'a boat that is sitting in the water'},\n",
       " {'image_id': tensor(305821),\n",
       "  'caption': 'a group of giraffes are standing in the grass'},\n",
       " {'image_id': tensor(459374),\n",
       "  'caption': 'a yellow fire hydrant sitting in the middle of a sidewalk'},\n",
       " {'image_id': tensor(208589),\n",
       "  'caption': 'a bird is eating food out of a bird feeder'},\n",
       " {'image_id': tensor(358342),\n",
       "  'caption': 'a large building with a clock tower and a large building'},\n",
       " {'image_id': tensor(74711),\n",
       "  'caption': 'three ducks floating in the water near a pond'},\n",
       " {'image_id': tensor(58636),\n",
       "  'caption': 'a street sign on a pole with a sky background'},\n",
       " {'image_id': tensor(197461),\n",
       "  'caption': 'a sheep standing in a field of grass'},\n",
       " {'image_id': tensor(165029),\n",
       "  'caption': 'a man and a woman are standing in a room'},\n",
       " {'image_id': tensor(336777),\n",
       "  'caption': 'a street sign on a pole on a street'},\n",
       " {'image_id': tensor(472795),\n",
       "  'caption': 'a cow walking down a street next to a store'},\n",
       " {'image_id': tensor(182784),\n",
       "  'caption': 'a cow standing in the street next to a car'},\n",
       " {'image_id': tensor(458052), 'caption': 'a small dog is playing with a toy'},\n",
       " {'image_id': tensor(26942), 'caption': 'a cat sitting on a chair in a room'},\n",
       " {'image_id': tensor(418281),\n",
       "  'caption': 'a group of animals walking down a street'},\n",
       " {'image_id': tensor(535292),\n",
       "  'caption': 'a cow standing in a field with a herd of cows'},\n",
       " {'image_id': tensor(85329), 'caption': 'a close up of a white and black cat'},\n",
       " {'image_id': tensor(451872),\n",
       "  'caption': 'a group of elephants walking in a line'},\n",
       " {'image_id': tensor(314294),\n",
       "  'caption': 'a group of elephants walking in a line'},\n",
       " {'image_id': tensor(516750),\n",
       "  'caption': 'a group of boats are sitting in the water'},\n",
       " {'image_id': tensor(69946),\n",
       "  'caption': 'a boat is docked in a harbor with a view of the water'},\n",
       " {'image_id': tensor(109005),\n",
       "  'caption': 'a group of elephants walking across a grass covered field'},\n",
       " {'image_id': tensor(553442),\n",
       "  'caption': 'a woman and child sitting on a bench'},\n",
       " {'image_id': tensor(261779),\n",
       "  'caption': 'a woman in a dress sitting on a bench'},\n",
       " {'image_id': tensor(198448),\n",
       "  'caption': 'a woman sitting on a bench with her legs crossed'},\n",
       " {'image_id': tensor(329717),\n",
       "  'caption': 'a little boy sitting on a skateboard in a house'},\n",
       " {'image_id': tensor(341393),\n",
       "  'caption': 'a dog is laying on the ground in front of a pool'},\n",
       " {'image_id': tensor(299319),\n",
       "  'caption': 'a group of people walking down a dirt road'},\n",
       " {'image_id': tensor(288955),\n",
       "  'caption': 'a dog sitting on a table with a plate of food'},\n",
       " {'image_id': tensor(426578),\n",
       "  'caption': 'a person walking on a beach with a surfboard'},\n",
       " {'image_id': tensor(64710),\n",
       "  'caption': 'a motorcycle parked on the side of a dirt road'},\n",
       " {'image_id': tensor(180447),\n",
       "  'caption': 'a couple of zebras are standing in a field'},\n",
       " {'image_id': tensor(75162),\n",
       "  'caption': 'a zebra standing in the snow in a fenced in area'},\n",
       " {'image_id': tensor(516316),\n",
       "  'caption': 'a herd of zebra standing on top of a lush green field'},\n",
       " {'image_id': tensor(562121),\n",
       "  'caption': 'a group of zebras are standing in a field'},\n",
       " {'image_id': tensor(129637),\n",
       "  'caption': 'a group of four horses standing next to each other'},\n",
       " {'image_id': tensor(444444),\n",
       "  'caption': 'a woman is standing outside near a horse'},\n",
       " {'image_id': tensor(503005),\n",
       "  'caption': 'a person on a motorcycle taking a picture of a large building'},\n",
       " {'image_id': tensor(316795),\n",
       "  'caption': 'a woman riding a horse through a field'},\n",
       " {'image_id': tensor(375840),\n",
       "  'caption': 'a bowl of fruit and a bowl of fruit on a table'},\n",
       " {'image_id': tensor(147980),\n",
       "  'caption': 'a group of kids playing a game of baseball'},\n",
       " {'image_id': tensor(34180),\n",
       "  'caption': 'a man wearing a yellow hat and a pink hat'},\n",
       " {'image_id': tensor(169802),\n",
       "  'caption': 'a man with a yellow hat and a colorful banana'},\n",
       " {'image_id': tensor(430961),\n",
       "  'caption': 'a man in a baseball uniform throwing a ball'},\n",
       " {'image_id': tensor(570465),\n",
       "  'caption': 'a table with plates of food and glasses of water'},\n",
       " {'image_id': tensor(356708),\n",
       "  'caption': 'a man and a little girl on skis in the snow'},\n",
       " {'image_id': tensor(362368),\n",
       "  'caption': 'a little boy that is standing in front of a table'},\n",
       " {'image_id': tensor(216228),\n",
       "  'caption': 'a woman walking down a street with a bag of luggage'},\n",
       " {'image_id': tensor(448365),\n",
       "  'caption': 'a man riding a skateboard on a ramp'},\n",
       " {'image_id': tensor(472854),\n",
       "  'caption': 'a man riding a skateboard down a street'},\n",
       " {'image_id': tensor(127451),\n",
       "  'caption': 'two men in black jackets on skis in the snow'},\n",
       " {'image_id': tensor(299116),\n",
       "  'caption': 'a girl sitting at a table with a plate of food'},\n",
       " {'image_id': tensor(66412),\n",
       "  'caption': 'a man holding a snowboard in his hand'},\n",
       " {'image_id': tensor(410002),\n",
       "  'caption': 'a bunch of doughnuts that are sitting on a tray'},\n",
       " {'image_id': tensor(507065),\n",
       "  'caption': 'a young boy eating a sandwich with a fork'},\n",
       " {'image_id': tensor(415746),\n",
       "  'caption': 'a display case filled with lots of different kinds of donuts'},\n",
       " {'image_id': tensor(71171),\n",
       "  'caption': 'a plate with a sandwich and a pickle on it'},\n",
       " {'image_id': tensor(292301),\n",
       "  'caption': 'a sandwich and a drink sit on a table'},\n",
       " {'image_id': tensor(550627),\n",
       "  'caption': 'a box of donuts with sprinkles on it'},\n",
       " {'image_id': tensor(244339),\n",
       "  'caption': 'a young man in a green shirt and green tie'},\n",
       " {'image_id': tensor(284350),\n",
       "  'caption': 'a woman standing on a surfboard in the water'},\n",
       " {'image_id': tensor(309120),\n",
       "  'caption': 'a man is playing frisbee on a green field'},\n",
       " {'image_id': tensor(467477),\n",
       "  'caption': 'a man riding a wave on top of a surfboard'},\n",
       " {'image_id': tensor(154971),\n",
       "  'caption': 'a group of young men playing a game of soccer'},\n",
       " {'image_id': tensor(295837),\n",
       "  'caption': 'a woman in a kitchen preparing food on a table'},\n",
       " {'image_id': tensor(321214), 'caption': 'a baby eating a cake with a fork'},\n",
       " {'image_id': tensor(224757),\n",
       "  'caption': 'a group of kids playing a game of soccer'},\n",
       " {'image_id': tensor(182245),\n",
       "  'caption': 'a man sitting at a table with a plate of food'},\n",
       " {'image_id': tensor(199551),\n",
       "  'caption': 'a little girl laying in bed with a blanket on top of it'},\n",
       " {'image_id': tensor(239347),\n",
       "  'caption': 'a woman sitting on a bed in a white room'},\n",
       " {'image_id': tensor(353830),\n",
       "  'caption': 'a pizza with cheese and tomatoes on a plate'},\n",
       " {'image_id': tensor(301102),\n",
       "  'caption': 'two tennis rackets are laying on a tennis court'},\n",
       " {'image_id': tensor(473237),\n",
       "  'caption': 'a little girl eating a slice of pizza'},\n",
       " {'image_id': tensor(190081),\n",
       "  'caption': 'a woman holding a tennis racquet on a tennis court'},\n",
       " {'image_id': tensor(207151),\n",
       "  'caption': 'a pizza with many toppings on a wooden board'},\n",
       " {'image_id': tensor(371250),\n",
       "  'caption': 'a bed with a wooden head board and a painting on the wall'},\n",
       " {'image_id': tensor(209868),\n",
       "  'caption': 'a young child brushing his teeth with a tooth brush'},\n",
       " {'image_id': tensor(340175),\n",
       "  'caption': 'a living room with a couch and a table'},\n",
       " {'image_id': tensor(235597),\n",
       "  'caption': 'a man sitting in front of a laptop computer'},\n",
       " {'image_id': tensor(503311),\n",
       "  'caption': 'a person is flying a kite on the beach'},\n",
       " {'image_id': tensor(138477),\n",
       "  'caption': 'a person is flying a kite in a field'},\n",
       " {'image_id': tensor(76292), 'caption': 'a child is flying a kite in a field'},\n",
       " {'image_id': tensor(502090),\n",
       "  'caption': 'a person flying a kite on the beach'},\n",
       " {'image_id': tensor(28655),\n",
       "  'caption': 'a clock on a pole on a street corner'},\n",
       " {'image_id': tensor(191096),\n",
       "  'caption': 'a baseball player swinging a bat at a ball'},\n",
       " {'image_id': tensor(78707),\n",
       "  'caption': 'a baseball player holding a bat on a field'},\n",
       " {'image_id': tensor(336493),\n",
       "  'caption': 'a young boy holding a baseball bat during a baseball game'},\n",
       " {'image_id': tensor(74369),\n",
       "  'caption': 'a young baseball player throwing a baseball on a field'},\n",
       " {'image_id': tensor(384012),\n",
       "  'caption': 'a baseball player is getting ready to hit a ball'},\n",
       " {'image_id': tensor(579056),\n",
       "  'caption': 'a man holding a baseball bat on a field'},\n",
       " {'image_id': tensor(24223),\n",
       "  'caption': 'a person is holding a large pizza in a box'},\n",
       " {'image_id': tensor(69392),\n",
       "  'caption': 'a group of people standing on top of a tennis court'},\n",
       " {'image_id': tensor(272262),\n",
       "  'caption': 'a man holding a tennis racquet on a tennis court'},\n",
       " {'image_id': tensor(43635),\n",
       "  'caption': 'a group of people sitting on a bench in front of a building'},\n",
       " {'image_id': tensor(95786),\n",
       "  'caption': 'a cup of coffee sitting next to a cup on a table'},\n",
       " {'image_id': tensor(87199),\n",
       "  'caption': 'a man in a baseball cap and hat sitting on a bench'},\n",
       " {'image_id': tensor(527248),\n",
       "  'caption': 'a large crowd of people standing in front of a building'},\n",
       " {'image_id': tensor(353136),\n",
       "  'caption': 'a person is sitting on a bench and another is standing up'},\n",
       " {'image_id': tensor(83915),\n",
       "  'caption': 'a large building with a clock tower on top'},\n",
       " {'image_id': tensor(2240),\n",
       "  'caption': 'a group of stuffed animals sitting on top of a shelf'},\n",
       " {'image_id': tensor(28377), 'caption': 'a street sign on a pole on a street'},\n",
       " {'image_id': tensor(217183),\n",
       "  'caption': 'a vase with flowers in it sitting on a table'},\n",
       " {'image_id': tensor(366630),\n",
       "  'caption': 'a vase with flowers in it sitting on a table'},\n",
       " {'image_id': tensor(157184),\n",
       "  'caption': 'a man holding a pair of skis in his hands'},\n",
       " {'image_id': tensor(509819),\n",
       "  'caption': 'a pair of scissors and some tools on a table'},\n",
       " {'image_id': tensor(510657),\n",
       "  'caption': 'a group of people sitting at a table with glasses of wine'},\n",
       " {'image_id': tensor(195645),\n",
       "  'caption': 'a man and a woman sitting at a table with a baby'},\n",
       " {'image_id': tensor(171190),\n",
       "  'caption': 'a group of people sitting around a table with wine glasses on it'},\n",
       " {'image_id': tensor(484145),\n",
       "  'caption': 'a man standing in a kitchen holding a knife'},\n",
       " {'image_id': tensor(530207),\n",
       "  'caption': 'a group of people walking down a street'},\n",
       " {'image_id': tensor(17953),\n",
       "  'caption': 'a bunch of vegetables and fruits are on a table'},\n",
       " {'image_id': tensor(210012),\n",
       "  'caption': 'a woman standing in a kitchen with her dog'},\n",
       " {'image_id': tensor(33638),\n",
       "  'caption': 'a woman cooking in a kitchen with a stove and microwave'},\n",
       " {'image_id': tensor(31442), 'caption': 'a man sitting on a chair in a room'},\n",
       " {'image_id': tensor(329219),\n",
       "  'caption': 'a man walking a dog down a sidewalk'},\n",
       " {'image_id': tensor(399851), 'caption': 'a kitchen with a stove and a sink'},\n",
       " {'image_id': tensor(539124),\n",
       "  'caption': 'a couple of people that are walking down the street'},\n",
       " {'image_id': tensor(12896), 'caption': 'a bicycle is parked next to a fence'},\n",
       " {'image_id': tensor(378709),\n",
       "  'caption': 'a bathroom with a toilet and a sink'},\n",
       " {'image_id': tensor(431197),\n",
       "  'caption': 'a bathroom with a toilet sink and mirror'},\n",
       " {'image_id': tensor(463610),\n",
       "  'caption': 'a bathroom with a toilet and a sink'},\n",
       " {'image_id': tensor(540806),\n",
       "  'caption': 'a man riding a motorcycle down a road next to a bridge'},\n",
       " {'image_id': tensor(402330),\n",
       "  'caption': 'a toilet with a wooden seat and a white toilet'},\n",
       " {'image_id': tensor(378657),\n",
       "  'caption': 'a large clock tower with a massive clock on its face'},\n",
       " {'image_id': tensor(24343),\n",
       "  'caption': 'a man riding a motorcycle down a street'},\n",
       " {'image_id': tensor(376177), 'caption': 'a large air plane on a run way'},\n",
       " {'image_id': tensor(115178),\n",
       "  'caption': 'a red and white airplane flying in the sky'},\n",
       " {'image_id': tensor(572733),\n",
       "  'caption': 'a large airplane flying in a clear blue sky'},\n",
       " {'image_id': tensor(112956),\n",
       "  'caption': 'a large jetliner flying through a blue sky'},\n",
       " {'image_id': tensor(144122),\n",
       "  'caption': 'a red and white airplane flying in the sky'},\n",
       " {'image_id': tensor(183181),\n",
       "  'caption': 'a herd of sheep grazing on a lush green field'},\n",
       " {'image_id': tensor(275210),\n",
       "  'caption': 'a giraffe standing in the middle of a field'},\n",
       " {'image_id': tensor(519046),\n",
       "  'caption': 'a giraffe standing in a field with tall grass'},\n",
       " {'image_id': tensor(362159),\n",
       "  'caption': 'a traffic light on a city street at dusk'},\n",
       " {'image_id': tensor(389378),\n",
       "  'caption': 'a street at night with a car driving down the street'},\n",
       " {'image_id': tensor(12204),\n",
       "  'caption': 'a group of giraffes standing in a fenced off area'},\n",
       " {'image_id': tensor(91857),\n",
       "  'caption': 'two giraffes standing in a fenced in area'},\n",
       " {'image_id': tensor(220307),\n",
       "  'caption': 'a giraffe standing in the middle of a dirt road'},\n",
       " {'image_id': tensor(4760),\n",
       "  'caption': 'a fire hydrant on a sidewalk near a street'},\n",
       " {'image_id': tensor(410428),\n",
       "  'caption': 'a group of sheep standing on a lush green field'},\n",
       " {'image_id': tensor(450724),\n",
       "  'caption': 'a man sitting on a bench looking out over the ocean'},\n",
       " {'image_id': tensor(27440),\n",
       "  'caption': 'a giraffe standing in the middle of a dirt field'},\n",
       " {'image_id': tensor(438221), 'caption': 'a couple of ducks are in the water'},\n",
       " {'image_id': tensor(472557),\n",
       "  'caption': 'two giraffes standing next to each other in a pen'},\n",
       " {'image_id': tensor(123836),\n",
       "  'caption': 'a giraffe standing next to a pile of rocks'},\n",
       " {'image_id': tensor(317441),\n",
       "  'caption': 'a street sign with a one way sign on it'},\n",
       " {'image_id': tensor(1448),\n",
       "  'caption': 'a giraffe standing in a field with grass and trees'},\n",
       " {'image_id': tensor(536615),\n",
       "  'caption': 'a group of giraffes are standing in a pin'},\n",
       " {'image_id': tensor(141517),\n",
       "  'caption': 'a herd of sheep grazing on a lush green field'},\n",
       " {'image_id': tensor(71281),\n",
       "  'caption': 'a herd of sheep standing on top of a lush green field'},\n",
       " {'image_id': tensor(350262), 'caption': 'a group of cows grazing in a field'},\n",
       " {'image_id': tensor(1590),\n",
       "  'caption': 'a bunch of trash is sitting in the middle of a street'},\n",
       " {'image_id': tensor(547839),\n",
       "  'caption': 'a train traveling down a track with a car driving by'},\n",
       " {'image_id': tensor(550452),\n",
       "  'caption': 'a red train engine sitting on the tracks'},\n",
       " {'image_id': tensor(271240),\n",
       "  'caption': 'a white and green sign that reads UNK'},\n",
       " {'image_id': tensor(438232),\n",
       "  'caption': 'a train is pulling into a train station'},\n",
       " {'image_id': tensor(147915),\n",
       "  'caption': 'a stop sign with a street sign on top of it'},\n",
       " {'image_id': tensor(438985),\n",
       "  'caption': 'a cat is sitting on top of a suitcase'},\n",
       " {'image_id': tensor(31176),\n",
       "  'caption': 'a cat sitting on a window sill in a room'},\n",
       " {'image_id': tensor(451972),\n",
       "  'caption': 'a fire truck with a flag on it on a street'},\n",
       " {'image_id': tensor(199050),\n",
       "  'caption': 'a group of people sitting around a table'},\n",
       " {'image_id': tensor(468541), 'caption': 'a dog wearing a sweater and a tie'},\n",
       " {'image_id': tensor(38662),\n",
       "  'caption': 'a white boat sitting on top of a beach next to a light'},\n",
       " {'image_id': tensor(90476),\n",
       "  'caption': 'a group of boats are parked on the beach'},\n",
       " {'image_id': tensor(386739),\n",
       "  'caption': 'a man and woman are standing in front of a black and white'},\n",
       " {'image_id': tensor(36598),\n",
       "  'caption': 'a group of people walking down a street holding umbrellas'},\n",
       " {'image_id': tensor(181859),\n",
       "  'caption': 'a cat laying on a white sink in a bathroom'},\n",
       " {'image_id': tensor(177262),\n",
       "  'caption': 'a cat laying on top of a sink in a bathroom'},\n",
       " {'image_id': tensor(177015),\n",
       "  'caption': 'a man sitting on a couch using a laptop computer'},\n",
       " {'image_id': tensor(256260),\n",
       "  'caption': 'a man is petting an elephant with a hose'},\n",
       " {'image_id': tensor(88784),\n",
       "  'caption': 'a dog running across a field with a frisbee in its mouth'},\n",
       " {'image_id': tensor(48731),\n",
       "  'caption': 'a polar bear in the snow with a frisbee'},\n",
       " {'image_id': tensor(453860),\n",
       "  'caption': 'a person is standing in the snow with a frisbee'},\n",
       " {'image_id': tensor(178746),\n",
       "  'caption': 'a luggage cart sitting on the floor in a terminal'},\n",
       " {'image_id': tensor(347950),\n",
       "  'caption': 'a dog running with a frisbee in its mouth'},\n",
       " {'image_id': tensor(350789),\n",
       "  'caption': 'a group of zebras are standing in a field'},\n",
       " {'image_id': tensor(33645),\n",
       "  'caption': 'a little girl holding a baseball bat in a yard'},\n",
       " {'image_id': tensor(309100),\n",
       "  'caption': 'a group of zebras are standing in a field'},\n",
       " {'image_id': tensor(299089),\n",
       "  'caption': 'a group of zebras are standing in a field'},\n",
       " {'image_id': tensor(421999),\n",
       "  'caption': 'a zebra standing in the dirt near a tree'},\n",
       " {'image_id': tensor(366830),\n",
       "  'caption': 'a brown cow standing in a forest filled with trees'},\n",
       " {'image_id': tensor(199346),\n",
       "  'caption': 'a person riding a horse in a city square'},\n",
       " {'image_id': tensor(177246),\n",
       "  'caption': 'a sandwich and french fries on a tray'},\n",
       " {'image_id': tensor(348905),\n",
       "  'caption': 'a man riding a surfboard on a wave in the ocean'},\n",
       " {'image_id': tensor(469961),\n",
       "  'caption': 'a person riding skis on a snowy slope'},\n",
       " {'image_id': tensor(427802),\n",
       "  'caption': 'a pile of oranges sitting next to a pile of oranges'},\n",
       " {'image_id': tensor(338472), 'caption': 'a close up of a basket of oranges'},\n",
       " {'image_id': tensor(355137),\n",
       "  'caption': 'a person riding skis on a snowy surface'},\n",
       " {'image_id': tensor(361763), 'caption': 'a man is swinging a bat at a ball'},\n",
       " {'image_id': tensor(88854),\n",
       "  'caption': 'a group of people skiing down a snowy slope'},\n",
       " {'image_id': tensor(160195),\n",
       "  'caption': 'a man riding a skateboard down a sidewalk'},\n",
       " {'image_id': tensor(580591),\n",
       "  'caption': 'a person riding skis on a snowy surface'},\n",
       " {'image_id': tensor(226588),\n",
       "  'caption': 'a person riding skis on a snowy surface'},\n",
       " {'image_id': tensor(361472),\n",
       "  'caption': 'a group of kids riding skateboards down a street'},\n",
       " {'image_id': tensor(242103), 'caption': 'a plate of food with a green salad'},\n",
       " {'image_id': tensor(297233),\n",
       "  'caption': 'a table with plates of food and glasses on it'},\n",
       " {'image_id': tensor(2867),\n",
       "  'caption': 'a group of people standing on top of a snow covered slope'},\n",
       " {'image_id': tensor(257870),\n",
       "  'caption': 'a man holding a hot dog in his hand'},\n",
       " {'image_id': tensor(57286),\n",
       "  'caption': 'a skateboarder is jumping over a set of stairs'},\n",
       " {'image_id': tensor(435037),\n",
       "  'caption': 'a doughnut and a cup of coffee on a table'},\n",
       " {'image_id': tensor(546500), 'caption': 'a close up of a cake on a table'},\n",
       " {'image_id': tensor(545385),\n",
       "  'caption': 'a plate with a piece of cake and a spoon'},\n",
       " {'image_id': tensor(23320),\n",
       "  'caption': 'a slice of cake on a plate with a fork'},\n",
       " {'image_id': tensor(12085),\n",
       "  'caption': 'two cats are laying on a bed with white sheets'},\n",
       " {'image_id': tensor(8775),\n",
       "  'caption': 'a bed with a white comforter and a blue blanket'},\n",
       " {'image_id': tensor(384981),\n",
       "  'caption': 'a woman is sitting at a table with a birthday cake'},\n",
       " {'image_id': tensor(475398),\n",
       "  'caption': 'a woman standing in front of a cake with a birthday cake'},\n",
       " {'image_id': tensor(479213),\n",
       "  'caption': 'two women are standing in front of a cake'},\n",
       " {'image_id': tensor(30549),\n",
       "  'caption': 'two women standing next to each other holding glasses'},\n",
       " {'image_id': tensor(66072),\n",
       "  'caption': 'a man riding a surfboard on top of a wave'},\n",
       " {'image_id': tensor(513699),\n",
       "  'caption': 'a group of people walking across a beach holding surfboards'},\n",
       " {'image_id': tensor(45057),\n",
       "  'caption': 'a pizza with toppings on a white plate'},\n",
       " {'image_id': tensor(372577),\n",
       "  'caption': 'a man standing on a tennis court holding a racquet'},\n",
       " {'image_id': tensor(275202),\n",
       "  'caption': 'a pizza sitting on top of a white plate on a table'},\n",
       " {'image_id': tensor(294831),\n",
       "  'caption': 'a person is holding a pizza in a box'},\n",
       " {'image_id': tensor(190291),\n",
       "  'caption': 'a group of people sitting at a table with plates of food'},\n",
       " {'image_id': tensor(246649),\n",
       "  'caption': 'a man is playing tennis on a tennis court'},\n",
       " {'image_id': tensor(199449),\n",
       "  'caption': 'a living room with a couch and a table'},\n",
       " {'image_id': tensor(1626),\n",
       "  'caption': 'a man standing in a living room next to a couch'},\n",
       " {'image_id': tensor(234251),\n",
       "  'caption': 'a little girl standing in a room with a remote'},\n",
       " {'image_id': tensor(281376),\n",
       "  'caption': 'a desk with a keyboard and a laptop on it'},\n",
       " {'image_id': tensor(326082),\n",
       "  'caption': 'a living room with a couch and a tv'},\n",
       " {'image_id': tensor(525619),\n",
       "  'caption': 'a dog is sitting in the grass near a fence'},\n",
       " {'image_id': tensor(393031),\n",
       "  'caption': 'a baseball player is getting ready to hit a ball'},\n",
       " {'image_id': tensor(385514),\n",
       "  'caption': 'a baseball player swinging a bat at a ball'},\n",
       " {'image_id': tensor(539355), 'caption': 'a clock on a pole on a street'},\n",
       " {'image_id': tensor(320180),\n",
       "  'caption': 'a woman laying on a bed with her hands on her hair'},\n",
       " {'image_id': tensor(357633),\n",
       "  'caption': 'a laptop computer sitting on top of a wooden table'},\n",
       " {'image_id': tensor(127801),\n",
       "  'caption': 'a person holding a cell phone in their hand'},\n",
       " {'image_id': tensor(537991),\n",
       "  'caption': 'a woman sitting on a couch holding a smart phone'},\n",
       " {'image_id': tensor(25758),\n",
       "  'caption': 'a woman cooking food in a stainless steel oven'},\n",
       " {'image_id': tensor(565198),\n",
       "  'caption': 'a little girl holding a nintendo wii game controller'},\n",
       " {'image_id': tensor(577160),\n",
       "  'caption': 'a plate of food with a sandwich and salad'},\n",
       " {'image_id': tensor(321333),\n",
       "  'caption': 'two young boys sitting on a bench holding their teddy bear'},\n",
       " {'image_id': tensor(229688),\n",
       "  'caption': 'a woman sitting at a table with a plate of food'},\n",
       " {'image_id': tensor(509807),\n",
       "  'caption': 'a kitchen with a stove and a microwave'},\n",
       " {'image_id': tensor(37367), 'caption': 'a table and chairs in a small room'},\n",
       " {'image_id': tensor(22158),\n",
       "  'caption': 'a kitchen with a stove and a refrigerator'},\n",
       " {'image_id': tensor(220446),\n",
       "  'caption': 'a bathroom with a toilet and a sink'},\n",
       " {'image_id': tensor(247184),\n",
       "  'caption': 'a bathroom with a toilet and a sink'},\n",
       " {'image_id': tensor(313063),\n",
       "  'caption': 'a bathroom with a toilet sink and bathtub'},\n",
       " {'image_id': tensor(239376),\n",
       "  'caption': 'a bathroom with a white tub and a white tile floor'},\n",
       " {'image_id': tensor(28790),\n",
       "  'caption': 'a bathroom with a toilet and a shower'},\n",
       " {'image_id': tensor(416668),\n",
       "  'caption': 'a black cat sitting on a kitchen counter'},\n",
       " {'image_id': tensor(252203),\n",
       "  'caption': 'a dog sitting in the passenger seat of a car'},\n",
       " {'image_id': tensor(573962),\n",
       "  'caption': 'a view of a street with a lot of traffic'},\n",
       " {'image_id': tensor(480215),\n",
       "  'caption': 'a white toilet sitting next to a white bath tub'},\n",
       " {'image_id': tensor(299550),\n",
       "  'caption': 'a white toilet sitting next to a white sink'},\n",
       " {'image_id': tensor(184557),\n",
       "  'caption': 'a cat is sitting on the toilet in the bathroom'},\n",
       " {'image_id': tensor(577526),\n",
       "  'caption': 'a black and white cat laying on a bed'},\n",
       " {'image_id': tensor(31000),\n",
       "  'caption': 'a bowl of oranges and oranges on a table'},\n",
       " {'image_id': tensor(280360),\n",
       "  'caption': 'a small blue and yellow plane flying in the air'},\n",
       " {'image_id': tensor(283495),\n",
       "  'caption': 'a plane flying in the air with trees in the background'},\n",
       " {'image_id': tensor(189828),\n",
       "  'caption': 'a plane flying in the air above trees'},\n",
       " {'image_id': tensor(126502),\n",
       "  'caption': 'a close up of a giraffe near a fence'},\n",
       " {'image_id': tensor(141587),\n",
       "  'caption': 'a large jetliner flying over a city in front of a city'},\n",
       " {'image_id': tensor(16241),\n",
       "  'caption': 'a large airplane flying over a city in a city'},\n",
       " {'image_id': tensor(277208),\n",
       "  'caption': 'a giraffe standing in the middle of a field'},\n",
       " {'image_id': tensor(134863),\n",
       "  'caption': 'a street scene with a traffic light and a street sign'},\n",
       " {'image_id': tensor(34904),\n",
       "  'caption': 'a wooden bench with a blue wooden bench'},\n",
       " {'image_id': tensor(8179),\n",
       "  'caption': 'a traffic light sitting on the side of a road'},\n",
       " {'image_id': tensor(539784),\n",
       "  'caption': 'a herd of sheep crossing a road with a train passing by'},\n",
       " {'image_id': tensor(458755),\n",
       "  'caption': 'a woman is petting a sheep in a pen'},\n",
       " {'image_id': tensor(58492),\n",
       "  'caption': 'a bird is flying over the top of a hill'},\n",
       " {'image_id': tensor(484551),\n",
       "  'caption': 'a man is standing on a boat in the water'},\n",
       " {'image_id': tensor(133867),\n",
       "  'caption': 'a man is skateboarding down a busy street'},\n",
       " {'image_id': tensor(208778),\n",
       "  'caption': 'a man is standing in a bathroom with a sink'},\n",
       " {'image_id': tensor(434279),\n",
       "  'caption': 'a blue and white train sitting on the tracks'},\n",
       " {'image_id': tensor(136584),\n",
       "  'caption': 'a bird sitting on a power line next to a wire fence'},\n",
       " {'image_id': tensor(520482),\n",
       "  'caption': 'a group of birds standing on a wooden ledge'},\n",
       " {'image_id': tensor(434129),\n",
       "  'caption': 'a blue vase with a blue and white surfboard on it'},\n",
       " {'image_id': tensor(1180),\n",
       "  'caption': 'a woman in a white dress cutting a cake'},\n",
       " {'image_id': tensor(158118),\n",
       "  'caption': 'a man is walking down the street in the city'},\n",
       " {'image_id': tensor(572427), 'caption': 'a stop sign on a pole on a street'},\n",
       " {'image_id': tensor(73119),\n",
       "  'caption': 'a train is coming down the tracks in a black and white photo'},\n",
       " {'image_id': tensor(27226),\n",
       "  'caption': 'a red train is coming down the tracks'},\n",
       " {'image_id': tensor(288799),\n",
       "  'caption': 'a red train is coming down some tracks'},\n",
       " {'image_id': tensor(300471),\n",
       "  'caption': 'a cat laying on a blue bench next to a pool'},\n",
       " {'image_id': tensor(152740),\n",
       "  'caption': 'a herd of black cows grazing on a grassy hillside'},\n",
       " {'image_id': tensor(289781),\n",
       "  'caption': 'a boat sitting on a dock in the water'},\n",
       " {'image_id': tensor(173385),\n",
       "  'caption': 'a baby elephant standing next to an adult elephant'},\n",
       " {'image_id': tensor(450370),\n",
       "  'caption': 'a large elephant walking in the grass near trees'},\n",
       " {'image_id': tensor(502419),\n",
       "  'caption': 'a couple of elephants standing next to each other'},\n",
       " {'image_id': tensor(471497),\n",
       "  'caption': 'a large elephant walking through a lush green forest'},\n",
       " {'image_id': tensor(483275),\n",
       "  'caption': 'a group of elephants walking in a line'},\n",
       " {'image_id': tensor(144379),\n",
       "  'caption': 'a woman standing next to a pile of luggage'},\n",
       " {'image_id': tensor(337055),\n",
       "  'caption': 'a woman sitting on a bench with a cell phone'},\n",
       " {'image_id': tensor(568040),\n",
       "  'caption': 'a large elephant standing in a grass field'},\n",
       " {'image_id': tensor(404461),\n",
       "  'caption': 'a red fire hydrant sitting on the side of a road'},\n",
       " {'image_id': tensor(108338),\n",
       "  'caption': 'a group of elephants walking across a dirt field'},\n",
       " {'image_id': tensor(525376),\n",
       "  'caption': 'a bunch of luggage is sitting in a car'},\n",
       " {'image_id': tensor(395402),\n",
       "  'caption': 'a small dog standing on a kitchen floor'},\n",
       " {'image_id': tensor(530226),\n",
       "  'caption': 'a polar bear walking across a snowy field'},\n",
       " {'image_id': tensor(295097), 'caption': 'a cat laying on a rug on a couch'},\n",
       " {'image_id': tensor(114352),\n",
       "  'caption': 'a man holding a frisbee while standing in a field'},\n",
       " {'image_id': tensor(504341),\n",
       "  'caption': 'a dog is laying on the sand at the beach'},\n",
       " {'image_id': tensor(29577),\n",
       "  'caption': 'two horses are tied to a post on a city street'},\n",
       " {'image_id': tensor(545129),\n",
       "  'caption': 'a group of zebras are standing together in the dirt'},\n",
       " {'image_id': tensor(372252),\n",
       "  'caption': 'a group of zebras are grazing in a field'},\n",
       " {'image_id': tensor(121031),\n",
       "  'caption': 'a group of people riding on the back of a horse'},\n",
       " {'image_id': tensor(75990),\n",
       "  'caption': 'a man riding a horse drawn carriage down a street'},\n",
       " {'image_id': tensor(248441),\n",
       "  'caption': 'a woman standing next to a horse on a beach'},\n",
       " {'image_id': tensor(104568),\n",
       "  'caption': 'a bunch of vegetables and fruits on a table'},\n",
       " {'image_id': tensor(300655),\n",
       "  'caption': 'a person is standing in the grass with a frisbee'},\n",
       " {'image_id': tensor(51223),\n",
       "  'caption': 'a baseball player is running to first base'},\n",
       " {'image_id': tensor(95051),\n",
       "  'caption': 'a man riding skis down a snow covered slope'},\n",
       " {'image_id': tensor(169858),\n",
       "  'caption': 'a woman holding a bunch of bananas in her hands'},\n",
       " {'image_id': tensor(178748),\n",
       "  'caption': 'a pot of soup with broccoli and carrots in it'},\n",
       " {'image_id': tensor(59614),\n",
       "  'caption': 'a plate of food with broccoli and rice'},\n",
       " {'image_id': tensor(255209),\n",
       "  'caption': 'a dog is walking with a person on a leash'},\n",
       " {'image_id': tensor(279209),\n",
       "  'caption': 'a person walking in the snow with a snowboard'},\n",
       " {'image_id': tensor(90707),\n",
       "  'caption': 'a person is standing in front of a large window'},\n",
       " {'image_id': tensor(577403),\n",
       "  'caption': 'a group of young boys riding skateboards at a skate park'},\n",
       " {'image_id': tensor(289469),\n",
       "  'caption': 'a plate of food with a sandwich and french fries'},\n",
       " {'image_id': tensor(163852),\n",
       "  'caption': 'a white plate topped with a sandwich and a salad'},\n",
       " {'image_id': tensor(322369),\n",
       "  'caption': 'a sandwich and a cup of soda on a table'},\n",
       " {'image_id': tensor(308430),\n",
       "  'caption': 'a pan of food being cooked in a stove'},\n",
       " {'image_id': tensor(245242),\n",
       "  'caption': 'a cutting board with a knife and some carrots'},\n",
       " {'image_id': tensor(481187),\n",
       "  'caption': 'a person riding skis on a snowy slope'},\n",
       " {'image_id': tensor(39009),\n",
       "  'caption': 'a group of people holding up long yellow and white frosted cake'},\n",
       " {'image_id': tensor(166124),\n",
       "  'caption': 'a box of six donuts with different toppings'},\n",
       " {'image_id': tensor(3001),\n",
       "  'caption': 'a box of donuts and a tray of donuts on a table'},\n",
       " {'image_id': tensor(220111),\n",
       "  'caption': 'a table with plates of food and glasses of water'},\n",
       " {'image_id': tensor(296284),\n",
       "  'caption': 'a couple of doughnuts are in a display case'},\n",
       " {'image_id': tensor(207366),\n",
       "  'caption': 'a group of young men kicking around a soccer ball'},\n",
       " {'image_id': tensor(127517),\n",
       "  'caption': 'a group of surfboards lined up next to each other'},\n",
       " {'image_id': tensor(183715),\n",
       "  'caption': 'a woman holding a knife with a bunch of green frosting on it'},\n",
       " {'image_id': tensor(340642),\n",
       "  'caption': 'a slice of cake on a plate with a fork'},\n",
       " {'image_id': tensor(391915), 'caption': 'a room with a bed and a canopy'},\n",
       " {'image_id': tensor(13525),\n",
       "  'caption': 'a woman laying in bed with a white sheet'},\n",
       " {'image_id': tensor(294487),\n",
       "  'caption': 'a bed with a wooden head board and a wooden frame'},\n",
       " {'image_id': tensor(242909),\n",
       "  'caption': 'a pizza with many toppings on a plate'},\n",
       " {'image_id': tensor(448897),\n",
       "  'caption': 'a pizza with many toppings on a plate'},\n",
       " {'image_id': tensor(216303),\n",
       "  'caption': 'a woman in a short skirt holding a tennis racquet'},\n",
       " {'image_id': tensor(355272),\n",
       "  'caption': 'a young boy holding a nintendo wii game controller'},\n",
       " {'image_id': tensor(355228),\n",
       "  'caption': 'a small kitten is playing with a computer mouse'},\n",
       " {'image_id': tensor(70351),\n",
       "  'caption': 'a white plate topped with a hot dog and banana slices'},\n",
       " {'image_id': tensor(501429),\n",
       "  'caption': 'a baby is holding a toothbrush in its mouth'},\n",
       " {'image_id': tensor(311394),\n",
       "  'caption': 'a baby in a tie is holding a toothbrush'},\n",
       " {'image_id': tensor(90365),\n",
       "  'caption': 'a white toilet sitting in a bathroom next to a wall'},\n",
       " {'image_id': tensor(408327),\n",
       "  'caption': 'a woman in a short skirt holding a tennis racquet'},\n",
       " {'image_id': tensor(221291),\n",
       "  'caption': 'a little boy that is standing in the grass with a kite'},\n",
       " {'image_id': tensor(565239),\n",
       "  'caption': 'a group of people standing on a street flying a kite'},\n",
       " {'image_id': tensor(125404),\n",
       "  'caption': 'two young boys wearing baseball helmets and holding baseball gloves'},\n",
       " {'image_id': tensor(378545),\n",
       "  'caption': 'a clock on a pole in front of a building'},\n",
       " {'image_id': tensor(182503),\n",
       "  'caption': 'a pizza with cheese and other toppings on it'},\n",
       " {'image_id': tensor(372384),\n",
       "  'caption': 'a man is hitting a tennis ball on the court'},\n",
       " {'image_id': tensor(185781),\n",
       "  'caption': 'a group of people standing around a room with a laptop on the'},\n",
       " {'image_id': tensor(484312),\n",
       "  'caption': 'a man wearing a hat and glasses sitting in a chair'},\n",
       " {'image_id': tensor(471869),\n",
       "  'caption': 'a brown teddy bear sitting on top of a bed'},\n",
       " {'image_id': tensor(516766),\n",
       "  'caption': 'a stuffed animal is laying on a bed'},\n",
       " {'image_id': tensor(533407),\n",
       "  'caption': 'a group of men standing around a kitchen'},\n",
       " {'image_id': tensor(157001),\n",
       "  'caption': 'two people sitting at a table with laptops'},\n",
       " {'image_id': tensor(562345),\n",
       "  'caption': 'a woman with a yellow jacket and blue pants standing on a sidewalk'},\n",
       " {'image_id': tensor(130171), 'caption': 'a bowl of fruit with a spoon in it'},\n",
       " {'image_id': tensor(512116),\n",
       "  'caption': 'a little boy standing in a living room with a remote control'},\n",
       " {'image_id': tensor(455464),\n",
       "  'caption': 'a man with glasses and a cup with a cell phone'},\n",
       " {'image_id': tensor(214527),\n",
       "  'caption': 'a clock tower in the middle of a street'},\n",
       " {'image_id': tensor(138965),\n",
       "  'caption': 'a group of stuffed animals sitting on top of a bed'},\n",
       " {'image_id': tensor(8277),\n",
       "  'caption': 'a plate of food with a fork and a bowl of soup'},\n",
       " {'image_id': tensor(118134),\n",
       "  'caption': 'a large clock tower with a massive clock on its face'},\n",
       " {'image_id': tensor(498555),\n",
       "  'caption': 'a white vase with a flower inside of it'},\n",
       " {'image_id': tensor(157102),\n",
       "  'caption': 'a baby sitting at a table with a plate of food'},\n",
       " {'image_id': tensor(16928),\n",
       "  'caption': 'a rusty old fire hydrant in the middle of a forest'},\n",
       " {'image_id': tensor(271607),\n",
       "  'caption': 'a group of people standing around a wooden fence'},\n",
       " {'image_id': tensor(55772),\n",
       "  'caption': 'a person standing in the middle of a flower in the sun'},\n",
       " {'image_id': tensor(360170),\n",
       "  'caption': 'a group of people standing in a busy train'},\n",
       " {'image_id': tensor(227220),\n",
       "  'caption': 'a kitchen with a stove and a refrigerator'},\n",
       " {'image_id': tensor(538092),\n",
       "  'caption': 'a man standing in a kitchen with a refrigerator'},\n",
       " {'image_id': tensor(443949),\n",
       "  'caption': 'a kitchen with a stove and a refrigerator'},\n",
       " {'image_id': tensor(223094),\n",
       "  'caption': 'a refrigerator with a lot of food inside of it'},\n",
       " {'image_id': tensor(570138),\n",
       "  'caption': 'a bathroom with a toilet sink and mirror'},\n",
       " {'image_id': tensor(557135),\n",
       "  'caption': 'a kitchen with a sink and a refrigerator'},\n",
       " {'image_id': tensor(122302),\n",
       "  'caption': 'a row of parked motorcycles sitting on the side of a street'},\n",
       " {'image_id': tensor(386766),\n",
       "  'caption': 'a bathroom with a sink toilet and bathtub'},\n",
       " {'image_id': tensor(576576),\n",
       "  'caption': 'a bathroom with a toilet sink and mirror'},\n",
       " {'image_id': tensor(445812),\n",
       "  'caption': 'a bathroom with a sink and a toilet'},\n",
       " {'image_id': tensor(231732),\n",
       "  'caption': 'a bathroom with a sink and a mirror'},\n",
       " {'image_id': tensor(416184),\n",
       "  'caption': 'a bathroom with a toilet and a shower'},\n",
       " {'image_id': tensor(290078),\n",
       "  'caption': 'a white toilet sitting on the side of a road'},\n",
       " {'image_id': tensor(372495),\n",
       "  'caption': 'a bathroom with a toilet and a sink'},\n",
       " {'image_id': tensor(262514),\n",
       "  'caption': 'a white toilet sitting next to a walk in shower'},\n",
       " {'image_id': tensor(294763),\n",
       "  'caption': 'a white toilet sitting in a bathroom next to a tiled wall'},\n",
       " {'image_id': tensor(489624),\n",
       "  'caption': 'a toilet with a wooden seat and a white sink'},\n",
       " {'image_id': tensor(578314),\n",
       "  'caption': 'a white toilet in a very small room'},\n",
       " {'image_id': tensor(131504),\n",
       "  'caption': 'a clock tower with a large clock on its face'},\n",
       " {'image_id': tensor(50443), 'caption': 'a bathroom with a toilet and a sink'},\n",
       " {'image_id': tensor(84064),\n",
       "  'caption': 'a toilet with the lid up and a device on the wall'},\n",
       " {'image_id': tensor(185930), 'caption': 'a row of urinals mounted to a wall'},\n",
       " {'image_id': tensor(355221),\n",
       "  'caption': 'a row of parked motorcycles sitting on top of a street'},\n",
       " {'image_id': tensor(223930),\n",
       "  'caption': 'a motorcycle parked on the side of a street'},\n",
       " {'image_id': tensor(348708),\n",
       "  'caption': 'a plate with a bunch of bananas on it'},\n",
       " {'image_id': tensor(324008),\n",
       "  'caption': 'a tray of food with a sandwich and a bag of chips'},\n",
       " {'image_id': tensor(520108), 'caption': 'a bedroom with a bed and a table'},\n",
       " {'image_id': tensor(573756),\n",
       "  'caption': 'a giraffe standing in the middle of a lush green field'},\n",
       " {'image_id': tensor(188173),\n",
       "  'caption': 'a group of giraffes standing in a field'},\n",
       " {'image_id': tensor(233882),\n",
       "  'caption': 'a red and white plane sitting on a runway'},\n",
       " {'image_id': tensor(413734),\n",
       "  'caption': 'a large jetliner sitting on top of an airport tarmac'},\n",
       " {'image_id': tensor(373846),\n",
       "  'caption': 'a large jetliner sitting on top of an airport tarmac'},\n",
       " {'image_id': tensor(189197),\n",
       "  'caption': 'a person walking on a path near a body of water'},\n",
       " {'image_id': tensor(122007),\n",
       "  'caption': 'two giraffes standing in a field with mountains in the background'},\n",
       " {'image_id': tensor(181948),\n",
       "  'caption': 'a street with cars and street signs and trees'},\n",
       " {'image_id': tensor(315128),\n",
       "  'caption': 'a street sign on a street corner with a sky background'},\n",
       " {'image_id': tensor(199247),\n",
       "  'caption': 'a herd of sheep grazing on a lush green field'},\n",
       " {'image_id': tensor(974),\n",
       "  'caption': 'a group of people riding on the back of an elephant'},\n",
       " {'image_id': tensor(137265),\n",
       "  'caption': 'a red umbrella sitting on top of a white building'},\n",
       " {'image_id': tensor(507921),\n",
       "  'caption': 'a no parking sign on a pole on a city street'},\n",
       " {'image_id': tensor(40621),\n",
       "  'caption': 'a giraffe standing in a dirt field next to a fence'},\n",
       " {'image_id': tensor(262175),\n",
       "  'caption': 'a man wearing a hat and holding a frisbee'},\n",
       " {'image_id': tensor(548538),\n",
       "  'caption': 'a train traveling down tracks next to a forest'},\n",
       " {'image_id': tensor(65981),\n",
       "  'caption': 'a train traveling down tracks next to a forest'},\n",
       " {'image_id': tensor(167510),\n",
       "  'caption': 'a stop sign is shown on a street corner'},\n",
       " {'image_id': tensor(45966), 'caption': 'a sign on a pole on a street'},\n",
       " {'image_id': tensor(51961),\n",
       "  'caption': 'a graffiti covered wall with graffiti on it'},\n",
       " {'image_id': tensor(457900),\n",
       "  'caption': 'a bus is parked outside of a building'},\n",
       " {'image_id': tensor(71090),\n",
       "  'caption': 'a stuffed animal sitting on a window sill'},\n",
       " {'image_id': tensor(186518),\n",
       "  'caption': 'a large yellow train on a steel track'},\n",
       " {'image_id': tensor(576084),\n",
       "  'caption': 'a white horse standing next to a white horse'},\n",
       " {'image_id': tensor(342334),\n",
       "  'caption': 'a harbor filled with lots of small boats'},\n",
       " {'image_id': tensor(370749),\n",
       "  'caption': 'a large elephant walking in a grass field'},\n",
       " {'image_id': tensor(42055),\n",
       "  'caption': 'a blue and white umbrella sitting in the middle of a street'},\n",
       " {'image_id': tensor(21864),\n",
       "  'caption': 'a view of a body of water with a sky in the background'},\n",
       " {'image_id': tensor(412813),\n",
       "  'caption': 'a person sitting under an umbrella on the beach'},\n",
       " {'image_id': tensor(532867),\n",
       "  'caption': 'a woman holding a red umbrella on the beach'},\n",
       " {'image_id': tensor(550051),\n",
       "  'caption': 'a group of people sitting at a table with a red umbrella'},\n",
       " {'image_id': tensor(303215),\n",
       "  'caption': 'a white teddy bear hanging from a wire'},\n",
       " {'image_id': tensor(446522),\n",
       "  'caption': 'a dog is sitting on a couch in a living room'},\n",
       " {'image_id': tensor(313398),\n",
       "  'caption': 'a black dog laying on a yellow frisbee next to a plastic toy'},\n",
       " {'image_id': tensor(424812),\n",
       "  'caption': 'a horse and rider in a black and white photo'},\n",
       " {'image_id': tensor(371004),\n",
       "  'caption': 'a zebra standing next to a fence in a field'},\n",
       " {'image_id': tensor(546095),\n",
       "  'caption': 'a group of horses grazing in a field'},\n",
       " {'image_id': tensor(51540),\n",
       "  'caption': 'a large clock sitting on a table in a store'},\n",
       " {'image_id': tensor(307967),\n",
       "  'caption': 'a young boy holding a baseball bat on a field'},\n",
       " {'image_id': tensor(248980),\n",
       "  'caption': 'a plate of food with broccoli and a fork'},\n",
       " {'image_id': tensor(277440),\n",
       "  'caption': 'a computer desk with a computer on top of it'},\n",
       " {'image_id': tensor(40635),\n",
       "  'caption': 'a fruit stand with a wide variety of fruits and vegetables'},\n",
       " {'image_id': tensor(503595),\n",
       "  'caption': 'a plate of food with a fork and a fork'},\n",
       " {'image_id': tensor(126257),\n",
       "  'caption': 'a young boy riding a skateboard on a street'},\n",
       " {'image_id': tensor(118367),\n",
       "  'caption': 'a person holding a hot dog in their hand'},\n",
       " {'image_id': tensor(437789),\n",
       "  'caption': 'a table with various foods and fruits and a bowl of fruit'},\n",
       " {'image_id': tensor(272323),\n",
       "  'caption': 'a skateboarder is riding down a ramp on his skateboard'},\n",
       " {'image_id': tensor(70256), 'caption': 'a person cutting a cake on a table'},\n",
       " {'image_id': tensor(12817),\n",
       "  'caption': 'a man is doing a trick on a skateboard'},\n",
       " {'image_id': tensor(348730),\n",
       "  'caption': 'a man riding a skateboard down a street'},\n",
       " {'image_id': tensor(114684),\n",
       "  'caption': 'a woman sitting on a bench with a cell phone'},\n",
       " {'image_id': tensor(296236),\n",
       "  'caption': 'a woman is preparing a doughnut in a commercial kitchen'},\n",
       " {'image_id': tensor(412604),\n",
       "  'caption': 'a man in a blue sweater holding a banana'},\n",
       " {'image_id': tensor(523816),\n",
       "  'caption': 'a person on a snowboard on a snowy hill'},\n",
       " {'image_id': tensor(329475),\n",
       "  'caption': 'a display case filled with lots of donuts'},\n",
       " {'image_id': tensor(61647),\n",
       "  'caption': 'a cake with a bunch of cupcakes on top'},\n",
       " {'image_id': tensor(88269),\n",
       "  'caption': 'a plate with a sandwich and a bowl of soup'},\n",
       " {'image_id': tensor(211326),\n",
       "  'caption': 'a plate with a sandwich and a cup of coffee'},\n",
       " {'image_id': tensor(48668),\n",
       "  'caption': 'a man laying in bed with a blanket and a pillow'},\n",
       " {'image_id': tensor(308883),\n",
       "  'caption': 'a living room with a television and a couch'},\n",
       " {'image_id': tensor(193494),\n",
       "  'caption': 'a bed with a blue blanket and a blue blanket'},\n",
       " {'image_id': tensor(184139),\n",
       "  'caption': 'a bed with a white bedspread and a green light'},\n",
       " {'image_id': tensor(419860), 'caption': 'a large pizza that is on a table'},\n",
       " {'image_id': tensor(388481),\n",
       "  'caption': 'a laptop computer sitting on top of a wooden desk'},\n",
       " {'image_id': tensor(97561),\n",
       "  'caption': 'a small bathroom with a sink and mirror'},\n",
       " {'image_id': tensor(70020),\n",
       "  'caption': 'a woman holding a tennis racket on a tennis court'},\n",
       " {'image_id': tensor(466882),\n",
       "  'caption': 'a tennis player is serving the ball in a tennis match'},\n",
       " {'image_id': tensor(323356),\n",
       "  'caption': 'a man holding a blue frisbee while standing in a field'},\n",
       " {'image_id': tensor(405440),\n",
       "  'caption': 'a laptop computer sitting on top of a wooden desk'},\n",
       " {'image_id': tensor(148329), 'caption': 'a man eating a hot dog in a bun'},\n",
       " {'image_id': tensor(279524),\n",
       "  'caption': 'a living room with a couch and a tv'},\n",
       " {'image_id': tensor(91304),\n",
       "  'caption': 'a bed with a wooden head board and a small bed'},\n",
       " {'image_id': tensor(315486),\n",
       "  'caption': 'a little girl standing in front of a sink'},\n",
       " {'image_id': tensor(365325),\n",
       "  'caption': 'a baby sleeping on a bed with a blue blanket'},\n",
       " {'image_id': tensor(79686),\n",
       "  'caption': 'a living room with a couch a table and a tv'},\n",
       " {'image_id': tensor(499095),\n",
       "  'caption': 'a group of people playing a game with remote controllers'},\n",
       " {'image_id': tensor(35825),\n",
       "  'caption': 'a woman holding a nintendo wii game controller'},\n",
       " {'image_id': tensor(414071),\n",
       "  'caption': 'three young men standing in a living room holding wii remotes'},\n",
       " {'image_id': tensor(520430),\n",
       "  'caption': 'a woman holding a wii remote in her hand'},\n",
       " {'image_id': tensor(4125),\n",
       "  'caption': 'a living room with a couch and a coffee table'},\n",
       " {'image_id': tensor(487774), 'caption': 'a mouse and a keyboard on a table'},\n",
       " {'image_id': tensor(157516),\n",
       "  'caption': 'a man and a child are sitting on a coach'},\n",
       " {'image_id': tensor(217957),\n",
       "  'caption': 'a building with a clock on the front and side of it'},\n",
       " {'image_id': tensor(415727), 'caption': 'a group of kids standing in a room'},\n",
       " {'image_id': tensor(251367),\n",
       "  'caption': 'a baseball player holding a bat on a field'},\n",
       " {'image_id': tensor(148588),\n",
       "  'caption': 'a pizza sitting on top of a wooden table'},\n",
       " {'image_id': tensor(93765),\n",
       "  'caption': 'a coffee cup and a vase of flowers on a table'},\n",
       " {'image_id': tensor(488736),\n",
       "  'caption': 'a large clock on the side of a building'},\n",
       " {'image_id': tensor(324837),\n",
       "  'caption': 'a laptop computer sitting on top of a wooden desk'},\n",
       " {'image_id': tensor(63602),\n",
       "  'caption': 'a computer desk with a laptop computer on top of it'},\n",
       " {'image_id': tensor(33904),\n",
       "  'caption': 'a teddy bear sitting on a couch with a book'},\n",
       " {'image_id': tensor(445041),\n",
       "  'caption': 'a man riding a motorcycle down a street'},\n",
       " {'image_id': tensor(54959),\n",
       "  'caption': 'a kitchen with a stove and a microwave'},\n",
       " {'image_id': tensor(299946),\n",
       "  'caption': 'a man in a kitchen preparing food on a cutting board'},\n",
       " {'image_id': tensor(65969),\n",
       "  'caption': 'a table with a glass of water and a vase filled with flowers'},\n",
       " {'image_id': tensor(550322),\n",
       "  'caption': 'a pair of scissors sitting on a table'},\n",
       " {'image_id': tensor(76329), 'caption': 'a clock on a pole on a street'},\n",
       " {'image_id': tensor(368505),\n",
       "  'caption': 'a large building with a clock on the front'},\n",
       " {'image_id': tensor(213224),\n",
       "  'caption': 'a vase of flowers sitting on a table'},\n",
       " {'image_id': tensor(478282),\n",
       "  'caption': 'a vase with flowers in it sitting on a table'},\n",
       " {'image_id': tensor(251590),\n",
       "  'caption': 'a vase filled with flowers sitting on top of a table'},\n",
       " {'image_id': tensor(425475),\n",
       "  'caption': 'a person holding a glass of wine in their hand'},\n",
       " {'image_id': tensor(448795),\n",
       "  'caption': 'a view of a bathroom with a toilet and sink'},\n",
       " {'image_id': tensor(345389),\n",
       "  'caption': 'a woman standing in a kitchen with a blue towel'},\n",
       " {'image_id': tensor(280736),\n",
       "  'caption': 'a cat sitting on a ledge looking up at a person'},\n",
       " {'image_id': tensor(45208), 'caption': 'a black cat is standing in the sink'},\n",
       " {'image_id': tensor(557501),\n",
       "  'caption': 'a bathroom with a toilet and a sink'},\n",
       " {'image_id': tensor(496604),\n",
       "  'caption': 'a white toilet sitting next to a white sink'},\n",
       " {'image_id': tensor(46099), 'caption': 'a stop sign on a pole on a street'},\n",
       " {'image_id': tensor(144798),\n",
       "  'caption': 'a bathroom with a toilet sink and mirror'},\n",
       " {'image_id': tensor(463825), 'caption': 'a cat sitting in a bathroom sink'},\n",
       " {'image_id': tensor(50411), 'caption': 'a man riding a horse down a street'},\n",
       " {'image_id': tensor(524637),\n",
       "  'caption': 'a white toilet sitting in a bathroom next to a window'},\n",
       " {'image_id': tensor(562592),\n",
       "  'caption': 'a motorcycle is parked on the side of the road'},\n",
       " {'image_id': tensor(465424),\n",
       "  'caption': 'a group of people on motorcycles are parked on the side of the'},\n",
       " {'image_id': tensor(425151),\n",
       "  'caption': 'a living room with a couch and a coffee table'},\n",
       " {'image_id': tensor(210032),\n",
       "  'caption': 'a chicken sandwich and a cup of water on a table'},\n",
       " {'image_id': tensor(21202),\n",
       "  'caption': 'a street with cars and traffic lights on it'},\n",
       " {'image_id': tensor(398007),\n",
       "  'caption': 'a train station with a train coming up the tracks'},\n",
       " {'image_id': tensor(322824),\n",
       "  'caption': 'a street sign on a pole on a city street'},\n",
       " {'image_id': tensor(376236),\n",
       "  'caption': 'a young boy feeding a giraffe from a wooden fence'},\n",
       " {'image_id': tensor(468933),\n",
       "  'caption': 'a herd of sheep standing on top of a grass covered field'},\n",
       " {'image_id': tensor(68203),\n",
       "  'caption': 'a giraffe standing in a field with a mountain in the background'},\n",
       " {'image_id': tensor(197745),\n",
       "  'caption': 'two giraffes are standing next to each other'},\n",
       " {'image_id': tensor(352476),\n",
       "  'caption': 'a group of bicycles are parked next to a bus'},\n",
       " {'image_id': tensor(89909),\n",
       "  'caption': 'a wooden bench sitting in front of a garden'},\n",
       " {'image_id': tensor(38048),\n",
       "  'caption': 'a red and white fire hydrant sitting on the side of a road'},\n",
       " {'image_id': tensor(322955),\n",
       "  'caption': 'a bird standing on the beach looking out at the ocean'},\n",
       " {'image_id': tensor(211054),\n",
       "  'caption': 'a train traveling down tracks next to a building'},\n",
       " {'image_id': tensor(500703),\n",
       "  'caption': 'a train is traveling down the tracks in a city'},\n",
       " {'image_id': tensor(340637),\n",
       "  'caption': 'a cell phone sitting on a table next to a cell phone'},\n",
       " {'image_id': tensor(174329),\n",
       "  'caption': 'a yellow train is sitting on the tracks'},\n",
       " {'image_id': tensor(499537),\n",
       "  'caption': 'a street sign on a pole on a city street'},\n",
       " {'image_id': tensor(206770),\n",
       "  'caption': 'a truck is parked in front of a house'},\n",
       " {'image_id': tensor(67255),\n",
       "  'caption': 'a stop sign with a street sign on top of it'},\n",
       " {'image_id': tensor(258078),\n",
       "  'caption': 'a young boy is standing next to a bike'},\n",
       " {'image_id': tensor(171695),\n",
       "  'caption': 'a large bus with a colorful roof driving down a street'},\n",
       " {'image_id': tensor(79816), 'caption': 'a truck is parked in a dirt lot'},\n",
       " {'image_id': tensor(90366),\n",
       "  'caption': 'a couple of animals that are standing in the dirt'},\n",
       " {'image_id': tensor(76155),\n",
       "  'caption': 'a large group of cows standing in a field'},\n",
       " {'image_id': tensor(350084),\n",
       "  'caption': 'a white dump truck driving down a dirt road'},\n",
       " {'image_id': tensor(103272),\n",
       "  'caption': 'a large truck with a wooden deck parked in a field'},\n",
       " {'image_id': tensor(519764),\n",
       "  'caption': 'a black cat laying on a chair in a room'},\n",
       " {'image_id': tensor(450404),\n",
       "  'caption': 'a large truck parked in a field with a fence'},\n",
       " {'image_id': tensor(436676),\n",
       "  'caption': 'a woman laying on a couch with a black cat'},\n",
       " {'image_id': tensor(238459),\n",
       "  'caption': 'a herd of cattle grazing on a lush green field'},\n",
       " {'image_id': tensor(565186),\n",
       "  'caption': 'a large truck with a wooden fence in the back'},\n",
       " {'image_id': tensor(464286),\n",
       "  'caption': 'a herd of cattle standing on top of a pile of hay'},\n",
       " {'image_id': tensor(87470), 'caption': 'a herd of cows walking down a road'},\n",
       " {'image_id': tensor(16005),\n",
       "  'caption': 'a woman is holding a child in a hat as a cow looks'},\n",
       " {'image_id': tensor(163684),\n",
       "  'caption': 'a dog is running in the snow with a frisbee'},\n",
       " {'image_id': tensor(14257),\n",
       "  'caption': 'a group of people walking down a sidewalk'},\n",
       " {'image_id': tensor(533979),\n",
       "  'caption': 'a baby elephant standing next to a large metal fence'},\n",
       " {'image_id': tensor(419344),\n",
       "  'caption': 'a group of people standing around a herd of elephants'},\n",
       " {'image_id': tensor(148188),\n",
       "  'caption': 'a group of people riding on the backs of horses'},\n",
       " {'image_id': tensor(318080),\n",
       "  'caption': 'two bears are playing together in a body of water'},\n",
       " {'image_id': tensor(361551),\n",
       "  'caption': 'a group of people standing around a luggage cart'},\n",
       " {'image_id': tensor(306664),\n",
       "  'caption': 'a polar bear is walking around in the dirt'},\n",
       " {'image_id': tensor(121876), 'caption': 'a polar bear is standing on a rock'},\n",
       " {'image_id': tensor(236784),\n",
       "  'caption': 'two dogs are laying on a couch in a living room'},\n",
       " {'image_id': tensor(406976),\n",
       "  'caption': 'two dogs are laying on a couch with their faces on their faces'},\n",
       " {'image_id': tensor(18480),\n",
       "  'caption': 'a group of people holding frisbees and posing for a picture'},\n",
       " {'image_id': tensor(110435),\n",
       "  'caption': 'a woman is giving a baby a bath in the sink'},\n",
       " {'image_id': tensor(347650), 'caption': 'a dog laying on a bed with a book'},\n",
       " {'image_id': tensor(440895),\n",
       "  'caption': 'a building with a window and a clock on the side of the'},\n",
       " {'image_id': tensor(451305),\n",
       "  'caption': 'a zebra standing on a dirt ground next to a wooden fence'},\n",
       " {'image_id': tensor(431521),\n",
       "  'caption': 'a view of a field with a fence in the distance'},\n",
       " {'image_id': tensor(361919),\n",
       "  'caption': 'a group of people riding skis on a snowy surface'},\n",
       " {'image_id': tensor(424174),\n",
       "  'caption': 'a bunch of fruit sitting on a table'},\n",
       " {'image_id': tensor(332096),\n",
       "  'caption': 'a group of men playing baseball on a field'},\n",
       " {'image_id': tensor(158722),\n",
       "  'caption': 'a woman sitting on a bench in front of a store'},\n",
       " {'image_id': tensor(394801), 'caption': 'a bunch of bananas are on a table'},\n",
       " {'image_id': tensor(498439),\n",
       "  'caption': 'a group of baseball players standing on top of a field'},\n",
       " {'image_id': tensor(374369),\n",
       "  'caption': 'a person riding skis on a snowy surface'},\n",
       " {'image_id': tensor(313176),\n",
       "  'caption': 'a pizza with cheese and tomatoes on a pan'},\n",
       " {'image_id': tensor(556726),\n",
       "  'caption': 'a close up of a broccoli on a wooden surface'},\n",
       " {'image_id': tensor(123321),\n",
       "  'caption': 'a bowl of soup with broccoli and a spoon'},\n",
       " {'image_id': tensor(539079),\n",
       "  'caption': 'a person riding skis on a snowy slope'},\n",
       " {'image_id': tensor(36238),\n",
       "  'caption': 'a plate of food with broccoli and meat'},\n",
       " {'image_id': tensor(520508),\n",
       "  'caption': 'a person riding skis on a snowy surface'},\n",
       " {'image_id': tensor(149456),\n",
       "  'caption': 'a bunch of vegetables are sitting on a table'},\n",
       " {'image_id': tensor(414385),\n",
       "  'caption': 'a person riding a motorcycle on a highway'},\n",
       " {'image_id': tensor(497907),\n",
       "  'caption': 'a person on a snowboard on a snowy hill'},\n",
       " {'image_id': tensor(146272),\n",
       "  'caption': 'a person on a snowboard on a snowy slope'},\n",
       " {'image_id': tensor(320664),\n",
       "  'caption': 'a plate of food with a fork and a cup of coleslaw'},\n",
       " {'image_id': tensor(190391),\n",
       "  'caption': 'a hot dog with mustard and ketchup on a plate'},\n",
       " {'image_id': tensor(183786),\n",
       "  'caption': 'a group of doughnuts are sitting on a table'},\n",
       " {'image_id': tensor(325027),\n",
       "  'caption': 'a person holding a sandwich in their hand'},\n",
       " {'image_id': tensor(62230),\n",
       "  'caption': 'a group of men playing a game of basketball'},\n",
       " {'image_id': tensor(410885),\n",
       "  'caption': 'a group of people riding surfboards on top of a sandy beach'},\n",
       " {'image_id': tensor(810),\n",
       "  'caption': 'a hot dog with a side of fries and a drink'},\n",
       " {'image_id': tensor(276434), 'caption': 'a person cutting a cake on a table'},\n",
       " {'image_id': tensor(566529),\n",
       "  'caption': 'a man laying in a bed with a stuffed animal'},\n",
       " {'image_id': tensor(375285),\n",
       "  'caption': 'a group of people standing on a beach with surfboards'},\n",
       " {'image_id': tensor(105234),\n",
       "  'caption': 'a man and woman in a white dress and a man in a'},\n",
       " {'image_id': tensor(203734),\n",
       "  'caption': 'three young boys sitting on a bench eating pizza'},\n",
       " {'image_id': tensor(526972),\n",
       "  'caption': 'a pizza with several toppings on a rack'},\n",
       " {'image_id': tensor(478528),\n",
       "  'caption': 'a living room with a couch and a table'},\n",
       " {'image_id': tensor(4312),\n",
       "  'caption': 'a person sitting at a table with a plate of food'},\n",
       " {'image_id': tensor(410101),\n",
       "  'caption': 'a man standing in a room with a remote'},\n",
       " {'image_id': tensor(514787),\n",
       "  'caption': 'a group of people playing a game with remote controllers'},\n",
       " {'image_id': tensor(26584),\n",
       "  'caption': 'a hand holding a wii game controller in front of a tv'},\n",
       " {'image_id': tensor(546964),\n",
       "  'caption': 'a large room with a lot of chairs and tables'},\n",
       " {'image_id': tensor(164759),\n",
       "  'caption': 'a living room with a couch and a tv'},\n",
       " {'image_id': tensor(361527),\n",
       "  'caption': 'a computer monitor sitting on top of a wooden desk'},\n",
       " {'image_id': tensor(281782), 'caption': 'a man flying a kite in a yard'},\n",
       " {'image_id': tensor(579307),\n",
       "  'caption': 'two young children carrying their surfboards on the beach'},\n",
       " {'image_id': tensor(291962),\n",
       "  'caption': 'a young girl flying a kite in a field'},\n",
       " {'image_id': tensor(162445),\n",
       "  'caption': 'a group of people in a field flying kites'},\n",
       " {'image_id': tensor(136642),\n",
       "  'caption': 'a baseball player holding a bat on a field'},\n",
       " {'image_id': tensor(138553),\n",
       "  'caption': 'a baseball player holding a bat on a baseball field'},\n",
       " {'image_id': tensor(54593),\n",
       "  'caption': 'a young boy swinging a bat at a ball'},\n",
       " {'image_id': tensor(520787),\n",
       "  'caption': 'a slice of pizza on a plate with a fork and knife'},\n",
       " {'image_id': tensor(525646),\n",
       "  'caption': 'a pizza with a lot of veggies on it'},\n",
       " {'image_id': tensor(116208),\n",
       "  'caption': 'a large pizza with several toppings on a table'},\n",
       " {'image_id': tensor(208623),\n",
       "  'caption': 'a man sitting at a table using a laptop computer'},\n",
       " {'image_id': tensor(493623),\n",
       "  'caption': 'a white toilet sitting next to a white bath tub'},\n",
       " {'image_id': tensor(191069),\n",
       "  'caption': 'a person holding a cell phone in their hand'},\n",
       " {'image_id': tensor(221700),\n",
       "  'caption': 'a pair of scissors sitting on top of a table'},\n",
       " {'image_id': tensor(318290),\n",
       "  'caption': 'a microwave oven sitting on top of a table'},\n",
       " {'image_id': tensor(149500),\n",
       "  'caption': 'a man is sitting on a couch and holding a toothbrush'},\n",
       " {'image_id': tensor(205720),\n",
       "  'caption': 'a man is taking a picture of a boat'},\n",
       " {'image_id': tensor(309933),\n",
       "  'caption': 'a kitchen with a stove and a refrigerator'},\n",
       " {'image_id': tensor(233376),\n",
       "  'caption': 'a refrigerator and freezer in a small kitchen'},\n",
       " {'image_id': tensor(452881),\n",
       "  'caption': 'a room with a bed and a table with a vase on it'},\n",
       " {'image_id': tensor(292804),\n",
       "  'caption': 'a large clock on a wall in a train station'},\n",
       " {'image_id': tensor(321437), 'caption': 'a clock on a pole on a city street'},\n",
       " {'image_id': tensor(108853),\n",
       "  'caption': 'a vase of flowers sitting on a table'},\n",
       " {'image_id': tensor(410880),\n",
       "  'caption': 'a teddy bear sitting on a table in a room'},\n",
       " {'image_id': tensor(135399),\n",
       "  'caption': 'a table topped with plates of food and cups of coffee'},\n",
       " {'image_id': tensor(349184),\n",
       "  'caption': 'a woman sitting on a bench with her legs crossed'},\n",
       " {'image_id': tensor(130909),\n",
       "  'caption': 'a man and woman in a kitchen with a stove and a sink'},\n",
       " {'image_id': tensor(369913),\n",
       "  'caption': 'a woman holding a pair of scissors in her hands'},\n",
       " {'image_id': tensor(404462),\n",
       "  'caption': 'a black and white photo of a bathroom mirror'},\n",
       " {'image_id': tensor(300034),\n",
       "  'caption': 'a bathroom with a white toilet sitting next to a sink'},\n",
       " {'image_id': tensor(380854),\n",
       "  'caption': 'a bathroom with a toilet sink and mirror'},\n",
       " {'image_id': tensor(511583),\n",
       "  'caption': 'a car parked on the side of the road'},\n",
       " {'image_id': tensor(210273),\n",
       "  'caption': 'a busy street with cars and buses on it'},\n",
       " {'image_id': tensor(161112),\n",
       "  'caption': 'a man sitting on a couch with a cat'},\n",
       " {'image_id': tensor(120428),\n",
       "  'caption': 'a woman standing in a room with a wooden floor'},\n",
       " {'image_id': tensor(215408),\n",
       "  'caption': 'a large church tower with a clock on it'},\n",
       " {'image_id': tensor(46571),\n",
       "  'caption': 'a motorcycle parked on the side of a road'},\n",
       " {'image_id': tensor(542509),\n",
       "  'caption': 'a computer desk with a computer and a computer'},\n",
       " {'image_id': tensor(556349),\n",
       "  'caption': 'a red motorcycle parked on a sidewalk near a street'},\n",
       " {'image_id': tensor(475923),\n",
       "  'caption': 'a blue door with a door open and a white toilet'},\n",
       " {'image_id': tensor(534733),\n",
       "  'caption': 'a living room with a couch and a tv'},\n",
       " {'image_id': tensor(82229),\n",
       "  'caption': 'a television is on a stand in a room'},\n",
       " {'image_id': tensor(52017), 'caption': 'a small plane is flying in the air'},\n",
       " {'image_id': tensor(238700),\n",
       "  'caption': 'a giraffe standing in a field with lots of green grass'},\n",
       " {'image_id': tensor(526645),\n",
       "  'caption': 'a giraffe standing in the middle of a forest'},\n",
       " {'image_id': tensor(577866),\n",
       "  'caption': 'a man riding a bike down a street next to a truck'},\n",
       " {'image_id': tensor(361400),\n",
       "  'caption': 'a traffic light on a city street at night'},\n",
       " {'image_id': tensor(535578),\n",
       "  'caption': 'a herd of sheep grazing on a lush green hillside'},\n",
       " {'image_id': tensor(263011),\n",
       "  'caption': 'a group of people standing in front of a bus'},\n",
       " {'image_id': tensor(122051), 'caption': 'a car is stopped at a stop sign'},\n",
       " {'image_id': tensor(473171),\n",
       "  'caption': 'a stop sign on a street corner near a house'},\n",
       " {'image_id': tensor(150576),\n",
       "  'caption': 'a giraffe and a zebra are in a grassy field'},\n",
       " {'image_id': tensor(458560),\n",
       "  'caption': 'a bird standing on the ground in the water'},\n",
       " {'image_id': tensor(74465),\n",
       "  'caption': 'a train traveling down tracks next to a building'},\n",
       " {'image_id': tensor(393942),\n",
       "  'caption': 'a black and white photo of a person riding a train'},\n",
       " {'image_id': tensor(56983), 'caption': 'a bird flying over a bunch of birds'},\n",
       " {'image_id': tensor(144715),\n",
       "  'caption': 'a train traveling down tracks next to a forest'},\n",
       " {'image_id': tensor(199257),\n",
       "  'caption': 'a street sign on a pole on a street'},\n",
       " {'image_id': tensor(517967),\n",
       "  'caption': 'a woman in a hat is sitting on a laptop'},\n",
       " {'image_id': tensor(448786),\n",
       "  'caption': 'a white and blue train is on a train track'},\n",
       " {'image_id': tensor(506416),\n",
       "  'caption': 'a red and white train traveling down train tracks'},\n",
       " {'image_id': tensor(25747),\n",
       "  'caption': 'a red and white train on tracks next to trees'},\n",
       " {'image_id': tensor(224554),\n",
       "  'caption': 'a red and yellow train traveling down train tracks'},\n",
       " {'image_id': tensor(25550),\n",
       "  'caption': 'a group of people standing around a street'},\n",
       " {'image_id': tensor(128528),\n",
       "  'caption': 'a dog running in the snow with a frisbee'},\n",
       " {'image_id': tensor(153966),\n",
       "  'caption': 'a black and white cat laying on a bed'},\n",
       " {'image_id': tensor(480720),\n",
       "  'caption': 'two cats looking at each other through a mirror'},\n",
       " {'image_id': tensor(93803),\n",
       "  'caption': 'a construction site with a train going over it'},\n",
       " {'image_id': tensor(310618),\n",
       "  'caption': 'a giraffe eating leaves from a tree in a field'},\n",
       " {'image_id': tensor(290839),\n",
       "  'caption': 'a group of people standing on a boat in the water'},\n",
       " {'image_id': tensor(476552),\n",
       "  'caption': 'a woman standing in a boat filled with produce'},\n",
       " {'image_id': tensor(111109),\n",
       "  'caption': 'a young boy wearing a tie and holding a tennis racket'},\n",
       " {'image_id': tensor(542388),\n",
       "  'caption': 'a man in a suit and tie wearing a suit and tie'},\n",
       " {'image_id': tensor(135281),\n",
       "  'caption': 'a woman walking down a street holding an umbrella'},\n",
       " {'image_id': tensor(152252),\n",
       "  'caption': 'a large group of people standing in front of a building'},\n",
       " {'image_id': tensor(292685),\n",
       "  'caption': 'a group of people standing around a red and white building'},\n",
       " {'image_id': tensor(1682),\n",
       "  'caption': 'a boat is floating in the water near the shore'},\n",
       " {'image_id': tensor(360960),\n",
       "  'caption': 'a group of people walking down a sidewalk holding umbrellas'},\n",
       " {'image_id': tensor(456690),\n",
       "  'caption': 'a group of zebras grazing in a field'},\n",
       " {'image_id': tensor(31390),\n",
       "  'caption': 'a group of young men playing a game of soccer'},\n",
       " {'image_id': tensor(303267),\n",
       "  'caption': 'a couple of animals that are in the grass'},\n",
       " {'image_id': tensor(23034),\n",
       "  'caption': 'a man with a backpack and a dog on a leash'},\n",
       " {'image_id': tensor(359838),\n",
       "  'caption': 'a group of horses standing in a field'},\n",
       " {'image_id': tensor(377984),\n",
       "  'caption': 'a young girl riding on the back of a black horse'},\n",
       " {'image_id': tensor(546854),\n",
       "  'caption': 'a table with a plate of fruit and a bowl of oranges'},\n",
       " {'image_id': tensor(333156),\n",
       "  'caption': 'a chocolate cake with a piece cut out of it'},\n",
       " {'image_id': tensor(78959),\n",
       "  'caption': 'a bunch of bananas hanging from a tree'},\n",
       " {'image_id': tensor(229274),\n",
       "  'caption': 'a bunch of bananas hanging from a tree'},\n",
       " {'image_id': tensor(66179),\n",
       "  'caption': 'a bunch of apples hanging from a banana tree'},\n",
       " {'image_id': tensor(378098),\n",
       "  'caption': 'a plate of food with a fork and knife'},\n",
       " {'image_id': tensor(377111),\n",
       "  'caption': 'a man riding a skateboard on a ramp'},\n",
       " {'image_id': tensor(439092),\n",
       "  'caption': 'two people standing in the snow with their snowboards on their feet'},\n",
       " {'image_id': tensor(60970),\n",
       "  'caption': 'a plate of food with broccoli and rice'},\n",
       " {'image_id': tensor(516813),\n",
       "  'caption': 'a young boy riding a snowboard on a snow covered slope'},\n",
       " {'image_id': tensor(292170),\n",
       "  'caption': 'a woman standing in a market filled with lots of red fruit'},\n",
       " {'image_id': tensor(535306),\n",
       "  'caption': 'a man on a skateboard jumping over a metal ramp'},\n",
       " {'image_id': tensor(368528),\n",
       "  'caption': 'a man riding skis down a snow covered slope'},\n",
       " {'image_id': tensor(304834),\n",
       "  'caption': 'a woman riding a skateboard down a sidewalk'},\n",
       " {'image_id': tensor(536791),\n",
       "  'caption': 'a man is doing a trick on a skateboard'},\n",
       " {'image_id': tensor(302599),\n",
       "  'caption': 'a man on a skateboard jumping over a set of stairs'},\n",
       " {'image_id': tensor(160351),\n",
       "  'caption': 'a man riding a skateboard down a street'},\n",
       " {'image_id': tensor(93353),\n",
       "  'caption': 'a person holding a half eaten sandwich in their hand'},\n",
       " {'image_id': tensor(532211),\n",
       "  'caption': 'a man riding a skateboard down a street'},\n",
       " {'image_id': tensor(220187),\n",
       "  'caption': 'a man is doing a trick on a skateboard'},\n",
       " {'image_id': tensor(391365),\n",
       "  'caption': 'a man flying through the air while riding a skateboard'},\n",
       " {'image_id': tensor(230884),\n",
       "  'caption': 'a man riding a skateboard down a street'},\n",
       " {'image_id': tensor(412464),\n",
       "  'caption': 'a sandwich and salad on a white plate'},\n",
       " {'image_id': tensor(283113),\n",
       "  'caption': 'two hot dogs with ketchup and mustard on a plate'},\n",
       " {'image_id': tensor(138675),\n",
       "  'caption': 'a person on a snowboard on a snowy hill'},\n",
       " {'image_id': tensor(162902),\n",
       "  'caption': 'a group of people standing on top of a snow covered slope'},\n",
       " {'image_id': tensor(571449),\n",
       "  'caption': 'a person holding a sandwich in their hand'},\n",
       " {'image_id': tensor(317725),\n",
       "  'caption': 'a chocolate doughnut with sprinkles on a plate'},\n",
       " {'image_id': tensor(205101),\n",
       "  'caption': 'a sandwich and a glass of beer on a table'},\n",
       " {'image_id': tensor(461378),\n",
       "  'caption': 'a large display of colorful flowers on a table'},\n",
       " {'image_id': tensor(45550),\n",
       "  'caption': 'a man holding a plate with a slice of pizza'},\n",
       " {'image_id': tensor(66685),\n",
       "  'caption': 'a surfboard laying on the sand near the ocean'},\n",
       " {'image_id': tensor(173081),\n",
       "  'caption': 'a group of benches that are sitting in the floor'},\n",
       " {'image_id': tensor(46433),\n",
       "  'caption': 'two children are sitting on a bed with books'},\n",
       " {'image_id': tensor(4916),\n",
       "  'caption': 'a woman and a child standing in front of a mirror'},\n",
       " {'image_id': tensor(476939),\n",
       "  'caption': 'a man and woman in a hospital kitchen'},\n",
       " {'image_id': tensor(31281),\n",
       "  'caption': 'a person riding a surf board on a wave'},\n",
       " {'image_id': tensor(541965),\n",
       "  'caption': 'a table with a plate of pizza and a drink'},\n",
       " {'image_id': tensor(345029),\n",
       "  'caption': 'a woman is playing tennis on a court'},\n",
       " {'image_id': tensor(400317),\n",
       "  'caption': 'a man holding a tennis racquet on a tennis court'},\n",
       " {'image_id': tensor(39697),\n",
       "  'caption': 'a pizza sitting on top of a box on top of a table'},\n",
       " {'image_id': tensor(499755),\n",
       "  'caption': 'a woman in a short skirt holding a tennis racquet'},\n",
       " {'image_id': tensor(233915),\n",
       "  'caption': 'a woman is playing tennis on a blue court'},\n",
       " {'image_id': tensor(557130),\n",
       "  'caption': 'a group of young people standing around holding game controllers'},\n",
       " {'image_id': tensor(121611),\n",
       "  'caption': 'a living room with a couch and a table'},\n",
       " {'image_id': tensor(1655),\n",
       "  'caption': 'a man in a red jacket is looking at a cellphone'},\n",
       " {'image_id': tensor(339426),\n",
       "  'caption': 'a baseball player swinging a bat at a ball'},\n",
       " {'image_id': tensor(235836),\n",
       "  'caption': 'a young boy holding a baseball bat and ball'},\n",
       " {'image_id': tensor(322222),\n",
       "  'caption': 'two men playing tennis on a tennis court'},\n",
       " {'image_id': tensor(471015),\n",
       "  'caption': 'a group of people walking down a street'},\n",
       " {'image_id': tensor(515755),\n",
       "  'caption': 'a large brown teddy bear sitting on top of a couch'},\n",
       " {'image_id': tensor(117089),\n",
       "  'caption': 'a plate of food with a sandwich and a cup of coffee'},\n",
       " {'image_id': tensor(290843),\n",
       "  'caption': 'a cat laying on a bed with a laptop on a table'},\n",
       " {'image_id': tensor(11156),\n",
       "  'caption': 'a table with a cell phone a camera and a bag of things'},\n",
       " {'image_id': tensor(545734),\n",
       "  'caption': 'a kitchen with a microwave and a stove top oven'},\n",
       " {'image_id': tensor(128812),\n",
       "  'caption': 'a stove with a microwave on top of it'},\n",
       " {'image_id': tensor(433574),\n",
       "  'caption': 'a man is sitting in a chair with a cell phone'},\n",
       " {'image_id': tensor(525297),\n",
       "  'caption': 'a person taking a picture of a cow with a camera'},\n",
       " {'image_id': tensor(160186),\n",
       "  'caption': 'a man standing in front of a refrigerator in a kitchen'},\n",
       " {'image_id': tensor(544883),\n",
       "  'caption': 'a clock on a building with windows on the front'},\n",
       " {'image_id': tensor(136911),\n",
       "  'caption': 'a plate of food with a sandwich and fruit'},\n",
       " {'image_id': tensor(216710),\n",
       "  'caption': 'a bunch of different types of doughnuts on a table'},\n",
       " {'image_id': tensor(478077),\n",
       "  'caption': 'a kitchen with a stove and a checkered floor'},\n",
       " {'image_id': tensor(182279),\n",
       "  'caption': 'a group of people flying kites in a field'},\n",
       " {'image_id': tensor(28506), 'caption': 'a kitchen with a stove and a sink'},\n",
       " {'image_id': tensor(408449),\n",
       "  'caption': 'a couple of people that are walking down the street'},\n",
       " {'image_id': tensor(208871),\n",
       "  'caption': 'a man standing in a kitchen holding a box of pizza'},\n",
       " {'image_id': tensor(556205),\n",
       "  'caption': 'a man standing on a pier looking out at the water'},\n",
       " {'image_id': tensor(49097),\n",
       "  'caption': 'a dog walking next to a red bicycle on a sidewalk'},\n",
       " {'image_id': tensor(407915),\n",
       "  'caption': 'a bathroom with a sink and a mirror'},\n",
       " {'image_id': tensor(32990),\n",
       "  'caption': 'a bathroom with a toilet and a shower'},\n",
       " {'image_id': tensor(398606),\n",
       "  'caption': 'a bathroom with a sink and a mirror'},\n",
       " {'image_id': tensor(50350),\n",
       "  'caption': 'a bathroom with a toilet sink and shower'},\n",
       " {'image_id': tensor(553558),\n",
       "  'caption': 'a bathroom with a sink and a toilet'},\n",
       " {'image_id': tensor(124462),\n",
       "  'caption': 'a cat sitting in the drivers seat of a car'},\n",
       " {'image_id': tensor(162677),\n",
       "  'caption': 'a bathroom with a toilet and a sink'},\n",
       " {'image_id': tensor(295051),\n",
       "  'caption': 'a black cat sitting on a shelf in front of a window'},\n",
       " {'image_id': tensor(508302),\n",
       "  'caption': 'a man riding a motorcycle with a woman on back of it'},\n",
       " {'image_id': tensor(175024),\n",
       "  'caption': 'a man riding a motorcycle down a street'},\n",
       " {'image_id': tensor(28675),\n",
       "  'caption': 'a car driving down a street with a green light'},\n",
       " {'image_id': tensor(245450),\n",
       "  'caption': 'a train on a train track with a door open'},\n",
       " {'image_id': tensor(457054),\n",
       "  'caption': 'a white airplane with a green jacket on a runway'},\n",
       " {'image_id': tensor(418106),\n",
       "  'caption': 'a large passenger jet sitting on top of an airport runway'},\n",
       " {'image_id': tensor(575904),\n",
       "  'caption': 'a person riding a skateboard down a street'},\n",
       " {'image_id': tensor(393145),\n",
       "  'caption': 'a giraffe is standing in a field of grass'},\n",
       " {'image_id': tensor(178761),\n",
       "  'caption': 'a couple of cows standing next to a fence'},\n",
       " {'image_id': tensor(556901),\n",
       "  'caption': 'a red and white plane is parked at a dock'},\n",
       " {'image_id': tensor(397045), 'caption': 'a cat is sitting on a window sill'},\n",
       " {'image_id': tensor(115070),\n",
       "  'caption': 'a cat sitting on a cement block with a cat sitting on the'},\n",
       " {'image_id': tensor(450728),\n",
       "  'caption': 'a man riding an elephant down a street'},\n",
       " {'image_id': tensor(158414), 'caption': 'a bus is parked next to a bus stop'},\n",
       " {'image_id': tensor(56248),\n",
       "  'caption': 'a bus is parked on the side of the road'},\n",
       " {'image_id': tensor(96991),\n",
       "  'caption': 'a bench sits in the middle of a lake'},\n",
       " {'image_id': tensor(120767),\n",
       "  'caption': 'a group of people standing around a giraffe'},\n",
       " {'image_id': tensor(145727),\n",
       "  'caption': 'a park with a view of a person sitting on it'},\n",
       " {'image_id': tensor(42070),\n",
       "  'caption': 'a bus is parked on the side of the street'},\n",
       " {'image_id': tensor(85562),\n",
       "  'caption': 'a bus is parked on the side of the road'},\n",
       " {'image_id': tensor(408950),\n",
       "  'caption': 'a red double decker bus driving down a street'},\n",
       " {'image_id': tensor(19158),\n",
       "  'caption': 'a bus parked in a parking lot next to a street'},\n",
       " {'image_id': tensor(9041),\n",
       "  'caption': 'a cat is walking around a flock of birds'},\n",
       " {'image_id': tensor(29465),\n",
       "  'caption': 'a bird sitting on a branch in the snow'},\n",
       " {'image_id': tensor(122606),\n",
       "  'caption': 'a bus is parked on the side of the street'},\n",
       " {'image_id': tensor(15260),\n",
       "  'caption': 'a white and green vase with a white flower'},\n",
       " {'image_id': tensor(342394),\n",
       "  'caption': 'two giraffes are standing next to a pole'},\n",
       " {'image_id': tensor(472833),\n",
       "  'caption': 'a white swan swimming in a lake next to a pond'},\n",
       " {'image_id': tensor(412676),\n",
       "  'caption': 'a large building with a clock on the front'},\n",
       " {'image_id': tensor(571746),\n",
       "  'caption': 'a train traveling down the tracks near a mountain'},\n",
       " {'image_id': tensor(116722),\n",
       "  'caption': 'a train is on the tracks under a bridge'},\n",
       " {'image_id': tensor(553678),\n",
       "  'caption': 'a stop sign is shown in front of a fence'},\n",
       " {'image_id': tensor(370678),\n",
       "  'caption': 'a parking meter on the side of the street'},\n",
       " {'image_id': tensor(476339),\n",
       "  'caption': 'a parking meter sitting on the side of a road'},\n",
       " {'image_id': tensor(535183),\n",
       "  'caption': 'a group of people standing outside of a food truck'},\n",
       " {'image_id': tensor(359791),\n",
       "  'caption': 'a person sitting on a bench next to a body of water'},\n",
       " {'image_id': tensor(182334),\n",
       "  'caption': 'a man in a suit and tie looking at the camera'},\n",
       " {'image_id': tensor(546052), 'caption': 'a man holding a baby in his arms'},\n",
       " {'image_id': tensor(538451),\n",
       "  'caption': 'a large plant in a wooden box sitting on top of a wooden'},\n",
       " {'image_id': tensor(449485),\n",
       "  'caption': 'a person standing in a field with a suitcase'},\n",
       " {'image_id': tensor(74181),\n",
       "  'caption': 'a man standing next to a pile of luggage'},\n",
       " {'image_id': tensor(56013),\n",
       "  'caption': 'a pile of luggage sitting on the ground'},\n",
       " {'image_id': tensor(209544),\n",
       "  'caption': 'a man standing in a field with a frisbee'},\n",
       " {'image_id': tensor(379734),\n",
       "  'caption': 'a group of people playing frisbee in a field'},\n",
       " {'image_id': tensor(424422), 'caption': 'a man holding a frisbee in a park'},\n",
       " {'image_id': tensor(225715), 'caption': 'a bedroom with a bed and a desk'},\n",
       " {'image_id': tensor(26665),\n",
       "  'caption': 'a group of zebras are standing in a field'},\n",
       " {'image_id': tensor(60340),\n",
       "  'caption': 'a zebra standing in a dirt field next to a wooden fence'},\n",
       " {'image_id': tensor(476215),\n",
       "  'caption': 'a group of people standing around a horse'},\n",
       " {'image_id': tensor(74460),\n",
       "  'caption': 'two horses are standing in a field with trees'},\n",
       " {'image_id': tensor(529981), 'caption': 'a group of cows grazing in a field'},\n",
       " {'image_id': tensor(552503), 'caption': 'a pan of food on a stove top'},\n",
       " {'image_id': tensor(575915),\n",
       "  'caption': 'a slice of pizza on a plate on a table'},\n",
       " {'image_id': tensor(483545),\n",
       "  'caption': 'a table full of fruits and vegetables on it'},\n",
       " {'image_id': tensor(525118), 'caption': 'a bunch of bananas are on a table'},\n",
       " {'image_id': tensor(86202), 'caption': 'a person on a snowboard in the snow'},\n",
       " {'image_id': tensor(28582),\n",
       "  'caption': 'a close up of a plate of food with broccoli'},\n",
       " {'image_id': tensor(110156),\n",
       "  'caption': 'a group of people standing on top of a snow covered slope'},\n",
       " {'image_id': tensor(311690),\n",
       "  'caption': 'a plate of food with a glass of wine'},\n",
       " {'image_id': tensor(316240),\n",
       "  'caption': 'a collage of photos showing a lot of trees and a series of'},\n",
       " {'image_id': tensor(232432),\n",
       "  'caption': 'a man and two dogs walking down a sidewalk'},\n",
       " {'image_id': tensor(439651),\n",
       "  'caption': 'a coffee cup sitting on a table in front of a laptop'},\n",
       " {'image_id': tensor(248051),\n",
       "  'caption': 'a person riding a skate board on a street'},\n",
       " {'image_id': tensor(431891),\n",
       "  'caption': 'a bunch of carrots and some carrots on a table'},\n",
       " {'image_id': tensor(6415),\n",
       "  'caption': 'a cutting board with carrots and a knife'},\n",
       " {'image_id': tensor(420666),\n",
       "  'caption': 'a tray with a hot dog and some fries'},\n",
       " {'image_id': tensor(489739),\n",
       "  'caption': 'a little girl is holding a piece of paper'},\n",
       " {'image_id': tensor(571990),\n",
       "  'caption': 'a box filled with lots of different flavored donuts'},\n",
       " {'image_id': tensor(127842),\n",
       "  'caption': 'a man riding a surfboard on a wave in the ocean'},\n",
       " {'image_id': tensor(98003),\n",
       "  'caption': 'a slice of cake on a plate with a fork'},\n",
       " {'image_id': tensor(56651),\n",
       "  'caption': 'a woman holding a birthday cake with lit candles'},\n",
       " {'image_id': tensor(286760),\n",
       "  'caption': 'a white plate topped with a bowl of food'},\n",
       " {'image_id': tensor(452724),\n",
       "  'caption': 'a hotel room with two beds and a television'},\n",
       " {'image_id': tensor(330897),\n",
       "  'caption': 'a pizza with many toppings on a plate'},\n",
       " {'image_id': tensor(425620),\n",
       "  'caption': 'two little kids laying in a bed with stuffed animals'},\n",
       " {'image_id': tensor(565389),\n",
       "  'caption': 'a group of people sitting around a table eating'},\n",
       " {'image_id': tensor(275657),\n",
       "  'caption': 'a table with a white plate with a slice of pizza on it'},\n",
       " {'image_id': tensor(451683),\n",
       "  'caption': 'a large pizza with a slice missing from it'},\n",
       " {'image_id': tensor(95062),\n",
       "  'caption': 'a pizza sitting on top of a white plate on a table'},\n",
       " {'image_id': tensor(371135),\n",
       "  'caption': 'a woman is playing tennis on a tennis court'},\n",
       " {'image_id': tensor(466052),\n",
       "  'caption': 'a cup of coffee sitting on top of a toilet'},\n",
       " {'image_id': tensor(554859),\n",
       "  'caption': 'a living room with a couch and a table'},\n",
       " {'image_id': tensor(321866),\n",
       "  'caption': 'a child is helping a baby put into a bowl'},\n",
       " {'image_id': tensor(526414),\n",
       "  'caption': 'a living room with a couch and a tv'},\n",
       " {'image_id': tensor(534121),\n",
       "  'caption': 'a living room with a couch and a fireplace'},\n",
       " {'image_id': tensor(325211),\n",
       "  'caption': 'a computer keyboard sitting on top of a desk'},\n",
       " {'image_id': tensor(213008),\n",
       "  'caption': 'a bed with a white bedspread and a mirror'},\n",
       " {'image_id': tensor(7556), 'caption': 'a group of people on a body of water'},\n",
       " {'image_id': tensor(402248),\n",
       "  'caption': 'a man is sitting on the ground with a kite'},\n",
       " {'image_id': tensor(122266),\n",
       "  'caption': 'a woman is flying a kite in a field'},\n",
       " {'image_id': tensor(152004), 'caption': 'a glass vase with a flower in it'},\n",
       " {'image_id': tensor(447314), 'caption': 'a woman flying a kite in a park'},\n",
       " {'image_id': tensor(306940),\n",
       "  'caption': 'a baseball player holding a bat on a baseball field'},\n",
       " {'image_id': tensor(47882),\n",
       "  'caption': 'a kitchen with a center island and a large window'},\n",
       " {'image_id': tensor(1573),\n",
       "  'caption': 'a kitchen with a stove and a refrigerator'},\n",
       " {'image_id': tensor(385580),\n",
       "  'caption': 'a man and a woman standing in a kitchen'},\n",
       " {'image_id': tensor(501652),\n",
       "  'caption': 'a little boy sitting in a car looking out the window'},\n",
       " {'image_id': tensor(209048),\n",
       "  'caption': 'a white refrigerator freezer sitting inside of a kitchen'},\n",
       " {'image_id': tensor(33845),\n",
       "  'caption': 'a group of people sitting around a table with laptops'},\n",
       " {'image_id': tensor(159215),\n",
       "  'caption': 'a man holding a cell phone in his hand'},\n",
       " {'image_id': tensor(143167),\n",
       "  'caption': 'a clock tower in the middle of a city'},\n",
       " {'image_id': tensor(517687),\n",
       "  'caption': 'two cell phones sitting on top of a wooden table'},\n",
       " {'image_id': tensor(399205),\n",
       "  'caption': 'a man holding a cell phone standing next to a man'},\n",
       " {'image_id': tensor(36082),\n",
       "  'caption': 'a kitchen with a microwave and a sink'},\n",
       " {'image_id': tensor(220224),\n",
       "  'caption': 'a clock tower with a weather vane on top of it'},\n",
       " {'image_id': tensor(265596),\n",
       "  'caption': 'a piece of cake on a plate with a fork'},\n",
       " {'image_id': tensor(334399),\n",
       "  'caption': 'a man holding a white frisbee in his right hand'},\n",
       " {'image_id': tensor(487141),\n",
       "  'caption': 'a vase with flowers in it sitting on a table'},\n",
       " {'image_id': tensor(34080),\n",
       "  'caption': 'a pair of scissors sitting on a table'},\n",
       " {'image_id': tensor(433924),\n",
       "  'caption': 'a woman with a pair of scissors cutting her hair'},\n",
       " {'image_id': tensor(178795),\n",
       "  'caption': 'a plate of breakfast food on a table'},\n",
       " {'image_id': tensor(67686),\n",
       "  'caption': 'a plate with a sandwich and a bowl of soup'},\n",
       " {'image_id': tensor(161222),\n",
       "  'caption': 'a table with plates of food and a glass of water'},\n",
       " {'image_id': tensor(92678), 'caption': 'a woman flying a kite on the beach'},\n",
       " {'image_id': tensor(392892),\n",
       "  'caption': 'a kitchen with a table and chairs and a table'},\n",
       " {'image_id': tensor(321811),\n",
       "  'caption': 'a woman is working in a large kitchen'},\n",
       " {'image_id': tensor(274494),\n",
       "  'caption': 'a bathroom with a toilet sink and shower'},\n",
       " {'image_id': tensor(296707),\n",
       "  'caption': 'a bathroom with a sink and a toilet'},\n",
       " {'image_id': tensor(487525),\n",
       "  'caption': 'a bathroom with a toilet sink and mirror'},\n",
       " {'image_id': tensor(401623),\n",
       "  'caption': 'a bathroom with a white shower curtain and a large mirror'},\n",
       " {'image_id': tensor(411968),\n",
       "  'caption': 'a bathroom with a sink and a mirror'},\n",
       " {'image_id': tensor(430420),\n",
       "  'caption': 'a bathroom with a toilet and a sink'},\n",
       " {'image_id': tensor(26730),\n",
       "  'caption': 'a black motorcycle parked on the side of the road'},\n",
       " {'image_id': tensor(504811),\n",
       "  'caption': 'a large clock tower with a clock on each of its sides'},\n",
       " {'image_id': tensor(436467),\n",
       "  'caption': 'a close up of a bowl of food with carrots'},\n",
       " {'image_id': tensor(571804),\n",
       "  'caption': 'a bathroom with a toilet and a sink'},\n",
       " {'image_id': tensor(140658),\n",
       "  'caption': 'a church with a clock on the front of it'},\n",
       " {'image_id': tensor(230008),\n",
       "  'caption': 'a man riding a motorcycle down a street'},\n",
       " {'image_id': tensor(177938),\n",
       "  'caption': 'a man is working on a motorcycle in the garage'},\n",
       " {'image_id': tensor(359086),\n",
       "  'caption': 'a motorcycle parked in a parking lot next to a fence'},\n",
       " {'image_id': tensor(452122),\n",
       "  'caption': 'a large airplane is taking off from a runway'},\n",
       " {'image_id': tensor(413096),\n",
       "  'caption': 'a blue and white jet airliner on runway next to trees'},\n",
       " {'image_id': tensor(18975),\n",
       "  'caption': 'a view of a bunch of airplanes on a runway'},\n",
       " {'image_id': tensor(396051),\n",
       "  'caption': 'a large jetliner sitting on top of an airport tarmac'},\n",
       " {'image_id': tensor(268944),\n",
       "  'caption': 'a small airplane parked in a stationary position'},\n",
       " {'image_id': tensor(58851),\n",
       "  'caption': 'a bench sitting in the middle of a parking lot'},\n",
       " {'image_id': tensor(480605),\n",
       "  'caption': 'a large jetliner flying through a cloudy blue sky'},\n",
       " {'image_id': tensor(34662),\n",
       "  'caption': 'two sheep are standing in a field of grass'},\n",
       " {'image_id': tensor(28157),\n",
       "  'caption': 'a plane is flying over the ocean on a beach'},\n",
       " {'image_id': tensor(79392),\n",
       "  'caption': 'a plane flying over a city with a lot of mountains in the'},\n",
       " {'image_id': tensor(463211),\n",
       "  'caption': 'a woman with a pink shirt and a blue dress'},\n",
       " {'image_id': tensor(463084),\n",
       "  'caption': 'a bus is driving down a street in the rain'},\n",
       " {'image_id': tensor(165572),\n",
       "  'caption': 'a red double decker bus traveling down a street'},\n",
       " {'image_id': tensor(173797),\n",
       "  'caption': 'a city street with a bus driving down the street'},\n",
       " {'image_id': tensor(531163),\n",
       "  'caption': 'a bus is driving down a busy street'},\n",
       " {'image_id': tensor(393647),\n",
       "  'caption': 'a city bus is stopped at a bus stop'},\n",
       " {'image_id': tensor(35195),\n",
       "  'caption': 'a bird with a long beak walking on the beach'},\n",
       " {'image_id': tensor(219723),\n",
       "  'caption': 'a group of sheep are standing in a pen'},\n",
       " {'image_id': tensor(139660),\n",
       "  'caption': 'a small bird perched on a tree limb'},\n",
       " {'image_id': tensor(167810),\n",
       "  'caption': 'a group of ducks swimming in a pond'},\n",
       " {'image_id': tensor(279621),\n",
       "  'caption': 'a train traveling down tracks next to a forest'},\n",
       " {'image_id': tensor(578093),\n",
       "  'caption': 'a train station with a train stopped in the station'},\n",
       " {'image_id': tensor(519555), 'caption': 'a stop sign is shown on a road'},\n",
       " {'image_id': tensor(236000),\n",
       "  'caption': 'a truck is driving down a street with a truck behind it'},\n",
       " {'image_id': tensor(23731),\n",
       "  'caption': 'a cat is laying on a chair in a room'},\n",
       " {'image_id': tensor(38938),\n",
       "  'caption': 'a cat sitting on a dresser in a room'},\n",
       " {'image_id': tensor(379108),\n",
       "  'caption': 'a man and a woman on a boat in the water'},\n",
       " {'image_id': tensor(298628),\n",
       "  'caption': 'a group of three horses standing on a lush green hillside'},\n",
       " {'image_id': tensor(530706),\n",
       "  'caption': 'a group of people sitting at a table with laptops'},\n",
       " {'image_id': tensor(466259),\n",
       "  'caption': 'a woman with an umbrella is standing on a boat'},\n",
       " {'image_id': tensor(340332),\n",
       "  'caption': 'a dirty room with a dirty floor and a dirty toilet'},\n",
       " {'image_id': tensor(74759),\n",
       "  'caption': 'a group of elephants walking down a street'},\n",
       " {'image_id': tensor(414934),\n",
       "  'caption': 'a man riding a skateboard down a street next to a truck'},\n",
       " {'image_id': tensor(215245),\n",
       "  'caption': 'a group of zebras are standing in a field'},\n",
       " {'image_id': tensor(405249),\n",
       "  'caption': 'a group of children watch a birthday cake'},\n",
       " {'image_id': tensor(512467),\n",
       "  'caption': 'a white horse standing in a field with a blue sky in the'},\n",
       " {'image_id': tensor(156772), 'caption': 'a close up of a basket of oranges'},\n",
       " {'image_id': tensor(575179),\n",
       "  'caption': 'a sandwich with meat and lettuce on it'},\n",
       " {'image_id': tensor(189566),\n",
       "  'caption': 'a man and a woman sitting in front of a mirror'},\n",
       " {'image_id': tensor(192095),\n",
       "  'caption': 'a young boy in a baseball uniform throwing a ball'},\n",
       " {'image_id': tensor(298691),\n",
       "  'caption': 'a bowl of broccoli and carrots sitting on a table'},\n",
       " {'image_id': tensor(122239),\n",
       "  'caption': 'a young boy holding a red apple in his hand'},\n",
       " {'image_id': tensor(57843),\n",
       "  'caption': 'a plate with a slice of cake and a fork'},\n",
       " {'image_id': tensor(358982),\n",
       "  'caption': 'a person riding a skate board on a city street'},\n",
       " {'image_id': tensor(274455),\n",
       "  'caption': 'a person riding a skate board on a street'},\n",
       " {'image_id': tensor(519744),\n",
       "  'caption': 'a young man riding a skateboard down a street'},\n",
       " {'image_id': tensor(125971),\n",
       "  'caption': 'a hot dog with a pickle and some drinks'},\n",
       " {'image_id': tensor(490688),\n",
       "  'caption': 'a plate with a sandwich and a side of potatoes'},\n",
       " {'image_id': tensor(317028),\n",
       "  'caption': 'a person holding a donut with a green sugar doughnut'},\n",
       " {'image_id': tensor(581010),\n",
       "  'caption': 'a plate with a doughnut and a cup of coffee'},\n",
       " {'image_id': tensor(28998),\n",
       "  'caption': 'a young boy holding a baseball bat in his hands'},\n",
       " {'image_id': tensor(439326),\n",
       "  'caption': 'a white polar bear eating some food on a plate'},\n",
       " {'image_id': tensor(184384),\n",
       "  'caption': 'a sandwich and a cup of soup on a plate'},\n",
       " {'image_id': tensor(424880),\n",
       "  'caption': 'a piece of cake on a plate with a fork'},\n",
       " {'image_id': tensor(501122),\n",
       "  'caption': 'a man is cutting a large white snowboard'},\n",
       " {'image_id': tensor(234677),\n",
       "  'caption': 'a surfboard is on the beach with a surf board'},\n",
       " {'image_id': tensor(10837),\n",
       "  'caption': 'a group of young men playing a game of soccer'},\n",
       " {'image_id': tensor(205636),\n",
       "  'caption': 'a young boy sitting on a bed with a remote control'},\n",
       " {'image_id': tensor(184386),\n",
       "  'caption': 'a bed with a wooden head board and a picture of a bedroom'},\n",
       " {'image_id': tensor(231037),\n",
       "  'caption': 'a man riding a wave on top of a surfboard'},\n",
       " {'image_id': tensor(467437), 'caption': 'a man and woman laying on a bed'},\n",
       " {'image_id': tensor(258588), 'caption': 'a man is playing tennis on a court'},\n",
       " {'image_id': tensor(460251),\n",
       "  'caption': 'a remote control sitting on top of a wooden table'},\n",
       " {'image_id': tensor(357978),\n",
       "  'caption': 'a woman standing in front of a tv playing wii'},\n",
       " {'image_id': tensor(571641),\n",
       "  'caption': 'a desk with a computer and a keyboard'},\n",
       " {'image_id': tensor(163348),\n",
       "  'caption': 'a desk with a laptop computer and a printer'},\n",
       " {'image_id': tensor(298978),\n",
       "  'caption': 'a woman in a car with a surfboard in the back'},\n",
       " {'image_id': tensor(258628),\n",
       "  'caption': 'a man holding a tennis racquet on a tennis court'},\n",
       " {'image_id': tensor(118432),\n",
       "  'caption': 'a group of people flying kites in a park'},\n",
       " {'image_id': tensor(205230),\n",
       "  'caption': 'a group of young children sitting at a table'},\n",
       " {'image_id': tensor(345136),\n",
       "  'caption': 'a child in a field with a kite in the air'},\n",
       " {'image_id': tensor(404613),\n",
       "  'caption': 'a young girl holding a tennis racket on a tennis court'},\n",
       " {'image_id': tensor(131089),\n",
       "  'caption': 'a young man riding a skateboard down a street'},\n",
       " {'image_id': tensor(432570),\n",
       "  'caption': 'a black and white photo of a vase with flowers in it'},\n",
       " {'image_id': tensor(214224),\n",
       "  'caption': 'a kitchen with a refrigerator and a stove'},\n",
       " {'image_id': tensor(199764),\n",
       "  'caption': 'a woman standing in a market selling food'},\n",
       " {'image_id': tensor(176312),\n",
       "  'caption': 'a woman standing in front of a green wall'},\n",
       " {'image_id': tensor(453297),\n",
       "  'caption': 'a cell phone sitting on top of a table next to a glass'},\n",
       " {'image_id': tensor(529668),\n",
       "  'caption': 'a woman holding a suitcase and standing next to a wall'},\n",
       " {'image_id': tensor(551107),\n",
       "  'caption': 'a little girl holding a nintendo wii game controller'},\n",
       " {'image_id': tensor(413120), 'caption': 'a close up of a bowl of broccoli'},\n",
       " {'image_id': tensor(369771),\n",
       "  'caption': 'a plastic container filled with a plate of food'},\n",
       " ...]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1591a6c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'output'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a144d40f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'image_id': tensor(391895),\n",
       "  'caption': 'a man riding a bike down a dirt road'},\n",
       " {'image_id': tensor(60623), 'caption': 'a woman eating a donut with a fork'},\n",
       " {'image_id': tensor(483108),\n",
       "  'caption': 'a man on a bicycle is looking at a train'},\n",
       " {'image_id': tensor(384213),\n",
       "  'caption': 'a kitchen with a window and a window'},\n",
       " {'image_id': tensor(386164),\n",
       "  'caption': 'a row of wooden tables with white sheets'},\n",
       " {'image_id': tensor(223648),\n",
       "  'caption': 'a long wooden table with a bunch of green bananas on it'},\n",
       " {'image_id': tensor(403385),\n",
       "  'caption': 'a bathroom with a toilet and a sink'},\n",
       " {'image_id': tensor(294832),\n",
       "  'caption': 'a bathroom with a white toilet and a white sink'},\n",
       " {'image_id': tensor(462565),\n",
       "  'caption': 'a group of people riding bikes down a street'},\n",
       " {'image_id': tensor(436141),\n",
       "  'caption': 'a bathroom with a sink and a toilet'},\n",
       " {'image_id': tensor(192440),\n",
       "  'caption': 'a white sink and a toilet in a room'},\n",
       " {'image_id': tensor(1146),\n",
       "  'caption': 'a man wearing a suit and tie with his hands in his pockets'},\n",
       " {'image_id': tensor(559665),\n",
       "  'caption': 'a man with a backpack and a motorcycle'},\n",
       " {'image_id': tensor(394240),\n",
       "  'caption': 'a motorcycle parked in front of a building'},\n",
       " {'image_id': tensor(491497),\n",
       "  'caption': 'a white bed sitting in a bedroom next to a window'},\n",
       " {'image_id': tensor(184791),\n",
       "  'caption': 'a painting of a vase of flowers on a table'},\n",
       " {'image_id': tensor(579664),\n",
       "  'caption': 'a bunch of bananas are sitting on a tree'},\n",
       " {'image_id': tensor(550529),\n",
       "  'caption': 'a motorcycle parked on a sidewalk with a sky background'},\n",
       " {'image_id': tensor(348881),\n",
       "  'caption': 'a person walking on a platform next to a parking meter'},\n",
       " {'image_id': tensor(560623),\n",
       "  'caption': 'a view of a bunch of luggage sitting on the ground'},\n",
       " {'image_id': tensor(561100),\n",
       "  'caption': 'a small blue and white airplane on a grass field'},\n",
       " {'image_id': tensor(354533),\n",
       "  'caption': 'a motorcycle parked in a desert field with a man standing nearby'},\n",
       " {'image_id': tensor(334321),\n",
       "  'caption': 'a dog is walking down the sidewalk with a man on a bike'},\n",
       " {'image_id': tensor(368117),\n",
       "  'caption': 'a traffic light with a red light in the background'},\n",
       " {'image_id': tensor(165547),\n",
       "  'caption': 'a kitchen with a window that has a table with chairs around it'},\n",
       " {'image_id': tensor(455859),\n",
       "  'caption': 'a group of people walking down a street'},\n",
       " {'image_id': tensor(290570),\n",
       "  'caption': 'a herd of sheep grazing on a lush green field'},\n",
       " {'image_id': tensor(281455),\n",
       "  'caption': 'a bird flying over a beach with a few people in the background'},\n",
       " {'image_id': tensor(17756), 'caption': 'a boat that is sitting in the water'},\n",
       " {'image_id': tensor(305821),\n",
       "  'caption': 'a group of giraffes are standing in the grass'},\n",
       " {'image_id': tensor(459374),\n",
       "  'caption': 'a yellow fire hydrant sitting in the middle of a sidewalk'},\n",
       " {'image_id': tensor(208589),\n",
       "  'caption': 'a bird is eating food out of a bird feeder'},\n",
       " {'image_id': tensor(358342),\n",
       "  'caption': 'a large building with a clock tower and a large building'},\n",
       " {'image_id': tensor(74711),\n",
       "  'caption': 'three ducks floating in the water near a pond'},\n",
       " {'image_id': tensor(58636),\n",
       "  'caption': 'a street sign on a pole with a sky background'},\n",
       " {'image_id': tensor(197461),\n",
       "  'caption': 'a sheep standing in a field of grass'},\n",
       " {'image_id': tensor(165029),\n",
       "  'caption': 'a man and a woman are standing in a room'},\n",
       " {'image_id': tensor(336777),\n",
       "  'caption': 'a street sign on a pole on a street'},\n",
       " {'image_id': tensor(472795),\n",
       "  'caption': 'a cow walking down a street next to a store'},\n",
       " {'image_id': tensor(182784),\n",
       "  'caption': 'a cow standing in the street next to a car'},\n",
       " {'image_id': tensor(458052), 'caption': 'a small dog is playing with a toy'},\n",
       " {'image_id': tensor(26942), 'caption': 'a cat sitting on a chair in a room'},\n",
       " {'image_id': tensor(418281),\n",
       "  'caption': 'a group of animals walking down a street'},\n",
       " {'image_id': tensor(535292),\n",
       "  'caption': 'a cow standing in a field with a herd of cows'},\n",
       " {'image_id': tensor(85329), 'caption': 'a close up of a white and black cat'},\n",
       " {'image_id': tensor(451872),\n",
       "  'caption': 'a group of elephants walking in a line'},\n",
       " {'image_id': tensor(314294),\n",
       "  'caption': 'a group of elephants walking in a line'},\n",
       " {'image_id': tensor(516750),\n",
       "  'caption': 'a group of boats are sitting in the water'},\n",
       " {'image_id': tensor(69946),\n",
       "  'caption': 'a boat is docked in a harbor with a view of the water'},\n",
       " {'image_id': tensor(109005),\n",
       "  'caption': 'a group of elephants walking across a grass covered field'},\n",
       " {'image_id': tensor(553442),\n",
       "  'caption': 'a woman and child sitting on a bench'},\n",
       " {'image_id': tensor(261779),\n",
       "  'caption': 'a woman in a dress sitting on a bench'},\n",
       " {'image_id': tensor(198448),\n",
       "  'caption': 'a woman sitting on a bench with her legs crossed'},\n",
       " {'image_id': tensor(329717),\n",
       "  'caption': 'a little boy sitting on a skateboard in a house'},\n",
       " {'image_id': tensor(341393),\n",
       "  'caption': 'a dog is laying on the ground in front of a pool'},\n",
       " {'image_id': tensor(299319),\n",
       "  'caption': 'a group of people walking down a dirt road'},\n",
       " {'image_id': tensor(288955),\n",
       "  'caption': 'a dog sitting on a table with a plate of food'},\n",
       " {'image_id': tensor(426578),\n",
       "  'caption': 'a person walking on a beach with a surfboard'},\n",
       " {'image_id': tensor(64710),\n",
       "  'caption': 'a motorcycle parked on the side of a dirt road'},\n",
       " {'image_id': tensor(180447),\n",
       "  'caption': 'a couple of zebras are standing in a field'},\n",
       " {'image_id': tensor(75162),\n",
       "  'caption': 'a zebra standing in the snow in a fenced in area'},\n",
       " {'image_id': tensor(516316),\n",
       "  'caption': 'a herd of zebra standing on top of a lush green field'},\n",
       " {'image_id': tensor(562121),\n",
       "  'caption': 'a group of zebras are standing in a field'},\n",
       " {'image_id': tensor(129637),\n",
       "  'caption': 'a group of four horses standing next to each other'},\n",
       " {'image_id': tensor(444444),\n",
       "  'caption': 'a woman is standing outside near a horse'},\n",
       " {'image_id': tensor(503005),\n",
       "  'caption': 'a person on a motorcycle taking a picture of a large building'},\n",
       " {'image_id': tensor(316795),\n",
       "  'caption': 'a woman riding a horse through a field'},\n",
       " {'image_id': tensor(375840),\n",
       "  'caption': 'a bowl of fruit and a bowl of fruit on a table'},\n",
       " {'image_id': tensor(147980),\n",
       "  'caption': 'a group of kids playing a game of baseball'},\n",
       " {'image_id': tensor(34180),\n",
       "  'caption': 'a man wearing a yellow hat and a pink hat'},\n",
       " {'image_id': tensor(169802),\n",
       "  'caption': 'a man with a yellow hat and a colorful banana'},\n",
       " {'image_id': tensor(430961),\n",
       "  'caption': 'a man in a baseball uniform throwing a ball'},\n",
       " {'image_id': tensor(570465),\n",
       "  'caption': 'a table with plates of food and glasses of water'},\n",
       " {'image_id': tensor(356708),\n",
       "  'caption': 'a man and a little girl on skis in the snow'},\n",
       " {'image_id': tensor(362368),\n",
       "  'caption': 'a little boy that is standing in front of a table'},\n",
       " {'image_id': tensor(216228),\n",
       "  'caption': 'a woman walking down a street with a bag of luggage'},\n",
       " {'image_id': tensor(448365),\n",
       "  'caption': 'a man riding a skateboard on a ramp'},\n",
       " {'image_id': tensor(472854),\n",
       "  'caption': 'a man riding a skateboard down a street'},\n",
       " {'image_id': tensor(127451),\n",
       "  'caption': 'two men in black jackets on skis in the snow'},\n",
       " {'image_id': tensor(299116),\n",
       "  'caption': 'a girl sitting at a table with a plate of food'},\n",
       " {'image_id': tensor(66412),\n",
       "  'caption': 'a man holding a snowboard in his hand'},\n",
       " {'image_id': tensor(410002),\n",
       "  'caption': 'a bunch of doughnuts that are sitting on a tray'},\n",
       " {'image_id': tensor(507065),\n",
       "  'caption': 'a young boy eating a sandwich with a fork'},\n",
       " {'image_id': tensor(415746),\n",
       "  'caption': 'a display case filled with lots of different kinds of donuts'},\n",
       " {'image_id': tensor(71171),\n",
       "  'caption': 'a plate with a sandwich and a pickle on it'},\n",
       " {'image_id': tensor(292301),\n",
       "  'caption': 'a sandwich and a drink sit on a table'},\n",
       " {'image_id': tensor(550627),\n",
       "  'caption': 'a box of donuts with sprinkles on it'},\n",
       " {'image_id': tensor(244339),\n",
       "  'caption': 'a young man in a green shirt and green tie'},\n",
       " {'image_id': tensor(284350),\n",
       "  'caption': 'a woman standing on a surfboard in the water'},\n",
       " {'image_id': tensor(309120),\n",
       "  'caption': 'a man is playing frisbee on a green field'},\n",
       " {'image_id': tensor(467477),\n",
       "  'caption': 'a man riding a wave on top of a surfboard'},\n",
       " {'image_id': tensor(154971),\n",
       "  'caption': 'a group of young men playing a game of soccer'},\n",
       " {'image_id': tensor(295837),\n",
       "  'caption': 'a woman in a kitchen preparing food on a table'},\n",
       " {'image_id': tensor(321214), 'caption': 'a baby eating a cake with a fork'},\n",
       " {'image_id': tensor(224757),\n",
       "  'caption': 'a group of kids playing a game of soccer'},\n",
       " {'image_id': tensor(182245),\n",
       "  'caption': 'a man sitting at a table with a plate of food'},\n",
       " {'image_id': tensor(199551),\n",
       "  'caption': 'a little girl laying in bed with a blanket on top of it'},\n",
       " {'image_id': tensor(239347),\n",
       "  'caption': 'a woman sitting on a bed in a white room'},\n",
       " {'image_id': tensor(353830),\n",
       "  'caption': 'a pizza with cheese and tomatoes on a plate'},\n",
       " {'image_id': tensor(301102),\n",
       "  'caption': 'two tennis rackets are laying on a tennis court'},\n",
       " {'image_id': tensor(473237),\n",
       "  'caption': 'a little girl eating a slice of pizza'},\n",
       " {'image_id': tensor(190081),\n",
       "  'caption': 'a woman holding a tennis racquet on a tennis court'},\n",
       " {'image_id': tensor(207151),\n",
       "  'caption': 'a pizza with many toppings on a wooden board'},\n",
       " {'image_id': tensor(371250),\n",
       "  'caption': 'a bed with a wooden head board and a painting on the wall'},\n",
       " {'image_id': tensor(209868),\n",
       "  'caption': 'a young child brushing his teeth with a tooth brush'},\n",
       " {'image_id': tensor(340175),\n",
       "  'caption': 'a living room with a couch and a table'},\n",
       " {'image_id': tensor(235597),\n",
       "  'caption': 'a man sitting in front of a laptop computer'},\n",
       " {'image_id': tensor(503311),\n",
       "  'caption': 'a person is flying a kite on the beach'},\n",
       " {'image_id': tensor(138477),\n",
       "  'caption': 'a person is flying a kite in a field'},\n",
       " {'image_id': tensor(76292), 'caption': 'a child is flying a kite in a field'},\n",
       " {'image_id': tensor(502090),\n",
       "  'caption': 'a person flying a kite on the beach'},\n",
       " {'image_id': tensor(28655),\n",
       "  'caption': 'a clock on a pole on a street corner'},\n",
       " {'image_id': tensor(191096),\n",
       "  'caption': 'a baseball player swinging a bat at a ball'},\n",
       " {'image_id': tensor(78707),\n",
       "  'caption': 'a baseball player holding a bat on a field'},\n",
       " {'image_id': tensor(336493),\n",
       "  'caption': 'a young boy holding a baseball bat during a baseball game'},\n",
       " {'image_id': tensor(74369),\n",
       "  'caption': 'a young baseball player throwing a baseball on a field'},\n",
       " {'image_id': tensor(384012),\n",
       "  'caption': 'a baseball player is getting ready to hit a ball'},\n",
       " {'image_id': tensor(579056),\n",
       "  'caption': 'a man holding a baseball bat on a field'},\n",
       " {'image_id': tensor(24223),\n",
       "  'caption': 'a person is holding a large pizza in a box'},\n",
       " {'image_id': tensor(69392),\n",
       "  'caption': 'a group of people standing on top of a tennis court'},\n",
       " {'image_id': tensor(272262),\n",
       "  'caption': 'a man holding a tennis racquet on a tennis court'},\n",
       " {'image_id': tensor(43635),\n",
       "  'caption': 'a group of people sitting on a bench in front of a building'},\n",
       " {'image_id': tensor(95786),\n",
       "  'caption': 'a cup of coffee sitting next to a cup on a table'},\n",
       " {'image_id': tensor(87199),\n",
       "  'caption': 'a man in a baseball cap and hat sitting on a bench'},\n",
       " {'image_id': tensor(527248),\n",
       "  'caption': 'a large crowd of people standing in front of a building'},\n",
       " {'image_id': tensor(353136),\n",
       "  'caption': 'a person is sitting on a bench and another is standing up'},\n",
       " {'image_id': tensor(83915),\n",
       "  'caption': 'a large building with a clock tower on top'},\n",
       " {'image_id': tensor(2240),\n",
       "  'caption': 'a group of stuffed animals sitting on top of a shelf'},\n",
       " {'image_id': tensor(28377), 'caption': 'a street sign on a pole on a street'},\n",
       " {'image_id': tensor(217183),\n",
       "  'caption': 'a vase with flowers in it sitting on a table'},\n",
       " {'image_id': tensor(366630),\n",
       "  'caption': 'a vase with flowers in it sitting on a table'},\n",
       " {'image_id': tensor(157184),\n",
       "  'caption': 'a man holding a pair of skis in his hands'},\n",
       " {'image_id': tensor(509819),\n",
       "  'caption': 'a pair of scissors and some tools on a table'},\n",
       " {'image_id': tensor(510657),\n",
       "  'caption': 'a group of people sitting at a table with glasses of wine'},\n",
       " {'image_id': tensor(195645),\n",
       "  'caption': 'a man and a woman sitting at a table with a baby'},\n",
       " {'image_id': tensor(171190),\n",
       "  'caption': 'a group of people sitting around a table with wine glasses on it'},\n",
       " {'image_id': tensor(484145),\n",
       "  'caption': 'a man standing in a kitchen holding a knife'},\n",
       " {'image_id': tensor(530207),\n",
       "  'caption': 'a group of people walking down a street'},\n",
       " {'image_id': tensor(17953),\n",
       "  'caption': 'a bunch of vegetables and fruits are on a table'},\n",
       " {'image_id': tensor(210012),\n",
       "  'caption': 'a woman standing in a kitchen with her dog'},\n",
       " {'image_id': tensor(33638),\n",
       "  'caption': 'a woman cooking in a kitchen with a stove and microwave'},\n",
       " {'image_id': tensor(31442), 'caption': 'a man sitting on a chair in a room'},\n",
       " {'image_id': tensor(329219),\n",
       "  'caption': 'a man walking a dog down a sidewalk'},\n",
       " {'image_id': tensor(399851), 'caption': 'a kitchen with a stove and a sink'},\n",
       " {'image_id': tensor(539124),\n",
       "  'caption': 'a couple of people that are walking down the street'},\n",
       " {'image_id': tensor(12896), 'caption': 'a bicycle is parked next to a fence'},\n",
       " {'image_id': tensor(378709),\n",
       "  'caption': 'a bathroom with a toilet and a sink'},\n",
       " {'image_id': tensor(431197),\n",
       "  'caption': 'a bathroom with a toilet sink and mirror'},\n",
       " {'image_id': tensor(463610),\n",
       "  'caption': 'a bathroom with a toilet and a sink'},\n",
       " {'image_id': tensor(540806),\n",
       "  'caption': 'a man riding a motorcycle down a road next to a bridge'},\n",
       " {'image_id': tensor(402330),\n",
       "  'caption': 'a toilet with a wooden seat and a white toilet'},\n",
       " {'image_id': tensor(378657),\n",
       "  'caption': 'a large clock tower with a massive clock on its face'},\n",
       " {'image_id': tensor(24343),\n",
       "  'caption': 'a man riding a motorcycle down a street'},\n",
       " {'image_id': tensor(376177), 'caption': 'a large air plane on a run way'},\n",
       " {'image_id': tensor(115178),\n",
       "  'caption': 'a red and white airplane flying in the sky'},\n",
       " {'image_id': tensor(572733),\n",
       "  'caption': 'a large airplane flying in a clear blue sky'},\n",
       " {'image_id': tensor(112956),\n",
       "  'caption': 'a large jetliner flying through a blue sky'},\n",
       " {'image_id': tensor(144122),\n",
       "  'caption': 'a red and white airplane flying in the sky'},\n",
       " {'image_id': tensor(183181),\n",
       "  'caption': 'a herd of sheep grazing on a lush green field'},\n",
       " {'image_id': tensor(275210),\n",
       "  'caption': 'a giraffe standing in the middle of a field'},\n",
       " {'image_id': tensor(519046),\n",
       "  'caption': 'a giraffe standing in a field with tall grass'},\n",
       " {'image_id': tensor(362159),\n",
       "  'caption': 'a traffic light on a city street at dusk'},\n",
       " {'image_id': tensor(389378),\n",
       "  'caption': 'a street at night with a car driving down the street'},\n",
       " {'image_id': tensor(12204),\n",
       "  'caption': 'a group of giraffes standing in a fenced off area'},\n",
       " {'image_id': tensor(91857),\n",
       "  'caption': 'two giraffes standing in a fenced in area'},\n",
       " {'image_id': tensor(220307),\n",
       "  'caption': 'a giraffe standing in the middle of a dirt road'},\n",
       " {'image_id': tensor(4760),\n",
       "  'caption': 'a fire hydrant on a sidewalk near a street'},\n",
       " {'image_id': tensor(410428),\n",
       "  'caption': 'a group of sheep standing on a lush green field'},\n",
       " {'image_id': tensor(450724),\n",
       "  'caption': 'a man sitting on a bench looking out over the ocean'},\n",
       " {'image_id': tensor(27440),\n",
       "  'caption': 'a giraffe standing in the middle of a dirt field'},\n",
       " {'image_id': tensor(438221), 'caption': 'a couple of ducks are in the water'},\n",
       " {'image_id': tensor(472557),\n",
       "  'caption': 'two giraffes standing next to each other in a pen'},\n",
       " {'image_id': tensor(123836),\n",
       "  'caption': 'a giraffe standing next to a pile of rocks'},\n",
       " {'image_id': tensor(317441),\n",
       "  'caption': 'a street sign with a one way sign on it'},\n",
       " {'image_id': tensor(1448),\n",
       "  'caption': 'a giraffe standing in a field with grass and trees'},\n",
       " {'image_id': tensor(536615),\n",
       "  'caption': 'a group of giraffes are standing in a pin'},\n",
       " {'image_id': tensor(141517),\n",
       "  'caption': 'a herd of sheep grazing on a lush green field'},\n",
       " {'image_id': tensor(71281),\n",
       "  'caption': 'a herd of sheep standing on top of a lush green field'},\n",
       " {'image_id': tensor(350262), 'caption': 'a group of cows grazing in a field'},\n",
       " {'image_id': tensor(1590),\n",
       "  'caption': 'a bunch of trash is sitting in the middle of a street'},\n",
       " {'image_id': tensor(547839),\n",
       "  'caption': 'a train traveling down a track with a car driving by'},\n",
       " {'image_id': tensor(550452),\n",
       "  'caption': 'a red train engine sitting on the tracks'},\n",
       " {'image_id': tensor(271240),\n",
       "  'caption': 'a white and green sign that reads UNK'},\n",
       " {'image_id': tensor(438232),\n",
       "  'caption': 'a train is pulling into a train station'},\n",
       " {'image_id': tensor(147915),\n",
       "  'caption': 'a stop sign with a street sign on top of it'},\n",
       " {'image_id': tensor(438985),\n",
       "  'caption': 'a cat is sitting on top of a suitcase'},\n",
       " {'image_id': tensor(31176),\n",
       "  'caption': 'a cat sitting on a window sill in a room'},\n",
       " {'image_id': tensor(451972),\n",
       "  'caption': 'a fire truck with a flag on it on a street'},\n",
       " {'image_id': tensor(199050),\n",
       "  'caption': 'a group of people sitting around a table'},\n",
       " {'image_id': tensor(468541), 'caption': 'a dog wearing a sweater and a tie'},\n",
       " {'image_id': tensor(38662),\n",
       "  'caption': 'a white boat sitting on top of a beach next to a light'},\n",
       " {'image_id': tensor(90476),\n",
       "  'caption': 'a group of boats are parked on the beach'},\n",
       " {'image_id': tensor(386739),\n",
       "  'caption': 'a man and woman are standing in front of a black and white'},\n",
       " {'image_id': tensor(36598),\n",
       "  'caption': 'a group of people walking down a street holding umbrellas'},\n",
       " {'image_id': tensor(181859),\n",
       "  'caption': 'a cat laying on a white sink in a bathroom'},\n",
       " {'image_id': tensor(177262),\n",
       "  'caption': 'a cat laying on top of a sink in a bathroom'},\n",
       " {'image_id': tensor(177015),\n",
       "  'caption': 'a man sitting on a couch using a laptop computer'},\n",
       " {'image_id': tensor(256260),\n",
       "  'caption': 'a man is petting an elephant with a hose'},\n",
       " {'image_id': tensor(88784),\n",
       "  'caption': 'a dog running across a field with a frisbee in its mouth'},\n",
       " {'image_id': tensor(48731),\n",
       "  'caption': 'a polar bear in the snow with a frisbee'},\n",
       " {'image_id': tensor(453860),\n",
       "  'caption': 'a person is standing in the snow with a frisbee'},\n",
       " {'image_id': tensor(178746),\n",
       "  'caption': 'a luggage cart sitting on the floor in a terminal'},\n",
       " {'image_id': tensor(347950),\n",
       "  'caption': 'a dog running with a frisbee in its mouth'},\n",
       " {'image_id': tensor(350789),\n",
       "  'caption': 'a group of zebras are standing in a field'},\n",
       " {'image_id': tensor(33645),\n",
       "  'caption': 'a little girl holding a baseball bat in a yard'},\n",
       " {'image_id': tensor(309100),\n",
       "  'caption': 'a group of zebras are standing in a field'},\n",
       " {'image_id': tensor(299089),\n",
       "  'caption': 'a group of zebras are standing in a field'},\n",
       " {'image_id': tensor(421999),\n",
       "  'caption': 'a zebra standing in the dirt near a tree'},\n",
       " {'image_id': tensor(366830),\n",
       "  'caption': 'a brown cow standing in a forest filled with trees'},\n",
       " {'image_id': tensor(199346),\n",
       "  'caption': 'a person riding a horse in a city square'},\n",
       " {'image_id': tensor(177246),\n",
       "  'caption': 'a sandwich and french fries on a tray'},\n",
       " {'image_id': tensor(348905),\n",
       "  'caption': 'a man riding a surfboard on a wave in the ocean'},\n",
       " {'image_id': tensor(469961),\n",
       "  'caption': 'a person riding skis on a snowy slope'},\n",
       " {'image_id': tensor(427802),\n",
       "  'caption': 'a pile of oranges sitting next to a pile of oranges'},\n",
       " {'image_id': tensor(338472), 'caption': 'a close up of a basket of oranges'},\n",
       " {'image_id': tensor(355137),\n",
       "  'caption': 'a person riding skis on a snowy surface'},\n",
       " {'image_id': tensor(361763), 'caption': 'a man is swinging a bat at a ball'},\n",
       " {'image_id': tensor(88854),\n",
       "  'caption': 'a group of people skiing down a snowy slope'},\n",
       " {'image_id': tensor(160195),\n",
       "  'caption': 'a man riding a skateboard down a sidewalk'},\n",
       " {'image_id': tensor(580591),\n",
       "  'caption': 'a person riding skis on a snowy surface'},\n",
       " {'image_id': tensor(226588),\n",
       "  'caption': 'a person riding skis on a snowy surface'},\n",
       " {'image_id': tensor(361472),\n",
       "  'caption': 'a group of kids riding skateboards down a street'},\n",
       " {'image_id': tensor(242103), 'caption': 'a plate of food with a green salad'},\n",
       " {'image_id': tensor(297233),\n",
       "  'caption': 'a table with plates of food and glasses on it'},\n",
       " {'image_id': tensor(2867),\n",
       "  'caption': 'a group of people standing on top of a snow covered slope'},\n",
       " {'image_id': tensor(257870),\n",
       "  'caption': 'a man holding a hot dog in his hand'},\n",
       " {'image_id': tensor(57286),\n",
       "  'caption': 'a skateboarder is jumping over a set of stairs'},\n",
       " {'image_id': tensor(435037),\n",
       "  'caption': 'a doughnut and a cup of coffee on a table'},\n",
       " {'image_id': tensor(546500), 'caption': 'a close up of a cake on a table'},\n",
       " {'image_id': tensor(545385),\n",
       "  'caption': 'a plate with a piece of cake and a spoon'},\n",
       " {'image_id': tensor(23320),\n",
       "  'caption': 'a slice of cake on a plate with a fork'},\n",
       " {'image_id': tensor(12085),\n",
       "  'caption': 'two cats are laying on a bed with white sheets'},\n",
       " {'image_id': tensor(8775),\n",
       "  'caption': 'a bed with a white comforter and a blue blanket'},\n",
       " {'image_id': tensor(384981),\n",
       "  'caption': 'a woman is sitting at a table with a birthday cake'},\n",
       " {'image_id': tensor(475398),\n",
       "  'caption': 'a woman standing in front of a cake with a birthday cake'},\n",
       " {'image_id': tensor(479213),\n",
       "  'caption': 'two women are standing in front of a cake'},\n",
       " {'image_id': tensor(30549),\n",
       "  'caption': 'two women standing next to each other holding glasses'},\n",
       " {'image_id': tensor(66072),\n",
       "  'caption': 'a man riding a surfboard on top of a wave'},\n",
       " {'image_id': tensor(513699),\n",
       "  'caption': 'a group of people walking across a beach holding surfboards'},\n",
       " {'image_id': tensor(45057),\n",
       "  'caption': 'a pizza with toppings on a white plate'},\n",
       " {'image_id': tensor(372577),\n",
       "  'caption': 'a man standing on a tennis court holding a racquet'},\n",
       " {'image_id': tensor(275202),\n",
       "  'caption': 'a pizza sitting on top of a white plate on a table'},\n",
       " {'image_id': tensor(294831),\n",
       "  'caption': 'a person is holding a pizza in a box'},\n",
       " {'image_id': tensor(190291),\n",
       "  'caption': 'a group of people sitting at a table with plates of food'},\n",
       " {'image_id': tensor(246649),\n",
       "  'caption': 'a man is playing tennis on a tennis court'},\n",
       " {'image_id': tensor(199449),\n",
       "  'caption': 'a living room with a couch and a table'},\n",
       " {'image_id': tensor(1626),\n",
       "  'caption': 'a man standing in a living room next to a couch'},\n",
       " {'image_id': tensor(234251),\n",
       "  'caption': 'a little girl standing in a room with a remote'},\n",
       " {'image_id': tensor(281376),\n",
       "  'caption': 'a desk with a keyboard and a laptop on it'},\n",
       " {'image_id': tensor(326082),\n",
       "  'caption': 'a living room with a couch and a tv'},\n",
       " {'image_id': tensor(525619),\n",
       "  'caption': 'a dog is sitting in the grass near a fence'},\n",
       " {'image_id': tensor(393031),\n",
       "  'caption': 'a baseball player is getting ready to hit a ball'},\n",
       " {'image_id': tensor(385514),\n",
       "  'caption': 'a baseball player swinging a bat at a ball'},\n",
       " {'image_id': tensor(539355), 'caption': 'a clock on a pole on a street'},\n",
       " {'image_id': tensor(320180),\n",
       "  'caption': 'a woman laying on a bed with her hands on her hair'},\n",
       " {'image_id': tensor(357633),\n",
       "  'caption': 'a laptop computer sitting on top of a wooden table'},\n",
       " {'image_id': tensor(127801),\n",
       "  'caption': 'a person holding a cell phone in their hand'},\n",
       " {'image_id': tensor(537991),\n",
       "  'caption': 'a woman sitting on a couch holding a smart phone'},\n",
       " {'image_id': tensor(25758),\n",
       "  'caption': 'a woman cooking food in a stainless steel oven'},\n",
       " {'image_id': tensor(565198),\n",
       "  'caption': 'a little girl holding a nintendo wii game controller'},\n",
       " {'image_id': tensor(577160),\n",
       "  'caption': 'a plate of food with a sandwich and salad'},\n",
       " {'image_id': tensor(321333),\n",
       "  'caption': 'two young boys sitting on a bench holding their teddy bear'},\n",
       " {'image_id': tensor(229688),\n",
       "  'caption': 'a woman sitting at a table with a plate of food'},\n",
       " {'image_id': tensor(509807),\n",
       "  'caption': 'a kitchen with a stove and a microwave'},\n",
       " {'image_id': tensor(37367), 'caption': 'a table and chairs in a small room'},\n",
       " {'image_id': tensor(22158),\n",
       "  'caption': 'a kitchen with a stove and a refrigerator'},\n",
       " {'image_id': tensor(220446),\n",
       "  'caption': 'a bathroom with a toilet and a sink'},\n",
       " {'image_id': tensor(247184),\n",
       "  'caption': 'a bathroom with a toilet and a sink'},\n",
       " {'image_id': tensor(313063),\n",
       "  'caption': 'a bathroom with a toilet sink and bathtub'},\n",
       " {'image_id': tensor(239376),\n",
       "  'caption': 'a bathroom with a white tub and a white tile floor'},\n",
       " {'image_id': tensor(28790),\n",
       "  'caption': 'a bathroom with a toilet and a shower'},\n",
       " {'image_id': tensor(416668),\n",
       "  'caption': 'a black cat sitting on a kitchen counter'},\n",
       " {'image_id': tensor(252203),\n",
       "  'caption': 'a dog sitting in the passenger seat of a car'},\n",
       " {'image_id': tensor(573962),\n",
       "  'caption': 'a view of a street with a lot of traffic'},\n",
       " {'image_id': tensor(480215),\n",
       "  'caption': 'a white toilet sitting next to a white bath tub'},\n",
       " {'image_id': tensor(299550),\n",
       "  'caption': 'a white toilet sitting next to a white sink'},\n",
       " {'image_id': tensor(184557),\n",
       "  'caption': 'a cat is sitting on the toilet in the bathroom'},\n",
       " {'image_id': tensor(577526),\n",
       "  'caption': 'a black and white cat laying on a bed'},\n",
       " {'image_id': tensor(31000),\n",
       "  'caption': 'a bowl of oranges and oranges on a table'},\n",
       " {'image_id': tensor(280360),\n",
       "  'caption': 'a small blue and yellow plane flying in the air'},\n",
       " {'image_id': tensor(283495),\n",
       "  'caption': 'a plane flying in the air with trees in the background'},\n",
       " {'image_id': tensor(189828),\n",
       "  'caption': 'a plane flying in the air above trees'},\n",
       " {'image_id': tensor(126502),\n",
       "  'caption': 'a close up of a giraffe near a fence'},\n",
       " {'image_id': tensor(141587),\n",
       "  'caption': 'a large jetliner flying over a city in front of a city'},\n",
       " {'image_id': tensor(16241),\n",
       "  'caption': 'a large airplane flying over a city in a city'},\n",
       " {'image_id': tensor(277208),\n",
       "  'caption': 'a giraffe standing in the middle of a field'},\n",
       " {'image_id': tensor(134863),\n",
       "  'caption': 'a street scene with a traffic light and a street sign'},\n",
       " {'image_id': tensor(34904),\n",
       "  'caption': 'a wooden bench with a blue wooden bench'},\n",
       " {'image_id': tensor(8179),\n",
       "  'caption': 'a traffic light sitting on the side of a road'},\n",
       " {'image_id': tensor(539784),\n",
       "  'caption': 'a herd of sheep crossing a road with a train passing by'},\n",
       " {'image_id': tensor(458755),\n",
       "  'caption': 'a woman is petting a sheep in a pen'},\n",
       " {'image_id': tensor(58492),\n",
       "  'caption': 'a bird is flying over the top of a hill'},\n",
       " {'image_id': tensor(484551),\n",
       "  'caption': 'a man is standing on a boat in the water'},\n",
       " {'image_id': tensor(133867),\n",
       "  'caption': 'a man is skateboarding down a busy street'},\n",
       " {'image_id': tensor(208778),\n",
       "  'caption': 'a man is standing in a bathroom with a sink'},\n",
       " {'image_id': tensor(434279),\n",
       "  'caption': 'a blue and white train sitting on the tracks'},\n",
       " {'image_id': tensor(136584),\n",
       "  'caption': 'a bird sitting on a power line next to a wire fence'},\n",
       " {'image_id': tensor(520482),\n",
       "  'caption': 'a group of birds standing on a wooden ledge'},\n",
       " {'image_id': tensor(434129),\n",
       "  'caption': 'a blue vase with a blue and white surfboard on it'},\n",
       " {'image_id': tensor(1180),\n",
       "  'caption': 'a woman in a white dress cutting a cake'},\n",
       " {'image_id': tensor(158118),\n",
       "  'caption': 'a man is walking down the street in the city'},\n",
       " {'image_id': tensor(572427), 'caption': 'a stop sign on a pole on a street'},\n",
       " {'image_id': tensor(73119),\n",
       "  'caption': 'a train is coming down the tracks in a black and white photo'},\n",
       " {'image_id': tensor(27226),\n",
       "  'caption': 'a red train is coming down the tracks'},\n",
       " {'image_id': tensor(288799),\n",
       "  'caption': 'a red train is coming down some tracks'},\n",
       " {'image_id': tensor(300471),\n",
       "  'caption': 'a cat laying on a blue bench next to a pool'},\n",
       " {'image_id': tensor(152740),\n",
       "  'caption': 'a herd of black cows grazing on a grassy hillside'},\n",
       " {'image_id': tensor(289781),\n",
       "  'caption': 'a boat sitting on a dock in the water'},\n",
       " {'image_id': tensor(173385),\n",
       "  'caption': 'a baby elephant standing next to an adult elephant'},\n",
       " {'image_id': tensor(450370),\n",
       "  'caption': 'a large elephant walking in the grass near trees'},\n",
       " {'image_id': tensor(502419),\n",
       "  'caption': 'a couple of elephants standing next to each other'},\n",
       " {'image_id': tensor(471497),\n",
       "  'caption': 'a large elephant walking through a lush green forest'},\n",
       " {'image_id': tensor(483275),\n",
       "  'caption': 'a group of elephants walking in a line'},\n",
       " {'image_id': tensor(144379),\n",
       "  'caption': 'a woman standing next to a pile of luggage'},\n",
       " {'image_id': tensor(337055),\n",
       "  'caption': 'a woman sitting on a bench with a cell phone'},\n",
       " {'image_id': tensor(568040),\n",
       "  'caption': 'a large elephant standing in a grass field'},\n",
       " {'image_id': tensor(404461),\n",
       "  'caption': 'a red fire hydrant sitting on the side of a road'},\n",
       " {'image_id': tensor(108338),\n",
       "  'caption': 'a group of elephants walking across a dirt field'},\n",
       " {'image_id': tensor(525376),\n",
       "  'caption': 'a bunch of luggage is sitting in a car'},\n",
       " {'image_id': tensor(395402),\n",
       "  'caption': 'a small dog standing on a kitchen floor'},\n",
       " {'image_id': tensor(530226),\n",
       "  'caption': 'a polar bear walking across a snowy field'},\n",
       " {'image_id': tensor(295097), 'caption': 'a cat laying on a rug on a couch'},\n",
       " {'image_id': tensor(114352),\n",
       "  'caption': 'a man holding a frisbee while standing in a field'},\n",
       " {'image_id': tensor(504341),\n",
       "  'caption': 'a dog is laying on the sand at the beach'},\n",
       " {'image_id': tensor(29577),\n",
       "  'caption': 'two horses are tied to a post on a city street'},\n",
       " {'image_id': tensor(545129),\n",
       "  'caption': 'a group of zebras are standing together in the dirt'},\n",
       " {'image_id': tensor(372252),\n",
       "  'caption': 'a group of zebras are grazing in a field'},\n",
       " {'image_id': tensor(121031),\n",
       "  'caption': 'a group of people riding on the back of a horse'},\n",
       " {'image_id': tensor(75990),\n",
       "  'caption': 'a man riding a horse drawn carriage down a street'},\n",
       " {'image_id': tensor(248441),\n",
       "  'caption': 'a woman standing next to a horse on a beach'},\n",
       " {'image_id': tensor(104568),\n",
       "  'caption': 'a bunch of vegetables and fruits on a table'},\n",
       " {'image_id': tensor(300655),\n",
       "  'caption': 'a person is standing in the grass with a frisbee'},\n",
       " {'image_id': tensor(51223),\n",
       "  'caption': 'a baseball player is running to first base'},\n",
       " {'image_id': tensor(95051),\n",
       "  'caption': 'a man riding skis down a snow covered slope'},\n",
       " {'image_id': tensor(169858),\n",
       "  'caption': 'a woman holding a bunch of bananas in her hands'},\n",
       " {'image_id': tensor(178748),\n",
       "  'caption': 'a pot of soup with broccoli and carrots in it'},\n",
       " {'image_id': tensor(59614),\n",
       "  'caption': 'a plate of food with broccoli and rice'},\n",
       " {'image_id': tensor(255209),\n",
       "  'caption': 'a dog is walking with a person on a leash'},\n",
       " {'image_id': tensor(279209),\n",
       "  'caption': 'a person walking in the snow with a snowboard'},\n",
       " {'image_id': tensor(90707),\n",
       "  'caption': 'a person is standing in front of a large window'},\n",
       " {'image_id': tensor(577403),\n",
       "  'caption': 'a group of young boys riding skateboards at a skate park'},\n",
       " {'image_id': tensor(289469),\n",
       "  'caption': 'a plate of food with a sandwich and french fries'},\n",
       " {'image_id': tensor(163852),\n",
       "  'caption': 'a white plate topped with a sandwich and a salad'},\n",
       " {'image_id': tensor(322369),\n",
       "  'caption': 'a sandwich and a cup of soda on a table'},\n",
       " {'image_id': tensor(308430),\n",
       "  'caption': 'a pan of food being cooked in a stove'},\n",
       " {'image_id': tensor(245242),\n",
       "  'caption': 'a cutting board with a knife and some carrots'},\n",
       " {'image_id': tensor(481187),\n",
       "  'caption': 'a person riding skis on a snowy slope'},\n",
       " {'image_id': tensor(39009),\n",
       "  'caption': 'a group of people holding up long yellow and white frosted cake'},\n",
       " {'image_id': tensor(166124),\n",
       "  'caption': 'a box of six donuts with different toppings'},\n",
       " {'image_id': tensor(3001),\n",
       "  'caption': 'a box of donuts and a tray of donuts on a table'},\n",
       " {'image_id': tensor(220111),\n",
       "  'caption': 'a table with plates of food and glasses of water'},\n",
       " {'image_id': tensor(296284),\n",
       "  'caption': 'a couple of doughnuts are in a display case'},\n",
       " {'image_id': tensor(207366),\n",
       "  'caption': 'a group of young men kicking around a soccer ball'},\n",
       " {'image_id': tensor(127517),\n",
       "  'caption': 'a group of surfboards lined up next to each other'},\n",
       " {'image_id': tensor(183715),\n",
       "  'caption': 'a woman holding a knife with a bunch of green frosting on it'},\n",
       " {'image_id': tensor(340642),\n",
       "  'caption': 'a slice of cake on a plate with a fork'},\n",
       " {'image_id': tensor(391915), 'caption': 'a room with a bed and a canopy'},\n",
       " {'image_id': tensor(13525),\n",
       "  'caption': 'a woman laying in bed with a white sheet'},\n",
       " {'image_id': tensor(294487),\n",
       "  'caption': 'a bed with a wooden head board and a wooden frame'},\n",
       " {'image_id': tensor(242909),\n",
       "  'caption': 'a pizza with many toppings on a plate'},\n",
       " {'image_id': tensor(448897),\n",
       "  'caption': 'a pizza with many toppings on a plate'},\n",
       " {'image_id': tensor(216303),\n",
       "  'caption': 'a woman in a short skirt holding a tennis racquet'},\n",
       " {'image_id': tensor(355272),\n",
       "  'caption': 'a young boy holding a nintendo wii game controller'},\n",
       " {'image_id': tensor(355228),\n",
       "  'caption': 'a small kitten is playing with a computer mouse'},\n",
       " {'image_id': tensor(70351),\n",
       "  'caption': 'a white plate topped with a hot dog and banana slices'},\n",
       " {'image_id': tensor(501429),\n",
       "  'caption': 'a baby is holding a toothbrush in its mouth'},\n",
       " {'image_id': tensor(311394),\n",
       "  'caption': 'a baby in a tie is holding a toothbrush'},\n",
       " {'image_id': tensor(90365),\n",
       "  'caption': 'a white toilet sitting in a bathroom next to a wall'},\n",
       " {'image_id': tensor(408327),\n",
       "  'caption': 'a woman in a short skirt holding a tennis racquet'},\n",
       " {'image_id': tensor(221291),\n",
       "  'caption': 'a little boy that is standing in the grass with a kite'},\n",
       " {'image_id': tensor(565239),\n",
       "  'caption': 'a group of people standing on a street flying a kite'},\n",
       " {'image_id': tensor(125404),\n",
       "  'caption': 'two young boys wearing baseball helmets and holding baseball gloves'},\n",
       " {'image_id': tensor(378545),\n",
       "  'caption': 'a clock on a pole in front of a building'},\n",
       " {'image_id': tensor(182503),\n",
       "  'caption': 'a pizza with cheese and other toppings on it'},\n",
       " {'image_id': tensor(372384),\n",
       "  'caption': 'a man is hitting a tennis ball on the court'},\n",
       " {'image_id': tensor(185781),\n",
       "  'caption': 'a group of people standing around a room with a laptop on the'},\n",
       " {'image_id': tensor(484312),\n",
       "  'caption': 'a man wearing a hat and glasses sitting in a chair'},\n",
       " {'image_id': tensor(471869),\n",
       "  'caption': 'a brown teddy bear sitting on top of a bed'},\n",
       " {'image_id': tensor(516766),\n",
       "  'caption': 'a stuffed animal is laying on a bed'},\n",
       " {'image_id': tensor(533407),\n",
       "  'caption': 'a group of men standing around a kitchen'},\n",
       " {'image_id': tensor(157001),\n",
       "  'caption': 'two people sitting at a table with laptops'},\n",
       " {'image_id': tensor(562345),\n",
       "  'caption': 'a woman with a yellow jacket and blue pants standing on a sidewalk'},\n",
       " {'image_id': tensor(130171), 'caption': 'a bowl of fruit with a spoon in it'},\n",
       " {'image_id': tensor(512116),\n",
       "  'caption': 'a little boy standing in a living room with a remote control'},\n",
       " {'image_id': tensor(455464),\n",
       "  'caption': 'a man with glasses and a cup with a cell phone'},\n",
       " {'image_id': tensor(214527),\n",
       "  'caption': 'a clock tower in the middle of a street'},\n",
       " {'image_id': tensor(138965),\n",
       "  'caption': 'a group of stuffed animals sitting on top of a bed'},\n",
       " {'image_id': tensor(8277),\n",
       "  'caption': 'a plate of food with a fork and a bowl of soup'},\n",
       " {'image_id': tensor(118134),\n",
       "  'caption': 'a large clock tower with a massive clock on its face'},\n",
       " {'image_id': tensor(498555),\n",
       "  'caption': 'a white vase with a flower inside of it'},\n",
       " {'image_id': tensor(157102),\n",
       "  'caption': 'a baby sitting at a table with a plate of food'},\n",
       " {'image_id': tensor(16928),\n",
       "  'caption': 'a rusty old fire hydrant in the middle of a forest'},\n",
       " {'image_id': tensor(271607),\n",
       "  'caption': 'a group of people standing around a wooden fence'},\n",
       " {'image_id': tensor(55772),\n",
       "  'caption': 'a person standing in the middle of a flower in the sun'},\n",
       " {'image_id': tensor(360170),\n",
       "  'caption': 'a group of people standing in a busy train'},\n",
       " {'image_id': tensor(227220),\n",
       "  'caption': 'a kitchen with a stove and a refrigerator'},\n",
       " {'image_id': tensor(538092),\n",
       "  'caption': 'a man standing in a kitchen with a refrigerator'},\n",
       " {'image_id': tensor(443949),\n",
       "  'caption': 'a kitchen with a stove and a refrigerator'},\n",
       " {'image_id': tensor(223094),\n",
       "  'caption': 'a refrigerator with a lot of food inside of it'},\n",
       " {'image_id': tensor(570138),\n",
       "  'caption': 'a bathroom with a toilet sink and mirror'},\n",
       " {'image_id': tensor(557135),\n",
       "  'caption': 'a kitchen with a sink and a refrigerator'},\n",
       " {'image_id': tensor(122302),\n",
       "  'caption': 'a row of parked motorcycles sitting on the side of a street'},\n",
       " {'image_id': tensor(386766),\n",
       "  'caption': 'a bathroom with a sink toilet and bathtub'},\n",
       " {'image_id': tensor(576576),\n",
       "  'caption': 'a bathroom with a toilet sink and mirror'},\n",
       " {'image_id': tensor(445812),\n",
       "  'caption': 'a bathroom with a sink and a toilet'},\n",
       " {'image_id': tensor(231732),\n",
       "  'caption': 'a bathroom with a sink and a mirror'},\n",
       " {'image_id': tensor(416184),\n",
       "  'caption': 'a bathroom with a toilet and a shower'},\n",
       " {'image_id': tensor(290078),\n",
       "  'caption': 'a white toilet sitting on the side of a road'},\n",
       " {'image_id': tensor(372495),\n",
       "  'caption': 'a bathroom with a toilet and a sink'},\n",
       " {'image_id': tensor(262514),\n",
       "  'caption': 'a white toilet sitting next to a walk in shower'},\n",
       " {'image_id': tensor(294763),\n",
       "  'caption': 'a white toilet sitting in a bathroom next to a tiled wall'},\n",
       " {'image_id': tensor(489624),\n",
       "  'caption': 'a toilet with a wooden seat and a white sink'},\n",
       " {'image_id': tensor(578314),\n",
       "  'caption': 'a white toilet in a very small room'},\n",
       " {'image_id': tensor(131504),\n",
       "  'caption': 'a clock tower with a large clock on its face'},\n",
       " {'image_id': tensor(50443), 'caption': 'a bathroom with a toilet and a sink'},\n",
       " {'image_id': tensor(84064),\n",
       "  'caption': 'a toilet with the lid up and a device on the wall'},\n",
       " {'image_id': tensor(185930), 'caption': 'a row of urinals mounted to a wall'},\n",
       " {'image_id': tensor(355221),\n",
       "  'caption': 'a row of parked motorcycles sitting on top of a street'},\n",
       " {'image_id': tensor(223930),\n",
       "  'caption': 'a motorcycle parked on the side of a street'},\n",
       " {'image_id': tensor(348708),\n",
       "  'caption': 'a plate with a bunch of bananas on it'},\n",
       " {'image_id': tensor(324008),\n",
       "  'caption': 'a tray of food with a sandwich and a bag of chips'},\n",
       " {'image_id': tensor(520108), 'caption': 'a bedroom with a bed and a table'},\n",
       " {'image_id': tensor(573756),\n",
       "  'caption': 'a giraffe standing in the middle of a lush green field'},\n",
       " {'image_id': tensor(188173),\n",
       "  'caption': 'a group of giraffes standing in a field'},\n",
       " {'image_id': tensor(233882),\n",
       "  'caption': 'a red and white plane sitting on a runway'},\n",
       " {'image_id': tensor(413734),\n",
       "  'caption': 'a large jetliner sitting on top of an airport tarmac'},\n",
       " {'image_id': tensor(373846),\n",
       "  'caption': 'a large jetliner sitting on top of an airport tarmac'},\n",
       " {'image_id': tensor(189197),\n",
       "  'caption': 'a person walking on a path near a body of water'},\n",
       " {'image_id': tensor(122007),\n",
       "  'caption': 'two giraffes standing in a field with mountains in the background'},\n",
       " {'image_id': tensor(181948),\n",
       "  'caption': 'a street with cars and street signs and trees'},\n",
       " {'image_id': tensor(315128),\n",
       "  'caption': 'a street sign on a street corner with a sky background'},\n",
       " {'image_id': tensor(199247),\n",
       "  'caption': 'a herd of sheep grazing on a lush green field'},\n",
       " {'image_id': tensor(974),\n",
       "  'caption': 'a group of people riding on the back of an elephant'},\n",
       " {'image_id': tensor(137265),\n",
       "  'caption': 'a red umbrella sitting on top of a white building'},\n",
       " {'image_id': tensor(507921),\n",
       "  'caption': 'a no parking sign on a pole on a city street'},\n",
       " {'image_id': tensor(40621),\n",
       "  'caption': 'a giraffe standing in a dirt field next to a fence'},\n",
       " {'image_id': tensor(262175),\n",
       "  'caption': 'a man wearing a hat and holding a frisbee'},\n",
       " {'image_id': tensor(548538),\n",
       "  'caption': 'a train traveling down tracks next to a forest'},\n",
       " {'image_id': tensor(65981),\n",
       "  'caption': 'a train traveling down tracks next to a forest'},\n",
       " {'image_id': tensor(167510),\n",
       "  'caption': 'a stop sign is shown on a street corner'},\n",
       " {'image_id': tensor(45966), 'caption': 'a sign on a pole on a street'},\n",
       " {'image_id': tensor(51961),\n",
       "  'caption': 'a graffiti covered wall with graffiti on it'},\n",
       " {'image_id': tensor(457900),\n",
       "  'caption': 'a bus is parked outside of a building'},\n",
       " {'image_id': tensor(71090),\n",
       "  'caption': 'a stuffed animal sitting on a window sill'},\n",
       " {'image_id': tensor(186518),\n",
       "  'caption': 'a large yellow train on a steel track'},\n",
       " {'image_id': tensor(576084),\n",
       "  'caption': 'a white horse standing next to a white horse'},\n",
       " {'image_id': tensor(342334),\n",
       "  'caption': 'a harbor filled with lots of small boats'},\n",
       " {'image_id': tensor(370749),\n",
       "  'caption': 'a large elephant walking in a grass field'},\n",
       " {'image_id': tensor(42055),\n",
       "  'caption': 'a blue and white umbrella sitting in the middle of a street'},\n",
       " {'image_id': tensor(21864),\n",
       "  'caption': 'a view of a body of water with a sky in the background'},\n",
       " {'image_id': tensor(412813),\n",
       "  'caption': 'a person sitting under an umbrella on the beach'},\n",
       " {'image_id': tensor(532867),\n",
       "  'caption': 'a woman holding a red umbrella on the beach'},\n",
       " {'image_id': tensor(550051),\n",
       "  'caption': 'a group of people sitting at a table with a red umbrella'},\n",
       " {'image_id': tensor(303215),\n",
       "  'caption': 'a white teddy bear hanging from a wire'},\n",
       " {'image_id': tensor(446522),\n",
       "  'caption': 'a dog is sitting on a couch in a living room'},\n",
       " {'image_id': tensor(313398),\n",
       "  'caption': 'a black dog laying on a yellow frisbee next to a plastic toy'},\n",
       " {'image_id': tensor(424812),\n",
       "  'caption': 'a horse and rider in a black and white photo'},\n",
       " {'image_id': tensor(371004),\n",
       "  'caption': 'a zebra standing next to a fence in a field'},\n",
       " {'image_id': tensor(546095),\n",
       "  'caption': 'a group of horses grazing in a field'},\n",
       " {'image_id': tensor(51540),\n",
       "  'caption': 'a large clock sitting on a table in a store'},\n",
       " {'image_id': tensor(307967),\n",
       "  'caption': 'a young boy holding a baseball bat on a field'},\n",
       " {'image_id': tensor(248980),\n",
       "  'caption': 'a plate of food with broccoli and a fork'},\n",
       " {'image_id': tensor(277440),\n",
       "  'caption': 'a computer desk with a computer on top of it'},\n",
       " {'image_id': tensor(40635),\n",
       "  'caption': 'a fruit stand with a wide variety of fruits and vegetables'},\n",
       " {'image_id': tensor(503595),\n",
       "  'caption': 'a plate of food with a fork and a fork'},\n",
       " {'image_id': tensor(126257),\n",
       "  'caption': 'a young boy riding a skateboard on a street'},\n",
       " {'image_id': tensor(118367),\n",
       "  'caption': 'a person holding a hot dog in their hand'},\n",
       " {'image_id': tensor(437789),\n",
       "  'caption': 'a table with various foods and fruits and a bowl of fruit'},\n",
       " {'image_id': tensor(272323),\n",
       "  'caption': 'a skateboarder is riding down a ramp on his skateboard'},\n",
       " {'image_id': tensor(70256), 'caption': 'a person cutting a cake on a table'},\n",
       " {'image_id': tensor(12817),\n",
       "  'caption': 'a man is doing a trick on a skateboard'},\n",
       " {'image_id': tensor(348730),\n",
       "  'caption': 'a man riding a skateboard down a street'},\n",
       " {'image_id': tensor(114684),\n",
       "  'caption': 'a woman sitting on a bench with a cell phone'},\n",
       " {'image_id': tensor(296236),\n",
       "  'caption': 'a woman is preparing a doughnut in a commercial kitchen'},\n",
       " {'image_id': tensor(412604),\n",
       "  'caption': 'a man in a blue sweater holding a banana'},\n",
       " {'image_id': tensor(523816),\n",
       "  'caption': 'a person on a snowboard on a snowy hill'},\n",
       " {'image_id': tensor(329475),\n",
       "  'caption': 'a display case filled with lots of donuts'},\n",
       " {'image_id': tensor(61647),\n",
       "  'caption': 'a cake with a bunch of cupcakes on top'},\n",
       " {'image_id': tensor(88269),\n",
       "  'caption': 'a plate with a sandwich and a bowl of soup'},\n",
       " {'image_id': tensor(211326),\n",
       "  'caption': 'a plate with a sandwich and a cup of coffee'},\n",
       " {'image_id': tensor(48668),\n",
       "  'caption': 'a man laying in bed with a blanket and a pillow'},\n",
       " {'image_id': tensor(308883),\n",
       "  'caption': 'a living room with a television and a couch'},\n",
       " {'image_id': tensor(193494),\n",
       "  'caption': 'a bed with a blue blanket and a blue blanket'},\n",
       " {'image_id': tensor(184139),\n",
       "  'caption': 'a bed with a white bedspread and a green light'},\n",
       " {'image_id': tensor(419860), 'caption': 'a large pizza that is on a table'},\n",
       " {'image_id': tensor(388481),\n",
       "  'caption': 'a laptop computer sitting on top of a wooden desk'},\n",
       " {'image_id': tensor(97561),\n",
       "  'caption': 'a small bathroom with a sink and mirror'},\n",
       " {'image_id': tensor(70020),\n",
       "  'caption': 'a woman holding a tennis racket on a tennis court'},\n",
       " {'image_id': tensor(466882),\n",
       "  'caption': 'a tennis player is serving the ball in a tennis match'},\n",
       " {'image_id': tensor(323356),\n",
       "  'caption': 'a man holding a blue frisbee while standing in a field'},\n",
       " {'image_id': tensor(405440),\n",
       "  'caption': 'a laptop computer sitting on top of a wooden desk'},\n",
       " {'image_id': tensor(148329), 'caption': 'a man eating a hot dog in a bun'},\n",
       " {'image_id': tensor(279524),\n",
       "  'caption': 'a living room with a couch and a tv'},\n",
       " {'image_id': tensor(91304),\n",
       "  'caption': 'a bed with a wooden head board and a small bed'},\n",
       " {'image_id': tensor(315486),\n",
       "  'caption': 'a little girl standing in front of a sink'},\n",
       " {'image_id': tensor(365325),\n",
       "  'caption': 'a baby sleeping on a bed with a blue blanket'},\n",
       " {'image_id': tensor(79686),\n",
       "  'caption': 'a living room with a couch a table and a tv'},\n",
       " {'image_id': tensor(499095),\n",
       "  'caption': 'a group of people playing a game with remote controllers'},\n",
       " {'image_id': tensor(35825),\n",
       "  'caption': 'a woman holding a nintendo wii game controller'},\n",
       " {'image_id': tensor(414071),\n",
       "  'caption': 'three young men standing in a living room holding wii remotes'},\n",
       " {'image_id': tensor(520430),\n",
       "  'caption': 'a woman holding a wii remote in her hand'},\n",
       " {'image_id': tensor(4125),\n",
       "  'caption': 'a living room with a couch and a coffee table'},\n",
       " {'image_id': tensor(487774), 'caption': 'a mouse and a keyboard on a table'},\n",
       " {'image_id': tensor(157516),\n",
       "  'caption': 'a man and a child are sitting on a coach'},\n",
       " {'image_id': tensor(217957),\n",
       "  'caption': 'a building with a clock on the front and side of it'},\n",
       " {'image_id': tensor(415727), 'caption': 'a group of kids standing in a room'},\n",
       " {'image_id': tensor(251367),\n",
       "  'caption': 'a baseball player holding a bat on a field'},\n",
       " {'image_id': tensor(148588),\n",
       "  'caption': 'a pizza sitting on top of a wooden table'},\n",
       " {'image_id': tensor(93765),\n",
       "  'caption': 'a coffee cup and a vase of flowers on a table'},\n",
       " {'image_id': tensor(488736),\n",
       "  'caption': 'a large clock on the side of a building'},\n",
       " {'image_id': tensor(324837),\n",
       "  'caption': 'a laptop computer sitting on top of a wooden desk'},\n",
       " {'image_id': tensor(63602),\n",
       "  'caption': 'a computer desk with a laptop computer on top of it'},\n",
       " {'image_id': tensor(33904),\n",
       "  'caption': 'a teddy bear sitting on a couch with a book'},\n",
       " {'image_id': tensor(445041),\n",
       "  'caption': 'a man riding a motorcycle down a street'},\n",
       " {'image_id': tensor(54959),\n",
       "  'caption': 'a kitchen with a stove and a microwave'},\n",
       " {'image_id': tensor(299946),\n",
       "  'caption': 'a man in a kitchen preparing food on a cutting board'},\n",
       " {'image_id': tensor(65969),\n",
       "  'caption': 'a table with a glass of water and a vase filled with flowers'},\n",
       " {'image_id': tensor(550322),\n",
       "  'caption': 'a pair of scissors sitting on a table'},\n",
       " {'image_id': tensor(76329), 'caption': 'a clock on a pole on a street'},\n",
       " {'image_id': tensor(368505),\n",
       "  'caption': 'a large building with a clock on the front'},\n",
       " {'image_id': tensor(213224),\n",
       "  'caption': 'a vase of flowers sitting on a table'},\n",
       " {'image_id': tensor(478282),\n",
       "  'caption': 'a vase with flowers in it sitting on a table'},\n",
       " {'image_id': tensor(251590),\n",
       "  'caption': 'a vase filled with flowers sitting on top of a table'},\n",
       " {'image_id': tensor(425475),\n",
       "  'caption': 'a person holding a glass of wine in their hand'},\n",
       " {'image_id': tensor(448795),\n",
       "  'caption': 'a view of a bathroom with a toilet and sink'},\n",
       " {'image_id': tensor(345389),\n",
       "  'caption': 'a woman standing in a kitchen with a blue towel'},\n",
       " {'image_id': tensor(280736),\n",
       "  'caption': 'a cat sitting on a ledge looking up at a person'},\n",
       " {'image_id': tensor(45208), 'caption': 'a black cat is standing in the sink'},\n",
       " {'image_id': tensor(557501),\n",
       "  'caption': 'a bathroom with a toilet and a sink'},\n",
       " {'image_id': tensor(496604),\n",
       "  'caption': 'a white toilet sitting next to a white sink'},\n",
       " {'image_id': tensor(46099), 'caption': 'a stop sign on a pole on a street'},\n",
       " {'image_id': tensor(144798),\n",
       "  'caption': 'a bathroom with a toilet sink and mirror'},\n",
       " {'image_id': tensor(463825), 'caption': 'a cat sitting in a bathroom sink'},\n",
       " {'image_id': tensor(50411), 'caption': 'a man riding a horse down a street'},\n",
       " {'image_id': tensor(524637),\n",
       "  'caption': 'a white toilet sitting in a bathroom next to a window'},\n",
       " {'image_id': tensor(562592),\n",
       "  'caption': 'a motorcycle is parked on the side of the road'},\n",
       " {'image_id': tensor(465424),\n",
       "  'caption': 'a group of people on motorcycles are parked on the side of the'},\n",
       " {'image_id': tensor(425151),\n",
       "  'caption': 'a living room with a couch and a coffee table'},\n",
       " {'image_id': tensor(210032),\n",
       "  'caption': 'a chicken sandwich and a cup of water on a table'},\n",
       " {'image_id': tensor(21202),\n",
       "  'caption': 'a street with cars and traffic lights on it'},\n",
       " {'image_id': tensor(398007),\n",
       "  'caption': 'a train station with a train coming up the tracks'},\n",
       " {'image_id': tensor(322824),\n",
       "  'caption': 'a street sign on a pole on a city street'},\n",
       " {'image_id': tensor(376236),\n",
       "  'caption': 'a young boy feeding a giraffe from a wooden fence'},\n",
       " {'image_id': tensor(468933),\n",
       "  'caption': 'a herd of sheep standing on top of a grass covered field'},\n",
       " {'image_id': tensor(68203),\n",
       "  'caption': 'a giraffe standing in a field with a mountain in the background'},\n",
       " {'image_id': tensor(197745),\n",
       "  'caption': 'two giraffes are standing next to each other'},\n",
       " {'image_id': tensor(352476),\n",
       "  'caption': 'a group of bicycles are parked next to a bus'},\n",
       " {'image_id': tensor(89909),\n",
       "  'caption': 'a wooden bench sitting in front of a garden'},\n",
       " {'image_id': tensor(38048),\n",
       "  'caption': 'a red and white fire hydrant sitting on the side of a road'},\n",
       " {'image_id': tensor(322955),\n",
       "  'caption': 'a bird standing on the beach looking out at the ocean'},\n",
       " {'image_id': tensor(211054),\n",
       "  'caption': 'a train traveling down tracks next to a building'},\n",
       " {'image_id': tensor(500703),\n",
       "  'caption': 'a train is traveling down the tracks in a city'},\n",
       " {'image_id': tensor(340637),\n",
       "  'caption': 'a cell phone sitting on a table next to a cell phone'},\n",
       " {'image_id': tensor(174329),\n",
       "  'caption': 'a yellow train is sitting on the tracks'},\n",
       " {'image_id': tensor(499537),\n",
       "  'caption': 'a street sign on a pole on a city street'},\n",
       " {'image_id': tensor(206770),\n",
       "  'caption': 'a truck is parked in front of a house'},\n",
       " {'image_id': tensor(67255),\n",
       "  'caption': 'a stop sign with a street sign on top of it'},\n",
       " {'image_id': tensor(258078),\n",
       "  'caption': 'a young boy is standing next to a bike'},\n",
       " {'image_id': tensor(171695),\n",
       "  'caption': 'a large bus with a colorful roof driving down a street'},\n",
       " {'image_id': tensor(79816), 'caption': 'a truck is parked in a dirt lot'},\n",
       " {'image_id': tensor(90366),\n",
       "  'caption': 'a couple of animals that are standing in the dirt'},\n",
       " {'image_id': tensor(76155),\n",
       "  'caption': 'a large group of cows standing in a field'},\n",
       " {'image_id': tensor(350084),\n",
       "  'caption': 'a white dump truck driving down a dirt road'},\n",
       " {'image_id': tensor(103272),\n",
       "  'caption': 'a large truck with a wooden deck parked in a field'},\n",
       " {'image_id': tensor(519764),\n",
       "  'caption': 'a black cat laying on a chair in a room'},\n",
       " {'image_id': tensor(450404),\n",
       "  'caption': 'a large truck parked in a field with a fence'},\n",
       " {'image_id': tensor(436676),\n",
       "  'caption': 'a woman laying on a couch with a black cat'},\n",
       " {'image_id': tensor(238459),\n",
       "  'caption': 'a herd of cattle grazing on a lush green field'},\n",
       " {'image_id': tensor(565186),\n",
       "  'caption': 'a large truck with a wooden fence in the back'},\n",
       " {'image_id': tensor(464286),\n",
       "  'caption': 'a herd of cattle standing on top of a pile of hay'},\n",
       " {'image_id': tensor(87470), 'caption': 'a herd of cows walking down a road'},\n",
       " {'image_id': tensor(16005),\n",
       "  'caption': 'a woman is holding a child in a hat as a cow looks'},\n",
       " {'image_id': tensor(163684),\n",
       "  'caption': 'a dog is running in the snow with a frisbee'},\n",
       " {'image_id': tensor(14257),\n",
       "  'caption': 'a group of people walking down a sidewalk'},\n",
       " {'image_id': tensor(533979),\n",
       "  'caption': 'a baby elephant standing next to a large metal fence'},\n",
       " {'image_id': tensor(419344),\n",
       "  'caption': 'a group of people standing around a herd of elephants'},\n",
       " {'image_id': tensor(148188),\n",
       "  'caption': 'a group of people riding on the backs of horses'},\n",
       " {'image_id': tensor(318080),\n",
       "  'caption': 'two bears are playing together in a body of water'},\n",
       " {'image_id': tensor(361551),\n",
       "  'caption': 'a group of people standing around a luggage cart'},\n",
       " {'image_id': tensor(306664),\n",
       "  'caption': 'a polar bear is walking around in the dirt'},\n",
       " {'image_id': tensor(121876), 'caption': 'a polar bear is standing on a rock'},\n",
       " {'image_id': tensor(236784),\n",
       "  'caption': 'two dogs are laying on a couch in a living room'},\n",
       " {'image_id': tensor(406976),\n",
       "  'caption': 'two dogs are laying on a couch with their faces on their faces'},\n",
       " {'image_id': tensor(18480),\n",
       "  'caption': 'a group of people holding frisbees and posing for a picture'},\n",
       " {'image_id': tensor(110435),\n",
       "  'caption': 'a woman is giving a baby a bath in the sink'},\n",
       " {'image_id': tensor(347650), 'caption': 'a dog laying on a bed with a book'},\n",
       " {'image_id': tensor(440895),\n",
       "  'caption': 'a building with a window and a clock on the side of the'},\n",
       " {'image_id': tensor(451305),\n",
       "  'caption': 'a zebra standing on a dirt ground next to a wooden fence'},\n",
       " {'image_id': tensor(431521),\n",
       "  'caption': 'a view of a field with a fence in the distance'},\n",
       " {'image_id': tensor(361919),\n",
       "  'caption': 'a group of people riding skis on a snowy surface'},\n",
       " {'image_id': tensor(424174),\n",
       "  'caption': 'a bunch of fruit sitting on a table'},\n",
       " {'image_id': tensor(332096),\n",
       "  'caption': 'a group of men playing baseball on a field'},\n",
       " {'image_id': tensor(158722),\n",
       "  'caption': 'a woman sitting on a bench in front of a store'},\n",
       " {'image_id': tensor(394801), 'caption': 'a bunch of bananas are on a table'},\n",
       " {'image_id': tensor(498439),\n",
       "  'caption': 'a group of baseball players standing on top of a field'},\n",
       " {'image_id': tensor(374369),\n",
       "  'caption': 'a person riding skis on a snowy surface'},\n",
       " {'image_id': tensor(313176),\n",
       "  'caption': 'a pizza with cheese and tomatoes on a pan'},\n",
       " {'image_id': tensor(556726),\n",
       "  'caption': 'a close up of a broccoli on a wooden surface'},\n",
       " {'image_id': tensor(123321),\n",
       "  'caption': 'a bowl of soup with broccoli and a spoon'},\n",
       " {'image_id': tensor(539079),\n",
       "  'caption': 'a person riding skis on a snowy slope'},\n",
       " {'image_id': tensor(36238),\n",
       "  'caption': 'a plate of food with broccoli and meat'},\n",
       " {'image_id': tensor(520508),\n",
       "  'caption': 'a person riding skis on a snowy surface'},\n",
       " {'image_id': tensor(149456),\n",
       "  'caption': 'a bunch of vegetables are sitting on a table'},\n",
       " {'image_id': tensor(414385),\n",
       "  'caption': 'a person riding a motorcycle on a highway'},\n",
       " {'image_id': tensor(497907),\n",
       "  'caption': 'a person on a snowboard on a snowy hill'},\n",
       " {'image_id': tensor(146272),\n",
       "  'caption': 'a person on a snowboard on a snowy slope'},\n",
       " {'image_id': tensor(320664),\n",
       "  'caption': 'a plate of food with a fork and a cup of coleslaw'},\n",
       " {'image_id': tensor(190391),\n",
       "  'caption': 'a hot dog with mustard and ketchup on a plate'},\n",
       " {'image_id': tensor(183786),\n",
       "  'caption': 'a group of doughnuts are sitting on a table'},\n",
       " {'image_id': tensor(325027),\n",
       "  'caption': 'a person holding a sandwich in their hand'},\n",
       " {'image_id': tensor(62230),\n",
       "  'caption': 'a group of men playing a game of basketball'},\n",
       " {'image_id': tensor(410885),\n",
       "  'caption': 'a group of people riding surfboards on top of a sandy beach'},\n",
       " {'image_id': tensor(810),\n",
       "  'caption': 'a hot dog with a side of fries and a drink'},\n",
       " {'image_id': tensor(276434), 'caption': 'a person cutting a cake on a table'},\n",
       " {'image_id': tensor(566529),\n",
       "  'caption': 'a man laying in a bed with a stuffed animal'},\n",
       " {'image_id': tensor(375285),\n",
       "  'caption': 'a group of people standing on a beach with surfboards'},\n",
       " {'image_id': tensor(105234),\n",
       "  'caption': 'a man and woman in a white dress and a man in a'},\n",
       " {'image_id': tensor(203734),\n",
       "  'caption': 'three young boys sitting on a bench eating pizza'},\n",
       " {'image_id': tensor(526972),\n",
       "  'caption': 'a pizza with several toppings on a rack'},\n",
       " {'image_id': tensor(478528),\n",
       "  'caption': 'a living room with a couch and a table'},\n",
       " {'image_id': tensor(4312),\n",
       "  'caption': 'a person sitting at a table with a plate of food'},\n",
       " {'image_id': tensor(410101),\n",
       "  'caption': 'a man standing in a room with a remote'},\n",
       " {'image_id': tensor(514787),\n",
       "  'caption': 'a group of people playing a game with remote controllers'},\n",
       " {'image_id': tensor(26584),\n",
       "  'caption': 'a hand holding a wii game controller in front of a tv'},\n",
       " {'image_id': tensor(546964),\n",
       "  'caption': 'a large room with a lot of chairs and tables'},\n",
       " {'image_id': tensor(164759),\n",
       "  'caption': 'a living room with a couch and a tv'},\n",
       " {'image_id': tensor(361527),\n",
       "  'caption': 'a computer monitor sitting on top of a wooden desk'},\n",
       " {'image_id': tensor(281782), 'caption': 'a man flying a kite in a yard'},\n",
       " {'image_id': tensor(579307),\n",
       "  'caption': 'two young children carrying their surfboards on the beach'},\n",
       " {'image_id': tensor(291962),\n",
       "  'caption': 'a young girl flying a kite in a field'},\n",
       " {'image_id': tensor(162445),\n",
       "  'caption': 'a group of people in a field flying kites'},\n",
       " {'image_id': tensor(136642),\n",
       "  'caption': 'a baseball player holding a bat on a field'},\n",
       " {'image_id': tensor(138553),\n",
       "  'caption': 'a baseball player holding a bat on a baseball field'},\n",
       " {'image_id': tensor(54593),\n",
       "  'caption': 'a young boy swinging a bat at a ball'},\n",
       " {'image_id': tensor(520787),\n",
       "  'caption': 'a slice of pizza on a plate with a fork and knife'},\n",
       " {'image_id': tensor(525646),\n",
       "  'caption': 'a pizza with a lot of veggies on it'},\n",
       " {'image_id': tensor(116208),\n",
       "  'caption': 'a large pizza with several toppings on a table'},\n",
       " {'image_id': tensor(208623),\n",
       "  'caption': 'a man sitting at a table using a laptop computer'},\n",
       " {'image_id': tensor(493623),\n",
       "  'caption': 'a white toilet sitting next to a white bath tub'},\n",
       " {'image_id': tensor(191069),\n",
       "  'caption': 'a person holding a cell phone in their hand'},\n",
       " {'image_id': tensor(221700),\n",
       "  'caption': 'a pair of scissors sitting on top of a table'},\n",
       " {'image_id': tensor(318290),\n",
       "  'caption': 'a microwave oven sitting on top of a table'},\n",
       " {'image_id': tensor(149500),\n",
       "  'caption': 'a man is sitting on a couch and holding a toothbrush'},\n",
       " {'image_id': tensor(205720),\n",
       "  'caption': 'a man is taking a picture of a boat'},\n",
       " {'image_id': tensor(309933),\n",
       "  'caption': 'a kitchen with a stove and a refrigerator'},\n",
       " {'image_id': tensor(233376),\n",
       "  'caption': 'a refrigerator and freezer in a small kitchen'},\n",
       " {'image_id': tensor(452881),\n",
       "  'caption': 'a room with a bed and a table with a vase on it'},\n",
       " {'image_id': tensor(292804),\n",
       "  'caption': 'a large clock on a wall in a train station'},\n",
       " {'image_id': tensor(321437), 'caption': 'a clock on a pole on a city street'},\n",
       " {'image_id': tensor(108853),\n",
       "  'caption': 'a vase of flowers sitting on a table'},\n",
       " {'image_id': tensor(410880),\n",
       "  'caption': 'a teddy bear sitting on a table in a room'},\n",
       " {'image_id': tensor(135399),\n",
       "  'caption': 'a table topped with plates of food and cups of coffee'},\n",
       " {'image_id': tensor(349184),\n",
       "  'caption': 'a woman sitting on a bench with her legs crossed'},\n",
       " {'image_id': tensor(130909),\n",
       "  'caption': 'a man and woman in a kitchen with a stove and a sink'},\n",
       " {'image_id': tensor(369913),\n",
       "  'caption': 'a woman holding a pair of scissors in her hands'},\n",
       " {'image_id': tensor(404462),\n",
       "  'caption': 'a black and white photo of a bathroom mirror'},\n",
       " {'image_id': tensor(300034),\n",
       "  'caption': 'a bathroom with a white toilet sitting next to a sink'},\n",
       " {'image_id': tensor(380854),\n",
       "  'caption': 'a bathroom with a toilet sink and mirror'},\n",
       " {'image_id': tensor(511583),\n",
       "  'caption': 'a car parked on the side of the road'},\n",
       " {'image_id': tensor(210273),\n",
       "  'caption': 'a busy street with cars and buses on it'},\n",
       " {'image_id': tensor(161112),\n",
       "  'caption': 'a man sitting on a couch with a cat'},\n",
       " {'image_id': tensor(120428),\n",
       "  'caption': 'a woman standing in a room with a wooden floor'},\n",
       " {'image_id': tensor(215408),\n",
       "  'caption': 'a large church tower with a clock on it'},\n",
       " {'image_id': tensor(46571),\n",
       "  'caption': 'a motorcycle parked on the side of a road'},\n",
       " {'image_id': tensor(542509),\n",
       "  'caption': 'a computer desk with a computer and a computer'},\n",
       " {'image_id': tensor(556349),\n",
       "  'caption': 'a red motorcycle parked on a sidewalk near a street'},\n",
       " {'image_id': tensor(475923),\n",
       "  'caption': 'a blue door with a door open and a white toilet'},\n",
       " {'image_id': tensor(534733),\n",
       "  'caption': 'a living room with a couch and a tv'},\n",
       " {'image_id': tensor(82229),\n",
       "  'caption': 'a television is on a stand in a room'},\n",
       " {'image_id': tensor(52017), 'caption': 'a small plane is flying in the air'},\n",
       " {'image_id': tensor(238700),\n",
       "  'caption': 'a giraffe standing in a field with lots of green grass'},\n",
       " {'image_id': tensor(526645),\n",
       "  'caption': 'a giraffe standing in the middle of a forest'},\n",
       " {'image_id': tensor(577866),\n",
       "  'caption': 'a man riding a bike down a street next to a truck'},\n",
       " {'image_id': tensor(361400),\n",
       "  'caption': 'a traffic light on a city street at night'},\n",
       " {'image_id': tensor(535578),\n",
       "  'caption': 'a herd of sheep grazing on a lush green hillside'},\n",
       " {'image_id': tensor(263011),\n",
       "  'caption': 'a group of people standing in front of a bus'},\n",
       " {'image_id': tensor(122051), 'caption': 'a car is stopped at a stop sign'},\n",
       " {'image_id': tensor(473171),\n",
       "  'caption': 'a stop sign on a street corner near a house'},\n",
       " {'image_id': tensor(150576),\n",
       "  'caption': 'a giraffe and a zebra are in a grassy field'},\n",
       " {'image_id': tensor(458560),\n",
       "  'caption': 'a bird standing on the ground in the water'},\n",
       " {'image_id': tensor(74465),\n",
       "  'caption': 'a train traveling down tracks next to a building'},\n",
       " {'image_id': tensor(393942),\n",
       "  'caption': 'a black and white photo of a person riding a train'},\n",
       " {'image_id': tensor(56983), 'caption': 'a bird flying over a bunch of birds'},\n",
       " {'image_id': tensor(144715),\n",
       "  'caption': 'a train traveling down tracks next to a forest'},\n",
       " {'image_id': tensor(199257),\n",
       "  'caption': 'a street sign on a pole on a street'},\n",
       " {'image_id': tensor(517967),\n",
       "  'caption': 'a woman in a hat is sitting on a laptop'},\n",
       " {'image_id': tensor(448786),\n",
       "  'caption': 'a white and blue train is on a train track'},\n",
       " {'image_id': tensor(506416),\n",
       "  'caption': 'a red and white train traveling down train tracks'},\n",
       " {'image_id': tensor(25747),\n",
       "  'caption': 'a red and white train on tracks next to trees'},\n",
       " {'image_id': tensor(224554),\n",
       "  'caption': 'a red and yellow train traveling down train tracks'},\n",
       " {'image_id': tensor(25550),\n",
       "  'caption': 'a group of people standing around a street'},\n",
       " {'image_id': tensor(128528),\n",
       "  'caption': 'a dog running in the snow with a frisbee'},\n",
       " {'image_id': tensor(153966),\n",
       "  'caption': 'a black and white cat laying on a bed'},\n",
       " {'image_id': tensor(480720),\n",
       "  'caption': 'two cats looking at each other through a mirror'},\n",
       " {'image_id': tensor(93803),\n",
       "  'caption': 'a construction site with a train going over it'},\n",
       " {'image_id': tensor(310618),\n",
       "  'caption': 'a giraffe eating leaves from a tree in a field'},\n",
       " {'image_id': tensor(290839),\n",
       "  'caption': 'a group of people standing on a boat in the water'},\n",
       " {'image_id': tensor(476552),\n",
       "  'caption': 'a woman standing in a boat filled with produce'},\n",
       " {'image_id': tensor(111109),\n",
       "  'caption': 'a young boy wearing a tie and holding a tennis racket'},\n",
       " {'image_id': tensor(542388),\n",
       "  'caption': 'a man in a suit and tie wearing a suit and tie'},\n",
       " {'image_id': tensor(135281),\n",
       "  'caption': 'a woman walking down a street holding an umbrella'},\n",
       " {'image_id': tensor(152252),\n",
       "  'caption': 'a large group of people standing in front of a building'},\n",
       " {'image_id': tensor(292685),\n",
       "  'caption': 'a group of people standing around a red and white building'},\n",
       " {'image_id': tensor(1682),\n",
       "  'caption': 'a boat is floating in the water near the shore'},\n",
       " {'image_id': tensor(360960),\n",
       "  'caption': 'a group of people walking down a sidewalk holding umbrellas'},\n",
       " {'image_id': tensor(456690),\n",
       "  'caption': 'a group of zebras grazing in a field'},\n",
       " {'image_id': tensor(31390),\n",
       "  'caption': 'a group of young men playing a game of soccer'},\n",
       " {'image_id': tensor(303267),\n",
       "  'caption': 'a couple of animals that are in the grass'},\n",
       " {'image_id': tensor(23034),\n",
       "  'caption': 'a man with a backpack and a dog on a leash'},\n",
       " {'image_id': tensor(359838),\n",
       "  'caption': 'a group of horses standing in a field'},\n",
       " {'image_id': tensor(377984),\n",
       "  'caption': 'a young girl riding on the back of a black horse'},\n",
       " {'image_id': tensor(546854),\n",
       "  'caption': 'a table with a plate of fruit and a bowl of oranges'},\n",
       " {'image_id': tensor(333156),\n",
       "  'caption': 'a chocolate cake with a piece cut out of it'},\n",
       " {'image_id': tensor(78959),\n",
       "  'caption': 'a bunch of bananas hanging from a tree'},\n",
       " {'image_id': tensor(229274),\n",
       "  'caption': 'a bunch of bananas hanging from a tree'},\n",
       " {'image_id': tensor(66179),\n",
       "  'caption': 'a bunch of apples hanging from a banana tree'},\n",
       " {'image_id': tensor(378098),\n",
       "  'caption': 'a plate of food with a fork and knife'},\n",
       " {'image_id': tensor(377111),\n",
       "  'caption': 'a man riding a skateboard on a ramp'},\n",
       " {'image_id': tensor(439092),\n",
       "  'caption': 'two people standing in the snow with their snowboards on their feet'},\n",
       " {'image_id': tensor(60970),\n",
       "  'caption': 'a plate of food with broccoli and rice'},\n",
       " {'image_id': tensor(516813),\n",
       "  'caption': 'a young boy riding a snowboard on a snow covered slope'},\n",
       " {'image_id': tensor(292170),\n",
       "  'caption': 'a woman standing in a market filled with lots of red fruit'},\n",
       " {'image_id': tensor(535306),\n",
       "  'caption': 'a man on a skateboard jumping over a metal ramp'},\n",
       " {'image_id': tensor(368528),\n",
       "  'caption': 'a man riding skis down a snow covered slope'},\n",
       " {'image_id': tensor(304834),\n",
       "  'caption': 'a woman riding a skateboard down a sidewalk'},\n",
       " {'image_id': tensor(536791),\n",
       "  'caption': 'a man is doing a trick on a skateboard'},\n",
       " {'image_id': tensor(302599),\n",
       "  'caption': 'a man on a skateboard jumping over a set of stairs'},\n",
       " {'image_id': tensor(160351),\n",
       "  'caption': 'a man riding a skateboard down a street'},\n",
       " {'image_id': tensor(93353),\n",
       "  'caption': 'a person holding a half eaten sandwich in their hand'},\n",
       " {'image_id': tensor(532211),\n",
       "  'caption': 'a man riding a skateboard down a street'},\n",
       " {'image_id': tensor(220187),\n",
       "  'caption': 'a man is doing a trick on a skateboard'},\n",
       " {'image_id': tensor(391365),\n",
       "  'caption': 'a man flying through the air while riding a skateboard'},\n",
       " {'image_id': tensor(230884),\n",
       "  'caption': 'a man riding a skateboard down a street'},\n",
       " {'image_id': tensor(412464),\n",
       "  'caption': 'a sandwich and salad on a white plate'},\n",
       " {'image_id': tensor(283113),\n",
       "  'caption': 'two hot dogs with ketchup and mustard on a plate'},\n",
       " {'image_id': tensor(138675),\n",
       "  'caption': 'a person on a snowboard on a snowy hill'},\n",
       " {'image_id': tensor(162902),\n",
       "  'caption': 'a group of people standing on top of a snow covered slope'},\n",
       " {'image_id': tensor(571449),\n",
       "  'caption': 'a person holding a sandwich in their hand'},\n",
       " {'image_id': tensor(317725),\n",
       "  'caption': 'a chocolate doughnut with sprinkles on a plate'},\n",
       " {'image_id': tensor(205101),\n",
       "  'caption': 'a sandwich and a glass of beer on a table'},\n",
       " {'image_id': tensor(461378),\n",
       "  'caption': 'a large display of colorful flowers on a table'},\n",
       " {'image_id': tensor(45550),\n",
       "  'caption': 'a man holding a plate with a slice of pizza'},\n",
       " {'image_id': tensor(66685),\n",
       "  'caption': 'a surfboard laying on the sand near the ocean'},\n",
       " {'image_id': tensor(173081),\n",
       "  'caption': 'a group of benches that are sitting in the floor'},\n",
       " {'image_id': tensor(46433),\n",
       "  'caption': 'two children are sitting on a bed with books'},\n",
       " {'image_id': tensor(4916),\n",
       "  'caption': 'a woman and a child standing in front of a mirror'},\n",
       " {'image_id': tensor(476939),\n",
       "  'caption': 'a man and woman in a hospital kitchen'},\n",
       " {'image_id': tensor(31281),\n",
       "  'caption': 'a person riding a surf board on a wave'},\n",
       " {'image_id': tensor(541965),\n",
       "  'caption': 'a table with a plate of pizza and a drink'},\n",
       " {'image_id': tensor(345029),\n",
       "  'caption': 'a woman is playing tennis on a court'},\n",
       " {'image_id': tensor(400317),\n",
       "  'caption': 'a man holding a tennis racquet on a tennis court'},\n",
       " {'image_id': tensor(39697),\n",
       "  'caption': 'a pizza sitting on top of a box on top of a table'},\n",
       " {'image_id': tensor(499755),\n",
       "  'caption': 'a woman in a short skirt holding a tennis racquet'},\n",
       " {'image_id': tensor(233915),\n",
       "  'caption': 'a woman is playing tennis on a blue court'},\n",
       " {'image_id': tensor(557130),\n",
       "  'caption': 'a group of young people standing around holding game controllers'},\n",
       " {'image_id': tensor(121611),\n",
       "  'caption': 'a living room with a couch and a table'},\n",
       " {'image_id': tensor(1655),\n",
       "  'caption': 'a man in a red jacket is looking at a cellphone'},\n",
       " {'image_id': tensor(339426),\n",
       "  'caption': 'a baseball player swinging a bat at a ball'},\n",
       " {'image_id': tensor(235836),\n",
       "  'caption': 'a young boy holding a baseball bat and ball'},\n",
       " {'image_id': tensor(322222),\n",
       "  'caption': 'two men playing tennis on a tennis court'},\n",
       " {'image_id': tensor(471015),\n",
       "  'caption': 'a group of people walking down a street'},\n",
       " {'image_id': tensor(515755),\n",
       "  'caption': 'a large brown teddy bear sitting on top of a couch'},\n",
       " {'image_id': tensor(117089),\n",
       "  'caption': 'a plate of food with a sandwich and a cup of coffee'},\n",
       " {'image_id': tensor(290843),\n",
       "  'caption': 'a cat laying on a bed with a laptop on a table'},\n",
       " {'image_id': tensor(11156),\n",
       "  'caption': 'a table with a cell phone a camera and a bag of things'},\n",
       " {'image_id': tensor(545734),\n",
       "  'caption': 'a kitchen with a microwave and a stove top oven'},\n",
       " {'image_id': tensor(128812),\n",
       "  'caption': 'a stove with a microwave on top of it'},\n",
       " {'image_id': tensor(433574),\n",
       "  'caption': 'a man is sitting in a chair with a cell phone'},\n",
       " {'image_id': tensor(525297),\n",
       "  'caption': 'a person taking a picture of a cow with a camera'},\n",
       " {'image_id': tensor(160186),\n",
       "  'caption': 'a man standing in front of a refrigerator in a kitchen'},\n",
       " {'image_id': tensor(544883),\n",
       "  'caption': 'a clock on a building with windows on the front'},\n",
       " {'image_id': tensor(136911),\n",
       "  'caption': 'a plate of food with a sandwich and fruit'},\n",
       " {'image_id': tensor(216710),\n",
       "  'caption': 'a bunch of different types of doughnuts on a table'},\n",
       " {'image_id': tensor(478077),\n",
       "  'caption': 'a kitchen with a stove and a checkered floor'},\n",
       " {'image_id': tensor(182279),\n",
       "  'caption': 'a group of people flying kites in a field'},\n",
       " {'image_id': tensor(28506), 'caption': 'a kitchen with a stove and a sink'},\n",
       " {'image_id': tensor(408449),\n",
       "  'caption': 'a couple of people that are walking down the street'},\n",
       " {'image_id': tensor(208871),\n",
       "  'caption': 'a man standing in a kitchen holding a box of pizza'},\n",
       " {'image_id': tensor(556205),\n",
       "  'caption': 'a man standing on a pier looking out at the water'},\n",
       " {'image_id': tensor(49097),\n",
       "  'caption': 'a dog walking next to a red bicycle on a sidewalk'},\n",
       " {'image_id': tensor(407915),\n",
       "  'caption': 'a bathroom with a sink and a mirror'},\n",
       " {'image_id': tensor(32990),\n",
       "  'caption': 'a bathroom with a toilet and a shower'},\n",
       " {'image_id': tensor(398606),\n",
       "  'caption': 'a bathroom with a sink and a mirror'},\n",
       " {'image_id': tensor(50350),\n",
       "  'caption': 'a bathroom with a toilet sink and shower'},\n",
       " {'image_id': tensor(553558),\n",
       "  'caption': 'a bathroom with a sink and a toilet'},\n",
       " {'image_id': tensor(124462),\n",
       "  'caption': 'a cat sitting in the drivers seat of a car'},\n",
       " {'image_id': tensor(162677),\n",
       "  'caption': 'a bathroom with a toilet and a sink'},\n",
       " {'image_id': tensor(295051),\n",
       "  'caption': 'a black cat sitting on a shelf in front of a window'},\n",
       " {'image_id': tensor(508302),\n",
       "  'caption': 'a man riding a motorcycle with a woman on back of it'},\n",
       " {'image_id': tensor(175024),\n",
       "  'caption': 'a man riding a motorcycle down a street'},\n",
       " {'image_id': tensor(28675),\n",
       "  'caption': 'a car driving down a street with a green light'},\n",
       " {'image_id': tensor(245450),\n",
       "  'caption': 'a train on a train track with a door open'},\n",
       " {'image_id': tensor(457054),\n",
       "  'caption': 'a white airplane with a green jacket on a runway'},\n",
       " {'image_id': tensor(418106),\n",
       "  'caption': 'a large passenger jet sitting on top of an airport runway'},\n",
       " {'image_id': tensor(575904),\n",
       "  'caption': 'a person riding a skateboard down a street'},\n",
       " {'image_id': tensor(393145),\n",
       "  'caption': 'a giraffe is standing in a field of grass'},\n",
       " {'image_id': tensor(178761),\n",
       "  'caption': 'a couple of cows standing next to a fence'},\n",
       " {'image_id': tensor(556901),\n",
       "  'caption': 'a red and white plane is parked at a dock'},\n",
       " {'image_id': tensor(397045), 'caption': 'a cat is sitting on a window sill'},\n",
       " {'image_id': tensor(115070),\n",
       "  'caption': 'a cat sitting on a cement block with a cat sitting on the'},\n",
       " {'image_id': tensor(450728),\n",
       "  'caption': 'a man riding an elephant down a street'},\n",
       " {'image_id': tensor(158414), 'caption': 'a bus is parked next to a bus stop'},\n",
       " {'image_id': tensor(56248),\n",
       "  'caption': 'a bus is parked on the side of the road'},\n",
       " {'image_id': tensor(96991),\n",
       "  'caption': 'a bench sits in the middle of a lake'},\n",
       " {'image_id': tensor(120767),\n",
       "  'caption': 'a group of people standing around a giraffe'},\n",
       " {'image_id': tensor(145727),\n",
       "  'caption': 'a park with a view of a person sitting on it'},\n",
       " {'image_id': tensor(42070),\n",
       "  'caption': 'a bus is parked on the side of the street'},\n",
       " {'image_id': tensor(85562),\n",
       "  'caption': 'a bus is parked on the side of the road'},\n",
       " {'image_id': tensor(408950),\n",
       "  'caption': 'a red double decker bus driving down a street'},\n",
       " {'image_id': tensor(19158),\n",
       "  'caption': 'a bus parked in a parking lot next to a street'},\n",
       " {'image_id': tensor(9041),\n",
       "  'caption': 'a cat is walking around a flock of birds'},\n",
       " {'image_id': tensor(29465),\n",
       "  'caption': 'a bird sitting on a branch in the snow'},\n",
       " {'image_id': tensor(122606),\n",
       "  'caption': 'a bus is parked on the side of the street'},\n",
       " {'image_id': tensor(15260),\n",
       "  'caption': 'a white and green vase with a white flower'},\n",
       " {'image_id': tensor(342394),\n",
       "  'caption': 'two giraffes are standing next to a pole'},\n",
       " {'image_id': tensor(472833),\n",
       "  'caption': 'a white swan swimming in a lake next to a pond'},\n",
       " {'image_id': tensor(412676),\n",
       "  'caption': 'a large building with a clock on the front'},\n",
       " {'image_id': tensor(571746),\n",
       "  'caption': 'a train traveling down the tracks near a mountain'},\n",
       " {'image_id': tensor(116722),\n",
       "  'caption': 'a train is on the tracks under a bridge'},\n",
       " {'image_id': tensor(553678),\n",
       "  'caption': 'a stop sign is shown in front of a fence'},\n",
       " {'image_id': tensor(370678),\n",
       "  'caption': 'a parking meter on the side of the street'},\n",
       " {'image_id': tensor(476339),\n",
       "  'caption': 'a parking meter sitting on the side of a road'},\n",
       " {'image_id': tensor(535183),\n",
       "  'caption': 'a group of people standing outside of a food truck'},\n",
       " {'image_id': tensor(359791),\n",
       "  'caption': 'a person sitting on a bench next to a body of water'},\n",
       " {'image_id': tensor(182334),\n",
       "  'caption': 'a man in a suit and tie looking at the camera'},\n",
       " {'image_id': tensor(546052), 'caption': 'a man holding a baby in his arms'},\n",
       " {'image_id': tensor(538451),\n",
       "  'caption': 'a large plant in a wooden box sitting on top of a wooden'},\n",
       " {'image_id': tensor(449485),\n",
       "  'caption': 'a person standing in a field with a suitcase'},\n",
       " {'image_id': tensor(74181),\n",
       "  'caption': 'a man standing next to a pile of luggage'},\n",
       " {'image_id': tensor(56013),\n",
       "  'caption': 'a pile of luggage sitting on the ground'},\n",
       " {'image_id': tensor(209544),\n",
       "  'caption': 'a man standing in a field with a frisbee'},\n",
       " {'image_id': tensor(379734),\n",
       "  'caption': 'a group of people playing frisbee in a field'},\n",
       " {'image_id': tensor(424422), 'caption': 'a man holding a frisbee in a park'},\n",
       " {'image_id': tensor(225715), 'caption': 'a bedroom with a bed and a desk'},\n",
       " {'image_id': tensor(26665),\n",
       "  'caption': 'a group of zebras are standing in a field'},\n",
       " {'image_id': tensor(60340),\n",
       "  'caption': 'a zebra standing in a dirt field next to a wooden fence'},\n",
       " {'image_id': tensor(476215),\n",
       "  'caption': 'a group of people standing around a horse'},\n",
       " {'image_id': tensor(74460),\n",
       "  'caption': 'two horses are standing in a field with trees'},\n",
       " {'image_id': tensor(529981), 'caption': 'a group of cows grazing in a field'},\n",
       " {'image_id': tensor(552503), 'caption': 'a pan of food on a stove top'},\n",
       " {'image_id': tensor(575915),\n",
       "  'caption': 'a slice of pizza on a plate on a table'},\n",
       " {'image_id': tensor(483545),\n",
       "  'caption': 'a table full of fruits and vegetables on it'},\n",
       " {'image_id': tensor(525118), 'caption': 'a bunch of bananas are on a table'},\n",
       " {'image_id': tensor(86202), 'caption': 'a person on a snowboard in the snow'},\n",
       " {'image_id': tensor(28582),\n",
       "  'caption': 'a close up of a plate of food with broccoli'},\n",
       " {'image_id': tensor(110156),\n",
       "  'caption': 'a group of people standing on top of a snow covered slope'},\n",
       " {'image_id': tensor(311690),\n",
       "  'caption': 'a plate of food with a glass of wine'},\n",
       " {'image_id': tensor(316240),\n",
       "  'caption': 'a collage of photos showing a lot of trees and a series of'},\n",
       " {'image_id': tensor(232432),\n",
       "  'caption': 'a man and two dogs walking down a sidewalk'},\n",
       " {'image_id': tensor(439651),\n",
       "  'caption': 'a coffee cup sitting on a table in front of a laptop'},\n",
       " {'image_id': tensor(248051),\n",
       "  'caption': 'a person riding a skate board on a street'},\n",
       " {'image_id': tensor(431891),\n",
       "  'caption': 'a bunch of carrots and some carrots on a table'},\n",
       " {'image_id': tensor(6415),\n",
       "  'caption': 'a cutting board with carrots and a knife'},\n",
       " {'image_id': tensor(420666),\n",
       "  'caption': 'a tray with a hot dog and some fries'},\n",
       " {'image_id': tensor(489739),\n",
       "  'caption': 'a little girl is holding a piece of paper'},\n",
       " {'image_id': tensor(571990),\n",
       "  'caption': 'a box filled with lots of different flavored donuts'},\n",
       " {'image_id': tensor(127842),\n",
       "  'caption': 'a man riding a surfboard on a wave in the ocean'},\n",
       " {'image_id': tensor(98003),\n",
       "  'caption': 'a slice of cake on a plate with a fork'},\n",
       " {'image_id': tensor(56651),\n",
       "  'caption': 'a woman holding a birthday cake with lit candles'},\n",
       " {'image_id': tensor(286760),\n",
       "  'caption': 'a white plate topped with a bowl of food'},\n",
       " {'image_id': tensor(452724),\n",
       "  'caption': 'a hotel room with two beds and a television'},\n",
       " {'image_id': tensor(330897),\n",
       "  'caption': 'a pizza with many toppings on a plate'},\n",
       " {'image_id': tensor(425620),\n",
       "  'caption': 'two little kids laying in a bed with stuffed animals'},\n",
       " {'image_id': tensor(565389),\n",
       "  'caption': 'a group of people sitting around a table eating'},\n",
       " {'image_id': tensor(275657),\n",
       "  'caption': 'a table with a white plate with a slice of pizza on it'},\n",
       " {'image_id': tensor(451683),\n",
       "  'caption': 'a large pizza with a slice missing from it'},\n",
       " {'image_id': tensor(95062),\n",
       "  'caption': 'a pizza sitting on top of a white plate on a table'},\n",
       " {'image_id': tensor(371135),\n",
       "  'caption': 'a woman is playing tennis on a tennis court'},\n",
       " {'image_id': tensor(466052),\n",
       "  'caption': 'a cup of coffee sitting on top of a toilet'},\n",
       " {'image_id': tensor(554859),\n",
       "  'caption': 'a living room with a couch and a table'},\n",
       " {'image_id': tensor(321866),\n",
       "  'caption': 'a child is helping a baby put into a bowl'},\n",
       " {'image_id': tensor(526414),\n",
       "  'caption': 'a living room with a couch and a tv'},\n",
       " {'image_id': tensor(534121),\n",
       "  'caption': 'a living room with a couch and a fireplace'},\n",
       " {'image_id': tensor(325211),\n",
       "  'caption': 'a computer keyboard sitting on top of a desk'},\n",
       " {'image_id': tensor(213008),\n",
       "  'caption': 'a bed with a white bedspread and a mirror'},\n",
       " {'image_id': tensor(7556), 'caption': 'a group of people on a body of water'},\n",
       " {'image_id': tensor(402248),\n",
       "  'caption': 'a man is sitting on the ground with a kite'},\n",
       " {'image_id': tensor(122266),\n",
       "  'caption': 'a woman is flying a kite in a field'},\n",
       " {'image_id': tensor(152004), 'caption': 'a glass vase with a flower in it'},\n",
       " {'image_id': tensor(447314), 'caption': 'a woman flying a kite in a park'},\n",
       " {'image_id': tensor(306940),\n",
       "  'caption': 'a baseball player holding a bat on a baseball field'},\n",
       " {'image_id': tensor(47882),\n",
       "  'caption': 'a kitchen with a center island and a large window'},\n",
       " {'image_id': tensor(1573),\n",
       "  'caption': 'a kitchen with a stove and a refrigerator'},\n",
       " {'image_id': tensor(385580),\n",
       "  'caption': 'a man and a woman standing in a kitchen'},\n",
       " {'image_id': tensor(501652),\n",
       "  'caption': 'a little boy sitting in a car looking out the window'},\n",
       " {'image_id': tensor(209048),\n",
       "  'caption': 'a white refrigerator freezer sitting inside of a kitchen'},\n",
       " {'image_id': tensor(33845),\n",
       "  'caption': 'a group of people sitting around a table with laptops'},\n",
       " {'image_id': tensor(159215),\n",
       "  'caption': 'a man holding a cell phone in his hand'},\n",
       " {'image_id': tensor(143167),\n",
       "  'caption': 'a clock tower in the middle of a city'},\n",
       " {'image_id': tensor(517687),\n",
       "  'caption': 'two cell phones sitting on top of a wooden table'},\n",
       " {'image_id': tensor(399205),\n",
       "  'caption': 'a man holding a cell phone standing next to a man'},\n",
       " {'image_id': tensor(36082),\n",
       "  'caption': 'a kitchen with a microwave and a sink'},\n",
       " {'image_id': tensor(220224),\n",
       "  'caption': 'a clock tower with a weather vane on top of it'},\n",
       " {'image_id': tensor(265596),\n",
       "  'caption': 'a piece of cake on a plate with a fork'},\n",
       " {'image_id': tensor(334399),\n",
       "  'caption': 'a man holding a white frisbee in his right hand'},\n",
       " {'image_id': tensor(487141),\n",
       "  'caption': 'a vase with flowers in it sitting on a table'},\n",
       " {'image_id': tensor(34080),\n",
       "  'caption': 'a pair of scissors sitting on a table'},\n",
       " {'image_id': tensor(433924),\n",
       "  'caption': 'a woman with a pair of scissors cutting her hair'},\n",
       " {'image_id': tensor(178795),\n",
       "  'caption': 'a plate of breakfast food on a table'},\n",
       " {'image_id': tensor(67686),\n",
       "  'caption': 'a plate with a sandwich and a bowl of soup'},\n",
       " {'image_id': tensor(161222),\n",
       "  'caption': 'a table with plates of food and a glass of water'},\n",
       " {'image_id': tensor(92678), 'caption': 'a woman flying a kite on the beach'},\n",
       " {'image_id': tensor(392892),\n",
       "  'caption': 'a kitchen with a table and chairs and a table'},\n",
       " {'image_id': tensor(321811),\n",
       "  'caption': 'a woman is working in a large kitchen'},\n",
       " {'image_id': tensor(274494),\n",
       "  'caption': 'a bathroom with a toilet sink and shower'},\n",
       " {'image_id': tensor(296707),\n",
       "  'caption': 'a bathroom with a sink and a toilet'},\n",
       " {'image_id': tensor(487525),\n",
       "  'caption': 'a bathroom with a toilet sink and mirror'},\n",
       " {'image_id': tensor(401623),\n",
       "  'caption': 'a bathroom with a white shower curtain and a large mirror'},\n",
       " {'image_id': tensor(411968),\n",
       "  'caption': 'a bathroom with a sink and a mirror'},\n",
       " {'image_id': tensor(430420),\n",
       "  'caption': 'a bathroom with a toilet and a sink'},\n",
       " {'image_id': tensor(26730),\n",
       "  'caption': 'a black motorcycle parked on the side of the road'},\n",
       " {'image_id': tensor(504811),\n",
       "  'caption': 'a large clock tower with a clock on each of its sides'},\n",
       " {'image_id': tensor(436467),\n",
       "  'caption': 'a close up of a bowl of food with carrots'},\n",
       " {'image_id': tensor(571804),\n",
       "  'caption': 'a bathroom with a toilet and a sink'},\n",
       " {'image_id': tensor(140658),\n",
       "  'caption': 'a church with a clock on the front of it'},\n",
       " {'image_id': tensor(230008),\n",
       "  'caption': 'a man riding a motorcycle down a street'},\n",
       " {'image_id': tensor(177938),\n",
       "  'caption': 'a man is working on a motorcycle in the garage'},\n",
       " {'image_id': tensor(359086),\n",
       "  'caption': 'a motorcycle parked in a parking lot next to a fence'},\n",
       " {'image_id': tensor(452122),\n",
       "  'caption': 'a large airplane is taking off from a runway'},\n",
       " {'image_id': tensor(413096),\n",
       "  'caption': 'a blue and white jet airliner on runway next to trees'},\n",
       " {'image_id': tensor(18975),\n",
       "  'caption': 'a view of a bunch of airplanes on a runway'},\n",
       " {'image_id': tensor(396051),\n",
       "  'caption': 'a large jetliner sitting on top of an airport tarmac'},\n",
       " {'image_id': tensor(268944),\n",
       "  'caption': 'a small airplane parked in a stationary position'},\n",
       " {'image_id': tensor(58851),\n",
       "  'caption': 'a bench sitting in the middle of a parking lot'},\n",
       " {'image_id': tensor(480605),\n",
       "  'caption': 'a large jetliner flying through a cloudy blue sky'},\n",
       " {'image_id': tensor(34662),\n",
       "  'caption': 'two sheep are standing in a field of grass'},\n",
       " {'image_id': tensor(28157),\n",
       "  'caption': 'a plane is flying over the ocean on a beach'},\n",
       " {'image_id': tensor(79392),\n",
       "  'caption': 'a plane flying over a city with a lot of mountains in the'},\n",
       " {'image_id': tensor(463211),\n",
       "  'caption': 'a woman with a pink shirt and a blue dress'},\n",
       " {'image_id': tensor(463084),\n",
       "  'caption': 'a bus is driving down a street in the rain'},\n",
       " {'image_id': tensor(165572),\n",
       "  'caption': 'a red double decker bus traveling down a street'},\n",
       " {'image_id': tensor(173797),\n",
       "  'caption': 'a city street with a bus driving down the street'},\n",
       " {'image_id': tensor(531163),\n",
       "  'caption': 'a bus is driving down a busy street'},\n",
       " {'image_id': tensor(393647),\n",
       "  'caption': 'a city bus is stopped at a bus stop'},\n",
       " {'image_id': tensor(35195),\n",
       "  'caption': 'a bird with a long beak walking on the beach'},\n",
       " {'image_id': tensor(219723),\n",
       "  'caption': 'a group of sheep are standing in a pen'},\n",
       " {'image_id': tensor(139660),\n",
       "  'caption': 'a small bird perched on a tree limb'},\n",
       " {'image_id': tensor(167810),\n",
       "  'caption': 'a group of ducks swimming in a pond'},\n",
       " {'image_id': tensor(279621),\n",
       "  'caption': 'a train traveling down tracks next to a forest'},\n",
       " {'image_id': tensor(578093),\n",
       "  'caption': 'a train station with a train stopped in the station'},\n",
       " {'image_id': tensor(519555), 'caption': 'a stop sign is shown on a road'},\n",
       " {'image_id': tensor(236000),\n",
       "  'caption': 'a truck is driving down a street with a truck behind it'},\n",
       " {'image_id': tensor(23731),\n",
       "  'caption': 'a cat is laying on a chair in a room'},\n",
       " {'image_id': tensor(38938),\n",
       "  'caption': 'a cat sitting on a dresser in a room'},\n",
       " {'image_id': tensor(379108),\n",
       "  'caption': 'a man and a woman on a boat in the water'},\n",
       " {'image_id': tensor(298628),\n",
       "  'caption': 'a group of three horses standing on a lush green hillside'},\n",
       " {'image_id': tensor(530706),\n",
       "  'caption': 'a group of people sitting at a table with laptops'},\n",
       " {'image_id': tensor(466259),\n",
       "  'caption': 'a woman with an umbrella is standing on a boat'},\n",
       " {'image_id': tensor(340332),\n",
       "  'caption': 'a dirty room with a dirty floor and a dirty toilet'},\n",
       " {'image_id': tensor(74759),\n",
       "  'caption': 'a group of elephants walking down a street'},\n",
       " {'image_id': tensor(414934),\n",
       "  'caption': 'a man riding a skateboard down a street next to a truck'},\n",
       " {'image_id': tensor(215245),\n",
       "  'caption': 'a group of zebras are standing in a field'},\n",
       " {'image_id': tensor(405249),\n",
       "  'caption': 'a group of children watch a birthday cake'},\n",
       " {'image_id': tensor(512467),\n",
       "  'caption': 'a white horse standing in a field with a blue sky in the'},\n",
       " {'image_id': tensor(156772), 'caption': 'a close up of a basket of oranges'},\n",
       " {'image_id': tensor(575179),\n",
       "  'caption': 'a sandwich with meat and lettuce on it'},\n",
       " {'image_id': tensor(189566),\n",
       "  'caption': 'a man and a woman sitting in front of a mirror'},\n",
       " {'image_id': tensor(192095),\n",
       "  'caption': 'a young boy in a baseball uniform throwing a ball'},\n",
       " {'image_id': tensor(298691),\n",
       "  'caption': 'a bowl of broccoli and carrots sitting on a table'},\n",
       " {'image_id': tensor(122239),\n",
       "  'caption': 'a young boy holding a red apple in his hand'},\n",
       " {'image_id': tensor(57843),\n",
       "  'caption': 'a plate with a slice of cake and a fork'},\n",
       " {'image_id': tensor(358982),\n",
       "  'caption': 'a person riding a skate board on a city street'},\n",
       " {'image_id': tensor(274455),\n",
       "  'caption': 'a person riding a skate board on a street'},\n",
       " {'image_id': tensor(519744),\n",
       "  'caption': 'a young man riding a skateboard down a street'},\n",
       " {'image_id': tensor(125971),\n",
       "  'caption': 'a hot dog with a pickle and some drinks'},\n",
       " {'image_id': tensor(490688),\n",
       "  'caption': 'a plate with a sandwich and a side of potatoes'},\n",
       " {'image_id': tensor(317028),\n",
       "  'caption': 'a person holding a donut with a green sugar doughnut'},\n",
       " {'image_id': tensor(581010),\n",
       "  'caption': 'a plate with a doughnut and a cup of coffee'},\n",
       " {'image_id': tensor(28998),\n",
       "  'caption': 'a young boy holding a baseball bat in his hands'},\n",
       " {'image_id': tensor(439326),\n",
       "  'caption': 'a white polar bear eating some food on a plate'},\n",
       " {'image_id': tensor(184384),\n",
       "  'caption': 'a sandwich and a cup of soup on a plate'},\n",
       " {'image_id': tensor(424880),\n",
       "  'caption': 'a piece of cake on a plate with a fork'},\n",
       " {'image_id': tensor(501122),\n",
       "  'caption': 'a man is cutting a large white snowboard'},\n",
       " {'image_id': tensor(234677),\n",
       "  'caption': 'a surfboard is on the beach with a surf board'},\n",
       " {'image_id': tensor(10837),\n",
       "  'caption': 'a group of young men playing a game of soccer'},\n",
       " {'image_id': tensor(205636),\n",
       "  'caption': 'a young boy sitting on a bed with a remote control'},\n",
       " {'image_id': tensor(184386),\n",
       "  'caption': 'a bed with a wooden head board and a picture of a bedroom'},\n",
       " {'image_id': tensor(231037),\n",
       "  'caption': 'a man riding a wave on top of a surfboard'},\n",
       " {'image_id': tensor(467437), 'caption': 'a man and woman laying on a bed'},\n",
       " {'image_id': tensor(258588), 'caption': 'a man is playing tennis on a court'},\n",
       " {'image_id': tensor(460251),\n",
       "  'caption': 'a remote control sitting on top of a wooden table'},\n",
       " {'image_id': tensor(357978),\n",
       "  'caption': 'a woman standing in front of a tv playing wii'},\n",
       " {'image_id': tensor(571641),\n",
       "  'caption': 'a desk with a computer and a keyboard'},\n",
       " {'image_id': tensor(163348),\n",
       "  'caption': 'a desk with a laptop computer and a printer'},\n",
       " {'image_id': tensor(298978),\n",
       "  'caption': 'a woman in a car with a surfboard in the back'},\n",
       " {'image_id': tensor(258628),\n",
       "  'caption': 'a man holding a tennis racquet on a tennis court'},\n",
       " {'image_id': tensor(118432),\n",
       "  'caption': 'a group of people flying kites in a park'},\n",
       " {'image_id': tensor(205230),\n",
       "  'caption': 'a group of young children sitting at a table'},\n",
       " {'image_id': tensor(345136),\n",
       "  'caption': 'a child in a field with a kite in the air'},\n",
       " {'image_id': tensor(404613),\n",
       "  'caption': 'a young girl holding a tennis racket on a tennis court'},\n",
       " {'image_id': tensor(131089),\n",
       "  'caption': 'a young man riding a skateboard down a street'},\n",
       " {'image_id': tensor(432570),\n",
       "  'caption': 'a black and white photo of a vase with flowers in it'},\n",
       " {'image_id': tensor(214224),\n",
       "  'caption': 'a kitchen with a refrigerator and a stove'},\n",
       " {'image_id': tensor(199764),\n",
       "  'caption': 'a woman standing in a market selling food'},\n",
       " {'image_id': tensor(176312),\n",
       "  'caption': 'a woman standing in front of a green wall'},\n",
       " {'image_id': tensor(453297),\n",
       "  'caption': 'a cell phone sitting on top of a table next to a glass'},\n",
       " {'image_id': tensor(529668),\n",
       "  'caption': 'a woman holding a suitcase and standing next to a wall'},\n",
       " {'image_id': tensor(551107),\n",
       "  'caption': 'a little girl holding a nintendo wii game controller'},\n",
       " {'image_id': tensor(413120), 'caption': 'a close up of a bowl of broccoli'},\n",
       " {'image_id': tensor(369771),\n",
       "  'caption': 'a plastic container filled with a plate of food'},\n",
       " ...]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b8907533",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type Tensor is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7572/82224693.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'1218_results.json'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_captions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\clipcap\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    177\u001b[0m     \u001b[1;31m# could accelerate with writelines in some versions of Python, at\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;31m# a debuggability cost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m         \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\clipcap\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[1;34m(o, _current_indent_level)\u001b[0m\n\u001b[0;32m    427\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0m_floatstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m_iterencode_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m_iterencode_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\clipcap\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36m_iterencode_list\u001b[1;34m(lst, _current_indent_level)\u001b[0m\n\u001b[0;32m    323\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m                 \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    326\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\clipcap\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36m_iterencode_dict\u001b[1;34m(dct, _current_indent_level)\u001b[0m\n\u001b[0;32m    403\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m                 \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\clipcap\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[1;34m(o, _current_indent_level)\u001b[0m\n\u001b[0;32m    436\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Circular reference detected\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m                 \u001b[0mmarkers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmarkerid\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 438\u001b[1;33m             \u001b[0mo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    439\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\clipcap\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m         \"\"\"\n\u001b[1;32m--> 179\u001b[1;33m         raise TypeError(f'Object of type {o.__class__.__name__} '\n\u001b[0m\u001b[0;32m    180\u001b[0m                         f'is not JSON serializable')\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Object of type Tensor is not JSON serializable"
     ]
    }
   ],
   "source": [
    "with open('1218_results.json', 'w') as f:\n",
    "    json.dump(pred_captions, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e5f567",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f73dba20",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if (osp.exists(bestmodelfn)):\n",
      "if (args.beam_size == 1):\n",
      "Loading annotation file...\n",
      "Found 5000 images in split: test\n",
      "[DEBUG] #words in wordlist: 9221\n",
      "[DEBUG] Loading test data ... 4.452054 secs\n",
      "[DEBUG] Running inference on test with 250 batches\n",
      "[DEBUG] Loading checkpoint output\\bestmodel.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/250 [00:00<?, ?it/s]D:\\CVclass\\convcap-master\\convcap-master\\convcap.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(x.view(sz[0] * sz[1], sz[2]))\n",
      "D:\\CVclass\\convcap-master\\convcap-master\\test.py:87: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  wordprobs = F.softmax(wordact_t).cpu().data.numpy()\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 250/250 [01:11<00:00,  3.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.47s)\n",
      "creating index...\n",
      "index created!\n",
      "Using 5000/5000 predictions\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 43520, 'reflen': 44789, 'guess': [43520, 38520, 33520, 28520], 'correct': [24850, 8862, 2193, 503]}\n",
      "ratio: 0.9716671504163753\n",
      "Bleu_1: 0.555\n",
      "Bleu_2: 0.352\n",
      "Bleu_3: 0.199\n",
      "Bleu_4: 0.108\n",
      "computing METEOR score...\n",
      "METEOR: 0.148\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.411\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.303\n",
      "computing SPICE score...\n",
      "SPICE: 0.085\n",
      "TEST set scores\n",
      "Bleu_1: 0.554592\n",
      "Bleu_2: 0.352029\n",
      "Bleu_3: 0.198949\n",
      "Bleu_4: 0.107769\n",
      "METEOR: 0.148145\n",
      "ROUGE_L: 0.411031\n",
      "CIDEr: 0.303347\n",
      "SPICE: 0.085442\n"
     ]
    }
   ],
   "source": [
    "if (osp.exists(bestmodelfn)):\n",
    "    print('if (osp.exists(bestmodelfn)):')\n",
    "    \n",
    "    if (args.beam_size == 1):\n",
    "        print('if (args.beam_size == 1):')\n",
    "        scores = test(args, 'test', modelfn=bestmodelfn)\n",
    "    else:\n",
    "        print('else:')\n",
    "        scores = test_beam(args, 'test', modelfn=bestmodelfn)\n",
    "        \n",
    "    print('TEST set scores')\n",
    "    for k, v in scores[0].items():\n",
    "        print('%s: %f' % (k, v))\n",
    "else:\n",
    "    print('2 else')\n",
    "    raise Exception('No checkpoint found %s' % bestmodelfn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3462746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('Bleu_1', 0.6257070931810783), ('Bleu_2', 0.4400814108073923), ('Bleu_3', 0.2950048884687872), ('Bleu_4', 0.19118162177132456), ('METEOR', 0.1882842543884385), ('ROUGE_L', 0.4576943954075463), ('CIDEr', 0.5376096446582836), ('SPICE', 0.11709152104827554)])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[0].items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176e00f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b78af3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
